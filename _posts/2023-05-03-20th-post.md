---
layout: post
title: "Region proposal - Selective Search, EdgeBox"
description: "Part 2. 컴퓨터비전 특화 이론과 실습", "Ch05. 객체탐지(Object Detection)와 분할(Segmentation)", "Object Detection - Object Detection by CNN"
date: 2023-05-03
tags: study
comments: true
---
###### Object Detection
* Finding object bounding box
![image](https://user-images.githubusercontent.com/122149118/235717577-15d69019-27cc-4364-80a9-9938fa40212b.png)
object detection이란 object의 bounding box를 찾는 task이다.
위 그림은 다양한 object recognition의 task들을 나타낸 것이다.
첫 번째 그림은 classification task로, image에 있는 object의 class label만 prediction한 task이다.
cat의 위치와 상관없이 cat이 있음을 예측하면 된다.
반면에 classification + localization task는 object가 어디에 있는지 localize해주는 것이다.
cat이라는 object가 있을 때 cat 근처에 bounding box를 찾아주는 것이 object localization task이다.
이러한 classification이나 object localization은 multiple, multiple instance, multiple object라는 말이 명시되어 있지 않다면 single object를 가정한다. 즉, 하나의 object만이 image에 있다는 것이 가정된다.
object detection은 image 한 장에 여러가지 object가 있을 수 있다.
각각 bounding box의 class label이 무엇인지 찾아주는 task가 object detection이다.
instance segmentation은 semantic segmentation과 object detection을 더한 것이다.
object의 localize할 뿐만 아니라 그 위치에 bounding box가 아닌 segmentation mask를 나타내는 task이다.
각 instance별로 class label을 prediction한 것이기 때문에 pixel level의 label이 무엇인지를 찾아주는 task는 instance segmentation이다.
object detection이나, instance segmentation은 multiple object를 다룬다는 특성을 가진다.
sementic segmentation과 instance segmentation의 차이는 sementic segmentation은 object가 어디에 위치하는지에 대해 상관하지 않고 바깥에 있는 영역들 마저도 class label을 prediction할 수 있다는 점이다. objectness는 측정하지 않는다.
instance segmentation은 objectness도 측정을 한다는 특성을 가진다.
###### Deep Learnig for Object Detection: A Naive Approach

Motivated by the great success of deep learning in image classification
Object Detection = Box localization + Box classification
Box localization ⇒ Object proposals
Box classification ⇒ CNN
![image](https://user-images.githubusercontent.com/122149118/235723194-d3919091-6831-423a-8689-6c5ded918192.png)
Selective Search for Object Detection, UCV 2013
![image](https://user-images.githubusercontent.com/122149118/235723390-9c285f9d-00ca-480e-a795-75dacfb58a51.png)
Edge Boxes: Locating Object Proposals from Edges, ECCV

object detection을 위한 가장 간단한 deep learning 기법은 box localization과 Box classification, 이 2가지를 수행한다는 것이다.
이 기법이 등장한 계기는 image classification이 deep learning을 사용하여 큰 성공을 거두었는데, 이러한 성공에 morivation을 받아 object detection을 box localization과 classification으로 수행한다.
이 때 box localization은 object proposal을 이용하여 보통 수행하게 되고, box classification은 CNN model을 사용하여 수행하게 된다.
object proposal에서 proposal은 '후보군, 후보'라는 의미로 object 후보가 될 수 있는 bounding box 여러 개를 찾아 각각 bounding box에 대해 class prediction을 수행하고 각 bounding box에 해당하는 class가 무엇인지 선택하는 것이다.
이 때 이 모든 후보군이 모두 object가 아닐 수도 있기 때문에 object의 localize를 더 잘할 수 있게 object스러운 object localize를 하는 것이 매우 중요하다.
box localization을 위한 object proposal을 만드는 고전적인 기법들의 method는 2가지로, 첫 번째는 selective search라는 기법이고 두 번째는 edge box라는 method이다.
selective search는 여러 개의 super pixel을 처음에 segment를 여러 개 만든다.
이 super pixel들을 합쳐 나아가는 방식으로 segmentation을 수행하여 최종적으로 segmentation을 수행하는 것이 첫 번째 그림이다.
edge box는 object의 edgeness를 측정하여 edge를 따 edgeness의 bounding box를 찾아주는 방식이다.

---

# Selective Search for Object Detection

To obtain region proposal

Motination
 * Capture all scales: 물체 크기 랜덤, 경계 불명확 할 수 있음
 ![image](https://user-images.githubusercontent.com/122149118/236103899-9973ab45-05a6-413a-9fea-6c7e09c92405.png)
 * Diversification: 색상, 재질, 크기 등의 조건을 고려해서 다중 전략을 취함
 ![image](https://user-images.githubusercontent.com/122149118/236104006-5a21153c-5ad9-4afa-8b0c-adc4d6714fe4.png)
 * Fast to compute: 계산 시 너무 오래 걸리면 안됨

object detection을 위한 selective search는 region proposal을 얻는 방식을 제안한다.
motivation으로 첫 번째, capture all scales는 물체 크기가 랜덤일 수 있으며 경계가 불명확할 수 있다는 것이다.
아래의 사진에서 양들과 카메라의 사이가 멀리 떨어져 있다면 양들이 작게 찍힐 것이고 가까이에 있다면 크게 찍힐 것이므로 크기가 랜덤일 수 있고 겹쳐질 수도, 일부분이 가려질 수도 있으며, 카메라의 boundary 밖으로 나가 잘려질 수도 있기 때문에 경계가 불명확할 수 있다.
두 번째는 divesification으로 object proposal, region proposal을 만들 때 색깔이나 재질, 크기 등의 조건을 고려해서 한 가지 전략으로만 문제를 풀어야 하는 것이 아닌 다중 전략을 취해야 한다는 것이다.
(a)의 dining table에서 음식들이 많이 존재하고 접시도 있는 것을 볼 수 있으며 (b)는 같은 고양이지만 고양이가 가진 pattern이 다르다.
(c)와 같은 카멜레온 예시는 background와 비슷한 색상을 가지기 때문에 색상만으로는 판단할 수 없고 질감이나 특성을 고려해서 알려주어야 한다.
(d)의 super car는 super car의 오른쪽 부분을 찍고 있기 때문에 앞 부분으로 무조건 가정할 수 없으며 이 모양의 특성을 3D 3차원 상에서의 전체적인 부분을 고려하여 object proposal을 찾아주어야 한다.
세 번째 motivation은 fast to compute이다.
계산 시 너무 오래 걸리면 안되고 컴퓨터가 real time까지는 아니어도 실제 application에 사용할 수 있을 정도로 빠르게 계산되어야 한다.
최근 object detection algorithm들은 gpu를 사용하여 deep learning model로 만들기 때문에 거의 real time으로도 작동이 가능하다.
거의 10fps 라던지 1초 이내의 시간이 걸리는데 당시에는 하드웨어도 크게 발전하지 않았었으며 gpu 사용 이전인 2013년에 제안되었던 논문들은 계산이 오래걸렸었다.
computation에 대한, cpu로 계산 할 때 어떻게 빨리 할 지에 대한 issue도 있었다.
하지만 이제는 어떻게 빨리 계산하는지에 대해서는 gpu로 해결되었기 때문에 다루지 않는다.
method의 technical contribution 위주로 다룰 것이다.

 * Two step to do object detection
 1) To obtain region proposal
 2) Recognition algorithm on the candidates
 ![image](https://user-images.githubusercontent.com/122149118/236212227-8288a931-ad25-4b10-a69a-e885094cc8d6.png)
 * 미리 위와 같은 segment가 있으면 그 영역에 대해 candidate objects로 사용하여 좀 더 쉽게 object detection을 할 수 있지 않을까?

object detection을 수행하는 2가지 step은 region proposal을 먼저 얻고, 후보 proposal들에 대해서 recognition algorithm을 적용하는 것이다.
이 때 selective search는 고양이들의 segment가 있으면 이 영역들을 candidate object로 사용하여 좀 더 쉽게 object detection을 할 수 있지 않을까라는 motivation을 찾는다.
다양한 색깔의 bounding box가 찾아질 수 있지만 엉뚱한 bounding box도 존재할 수 있을 것이다.
그러한 bounding box들에 대해서는 classification으로 구분해 낼 수 있다.

 * 목표: Object recognition이나 detection을 위한 후보 영역을 알아낼 수 있는 algorithm
 * 과정
    - Seed 설정
    - 초기에는 아주 많은 후보들이 존재
    - Seed 적절히 통합하여 후보 줄이기
![image](https://user-images.githubusercontent.com/122149118/236217168-cab38155-9700-41da-a26d-0ee06dc56429.png)

과정은 왼쪽 맨 첫 번째 사진과 같이 seed를 설정하면 다양한 object 후보들이 나올 것이다.
왼쪽 아래 첫 번째 사진과 같이 영상에서는 noise같은 것도 다른 segment로 판단을 해서, edge등을 판단하여 super pixel을 찾는다.
super pixel은 하나의 pixel이 아닌 어떤 영역들이 비슷한 sementice를 가진다고 하는 고전적인 segmentation같은 기법을 말한다.
seed를 설정하면 초기에는 많은 후보들이 존재하게 되고 다음 step에서는 seed를 적절히 통합하여 후보를 줄이는 과정을 가진다.
비슷한 seed들을 근처에서 비슷하면 합쳐 맨 오른쪽 3번째 사진과 같은 seed를, object segmentation mask라고도 할 수 있는 mask를 얻는다.
이 mask들의 바깥쪽으로 box를 그리게 되면 bounding box를 찾을 수 있다.
 - Input image에 sub segmentation 진행
 - 작은 영역을 큰 영역으로 결합
    * Set of regions에서 가장 유사한 두 가지 선택
    * 이 선택한 두 가지를 하나로 결합
![image](https://user-images.githubusercontent.com/122149118/236225007-43494aee-a9d4-4505-9d02-bf3fe4415566.png)
iteration을 많이 거치게 되면 어느정도 segment mask를 형성하는 map을 볼 수 있다.
 * Segmented region proposals을 사용해서 candidate object locations 구함
 * SVM으로 object recognition
 ![image](https://user-images.githubusercontent.com/122149118/236226475-e481cadb-e799-47db-aa81-5a54f199c267.png)
 예를 들어 소에 bounding box가 쳐져있는 Ground truth image가 있을 때 이 image의 경우 positive example로써 학습 image에 속한다.
 selective search는 학습하는 algorithm이 아니기 때문에 object hyorheses, object proposal들을 구하게 된다. 
 super pixel을 사용하여 segment를 merge하여 최종적인 object proposal 여러 개를 구한다.
 overlap되는 몇 개의 proposal을 제거한 후 이 proposal의 최종적인 몇 개의 후보들을 가져온 다음 너무 objectness가 떨어지는 것들은 적절한 algorithm을 통해 filtering을 해준다.
 training example의 bounding box를 SVM, 고전적인 classification algorithm에 histogram intersaction kernel을 사용해 넣어준 후 false positive bounding box들을 제거해주는 algorithm을 수행한다.
 이것을 training example로 사용하여 다시 SVM을 학습시켜준다.
 처음 SVM을 한 번 false positive를 걸러주고 그 다음 학습으로 사용하여 SVM을 training하는 형태의 학습 방식을 사용한다.
 deep learning 이전에도 구조화된 형태로 proposal을 구하고 classifier를 학습하는 형태의 object detection algorithm들이 있었다.

 * 결과
    - Mean Average Best Overlap(MABO)
    - Recall
    - #windows
![image](https://user-images.githubusercontent.com/122149118/236230680-8553f749-d919-4ba9-9259-4ae976fd1cd3.png)
이 때 사용했던 evaluation metric으로 mean average best overlap을 사용했다.
bounding box에서 set이 있을 때 정답 object bounding box와 얼마나 많이 겹치는지를 측정하는 metric이다.
추가적으로는 얼마나 많이 맞췄는지 어떤 overlaping 기준에 대해 accuracy를 구하는 것으로 맞으면 1, 틀리면 0을 반환하는  recall을 사용하기도 했으며 proposal을 많이 사용할수록 유리하게 되므로 number of windows도 기재해준다.
기존에 기법들에 비해 single strategy의 low bound가 있고 Selective search "Fast"를 사용했을 때 window를 적게 사용하여도 recall이나 MABO가 괜찮을 성능을 내고 Selective search "Quality"를 사용했을 때 recall이나 MABO가 가장 좋은 결과를 내는 것을 볼 수 있다.
testset은 PASCAL VOC 2007을 사용했다. 
![image](https://user-images.githubusercontent.com/122149118/236231024-285beeba-030a-4a09-b314-9601cde1345b.png)
selective search의 정성적인 결과이다.
기존의 사용방법들과 비교했을 때 selective search는 object위주로 잘 잡는 것을 볼 수 있다.
boundary가 불분명한 경우에는 잘 잡지 못해 failure case로 둔다.

# EdgeBox for Object Detection
 
 * Gradient orientation을 기반으로 edge group을 표현하고, 이를 이용해서 bounding box score를 계산함
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/f09fc242-5810-4196-bf23-14cb749576ed)

 두 번째 기법은 EdgeBox로, technic contribution이 gradient orientation을 기반으로 edge group 즉, edge map을 표현하고 이를 이용하여 bounding box score를 계산한다.
 어떤 edge의 특정한 부분들에 대해 바깥쪽으로 coordinate를 잡으면 bounding box를 찾을 수 있다.
 가장 선명한 edge부분들이 보통 bounding box일 것이기 때문이다.
 <del>selective search보다는 edgebox가 훨씬 더 잘 동작한다.</del>

 * Evaluation metric 제안: Intersection on Union(IoU)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/fc65b12e-a0d1-4660-9299-64f4f81c90bc)

 Intersection은 교집합을 뜻하고, Union은 합집합을 뜻하는데 bounding box의 합집합분의 교집합을 사용하는 것이다.
 GT bounding box가 있고, predicted bounding box가 있을 때 이것들의 합집합분의 교집합으로 굉장히 엄격한 metric이다.
 위 그림에서 볼 수 있듯 IoU가 0.7정도만 되어도 어느정도 맞추어냈다고 할 수 있을 것이다.
 object가 deformation이 있기 때문에, 비틀어져 있다면 object의 일부분이 삐져나올 수 있는데 이러한 objectness를 측정할 때 evaluation metric으로 IoU를 사용한다.
 object detection은 segmentation mask를 찾는 것이 아닌 bounding box를 찾는 것이기 때문에 box내에 object말고 clutter같은 것이 존재할 수 있다.
 따라서 clutter같은 것들에 대해 robust할 수 있고 측정하기에 좋은 metric이다.
 IoU를 threshold하여 mAP를 측정할 수도 있고 IoU 그 자체로서 MeanIoU 등을 잴 수도 있다.
 * Results: IoU 0.7로 threshold한 결과, Recall이 가장 높으면서도, 빠르다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/069dc794-d198-4bc9-984d-dbc85597377b)
 기존의 BING이라는 방법이 빠르긴 하지만 Recall이 떨어지는 것을 확인할 수 있다.
 IoU로 측정한 Area Under the Cover(AUC)도 가장 높고, thresholding한 결과들도 적은 proposal 개수에 비해 더 좋은 결과를 나타낸다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/e6af9921-e157-4259-a202-159f4373c078)
 EdgeBox의 qualitative result, 정성적 결과이다.
 edgebox로 찾아지는 어떤 bounding box들이 정답 근처를 잘 localize하고 있다.
 이 결과를 SVM을 그대로 태우게 되면 좋은 결과들이 나오게 된다.
 이 논문의 핵심은 더 잘 localize를 하는 것이 중요하다는 것이었으며 이 때는 localize를 잘하고 classifier를 잘하는 것이 그 당시 연구 방향이었는데 이러한 부분들이 localize하는 region proposal을 찾는 방식도 CNN network로 하나로 만들어지고 classification network도 classifier가 CNN으로 바뀌면서 최근에 사용되는 object detection의 network형태, model형태를 가지게 된다.