---
layout: post
title: "R-CNN, Fast R-CNN"
description: "Part 2. 컴퓨터비전 특화 이론과 실습", "Ch05. 객체탐지(Object Detection)와 분할(Segmentation)", "Object Detection - Object Detection by CNN"
date: 2023-05-09
tags: study
comments: true
published: true
---
# Region-based CNN(RCNN)
![image](https://github.com/leexera/leexera.github.io/assets/122149118/e7965e16-e2fb-4dbe-b9b6-f2ce653e5690)
 <b>Summary</b>
 * Independent evaluation of each proposal using Any architecture
 * Bounding box regression improves detection accuracy
 * Mean average precision(mAP): 53.7% with bounding box regression in VOC 2010 test set

 RCNN은 object detection의 대표적인 deep learning algorithm이라고 할 수 있다.
 구성은 어떤 Input image가 있을 때, region proposal을 selective search나 edgebox를 이용하여 뽑고, CNN feature를 뽑고 classification을 하는 단계를 다시 재적립한다.
 이러한 detector는 2-stage object detector로 2-stage object detector는 먼저 region proposal을 먼저 뽑고, classifier를 따로 두어 2단계의 object detection을 수행한다는 것이다.
 한 번에 object 위치를 뽑으면서 위치에 대한 classification을 동시에 수행하는 것은 1-stage detector, YOLO와 같은 detector들을 말한다.
 이전의 edgebox와 selective search와 달라진 부분은 classifier에서 CNN feature extractor로 classification을 수행한다는 점이다.
 classification을 수행한 후 Softmax나 SVM으로 logic을 구하여 최종적으로 sigmoid로 classification을 수행할 수 있다.
 만약 object가 1개라면 softmax로 충분하겠지만 object가 여러개라면 SVM을 사용하는 것이 좋다.
 결국 각 bounding box에 대해 수행하는 것이다보니 softmax도 적절하다고 볼 수 있다.
 어떠한 architecture를 사용한 각 proposal에 대해서 각각의 독립적인 evaluation을 가능하게 했다.
 예를 들어, selective search를 사용하여 CNN을 태우던지 edgebox를 사용하여 CNN을 태우던지 각각에 대해서 결합을 할 수 있게 된다.
 detection accuaracy를 높이기 위해서 bounding box regression을 수행하게 된다.
 bounding box regression은 classification을 말하는 것이 아니라 region proposal을 뽑는 것, bounding box를 찾아주는 것을 말하는 것이다.
 precision recall curve에 그 영역들을 측정해보았을 때 VOC 2010 test set에서 53.7%의 mAP를 얻어 높은 성능을 낸다.
 위 논문은 VGGNet과 비슷한 시기에 출판되었다.

 * Learning a transformation of bounding box
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/39c2a25f-8fd1-47f5-ad65-8bea996cdf10)
 region based CNN은 bounding box의 transformation을 학습하는 것이다.
 Compute CNN feature와 Classification사이에 classification을 수행하는 classifier가 있고, Extract region proposal과 Compute CNN feature사이에 bounding box를 regression하는 부분이 있는데 bounding box regression은 먼저 edgebox나 selective search로 찾아진 P라는 bounding box가 있다.
 G라는 위치로 coordinate를 옮겨주는 일을 수행하게 된다.
 P라는 bounding box의 displacement를 학습하게 되는 것이다.
 region proposal들이 있을 때 ground-truth를 정답으로 주고 trasformation, 얼마나 box가 이동을 해야하고 얼마나 커지고 작아져야 하는지 d를 학습하게 되는 것이 bounding box regression이 RCNN의 핵심이다.
 기존의 ground-truth bounding box의 x, y coordinate와 w, h는 기존의 P<sub>w</sub>의 d만큼 좌표에 대해서 평행이동 시켜준다.
 크기에 대해서는 exp값으로 곱해주어 최종적인 predict bounding box를 구하게 된다.
 이 때 d<sub>i</sub>(P)는 approximation을 하는데, CNN pool5 feature에 대해서 extriction을 하여 weight를 한 번 곱해주어 transformation을 시켜 그 value를 구하게 된다.
 최종적인 parameter update는 regression score를 minimize하게 되는 w를 구하게 된다.
 optimization 수식은 CNN을 사용하기 때문에 gradient decsent optimization으로 수행을 할 수 있게 된다.
 차이가 있을 때 pool5 feature로 나온 displacement를 뒤에 term으로 빼주게 되고, 이 값을 제곱하면 L<sub>2</sub> distance로서 모든 k, object proposal에 대해서 다 구해주게 된다.
 over fitting을 막기 위해 regularization term으로 w를 걸어준다.(||w<sub>i</sub>||)
 전체 수식을 optimize하게 되면 최종적으로 수렴하는 위치에 object bounding box regressor가 학습되게 되는 것이다.
 * Results
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/5c5444f8-e64e-4a7f-84fc-e45f7cf44d34)
 pascal VOC 2010 test set에서 detection average prediction을 구한 것이다.
 기존의 DPM v5, UVA, Regionelets, SegDPM보다 R-CNN, R-CNN BB(bounding box)방식이 훨씬 더 높은 성능을 낸다.
 R-CNN BB regression까지 포함한 결과가 모든 class에 대해서 높은 성능을 한 줄로 다 채우는 것을 볼 수 있다.
 이때부터 deep learning의 기반의 방법들이 한 줄로 다 채우는 것(모든 object에 대해서 모두 다 성능이 좋다)이 유행이 된 것으로 추측할 수 있다.
 mean Average Precision(mAP)라는 evaluation metric도 제안을 하고, CNN을 사용한 구조와 bounding box regressor라는 여러가지 contribution이 있는 R-CNN 논문이다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/6fa5f6f8-0012-4a9c-b53e-56eb79b3e693)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/f1e01733-43ee-46d8-8ecf-046367f6d8c7)
 R-CNN의 정성적 결과이다.
 object proposal transformation에 대해서 예시를 든 것이다.
 왼쪽 그림과 같이 (A)는 input image이고 (B)는 object 위치를 context를 고려하여 tight하게 scanner를 한 것이다. 
 불빛과 같은 context나 car image에서도 앞에 차와 도로 배경과 같은 것들을 고려하여 cropping을 한 것이다.
 (C)는 context없이 object만 tight하게 cropping한 것이다.
 (D)는 warppig까지 같이 해주어 tight하게 cropping된 image를 CNN의 input size에 맞게 펼쳐준 것이다.
 CNN은 정해진 input을 받아야하기 때문에 당시엔 ROI pooling과 같은 것들이 없었기에 정해진 input으로 길게 늘어뜨려 넣어주었어야 한다.
 작은 object에 대해서나 자전거의 앞바퀴가 잡힌 중간 정도 되는 object, 또는 사람이 크게 잡힌 object나 다양한 object에 대해서도 다른 object proposal transformation을 하여 결과를 구해낼 수 있다는 것이 첫 번째 figure의 핵심이다.
 말을 타고 있는 사람 image의 context를 고려하여 cropping을 하고 실제 object bounding box는 crop되어 사람이 말 타고 있는 영상을 잘라내야 한다.
 실제 CNN input에 넣을 때는 당시엔 adaptive하게 image size를 조절하는 것이 없었기 때문에 image를 사각형 형상에 맞춰 interpolation하여 input으로 넣게 된다.
 정성적 결과를 보게 되면 사람이 기타를 들고 있는데 사람과 기타 각각에 대해 bounding box를 높은 confidence score로 잘 찾아내는 것을 확인할 수 있다.
 
# Fast R-CNN
![image](https://github.com/leexera/leexera.github.io/assets/122149118/aa9bf6c0-fd07-40b5-b6da-b4670412390b)
 * A fast version of R-CNN
    - 9x faster in training and 213x faster in testing than R-CNN
    - A single feature computation and ROI pooling using object proposals
    - Bounding box regression into network
    - Single stage training using multi-task loss

 Fast R-CNN은 말 그대로 R-CNN의 조금 더 빨라진 version이라고 할 수 있다.
 training time때는 9배가 빨라지고, testing time때는 213배가 빨라졌다.
 inference time때는 gradient update를 하지 않기 때문에 gradient를 model에 저장하지 않아도 되어 훨씬 더 빨라지는 것이고 training time때 빨라지는 이유는 feature computation을 single한 CNN으로 만들고 object proposal을 resize하지 않아도 input을 넣을 수 있도록 Region Of Interest pooling이라는 기법을 제안한다.
 network안에 bounding box regression을 포함시켜 원래 외부에서 수행하던 bounding box regression을 한 번에 수행하게 된다.
 multi-task loss, 즉 classification loss와 regression loss를 한 번에 주어서 multi-task training을 수행한다.
 이전에는 2-stage로 나누어져 bounding box regression을 통해 bounding box를 찾는 regrion proposal method를 먼저 학습하고 그 다음 단계에서 classification을 따로 수행했다면 이 것들을 한 번에 같이 수행한다는 것이다.
 위 figure와 같이 input에 image를 넣고 Region Of Interest를 여러 개 찾아 projection시켜 image에 넣는다.
 각 RoI들에 대해 feature map들을 다 같은 size로 조정하는 RoI pooling을 수행하게된다.
 그 이후 fully connected layer를 몇 개 통과시키고 fully connected layer로 찾아진 feature를 또 하나의 FC layer를 통과시켜서 softmax로 classification을 수행하고 bounding box regressor로 좌표들이 어디를 잡아야하는지 region proposal들, RoI들이 얼마나 이동해야 하는지 regression을 수행한다.
 
 * RoI pooling in details
    - Conceptual illustration
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/9d76c9b1-9b00-4eb1-81e2-b1117e0ad830)
    - The resolution of pooled feature maps is 7X7 in practice
    - An advanced version of RoIpooling: RoI align

 이 논문의 main contribution이라고 볼 수 있는 것이 2-stage로 바꾼 것도 있지만, RoI poolig을 꼽을 수 있다.
 빨간색 box는 box들의 중점들을 나타내는데, 이것을 찾아야 할 때 검은색 영역들을 사각형으로 쪼갠다.
 즉, 영역들에 대해 따로따로 pooling을 하는 것이다.
 각 사각형들은 하나의 kernel size를 가진 feature sliding window는 잡아낼 수 없었는데 영역들에 대해서 서로 다르게, adaptive하게 각 size별로 하나의 영역으로 pooling을 하도록 적응형으로 pooling을 적용하는 것이 RoI pooling이다.
 cell-wise로 pooling을 적용하는 것이다.
 기존의 max pooling과 average pooling을 생각해보면 모두 같은 size의 kernel size로 pooling을 수행하는데 그것과 달리 각 영역과 상관없이 cell에 대한 pooling을 한다는 것이다.
 pooled feature의 최종적인 feature map은 7 by 7로 사용하게 된다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/e670c3b6-7e84-4f53-8701-4a133898d58b)
 위 영역의 size를 말한다.
 추후에 mask R-CNN이라는 논문에서 RoI pooling이 정수 영역으로만 좌표들이 잘리게 되므로 정수가 아닌 실수값도 coordinate값으로 포함할 수 있도록 align이라는 것을 수행하는 것을 제안한다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/03c39f34-bd17-43cf-bf28-ee997a3a7d11)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/2cdb8eaf-5021-4ce8-a682-f2ec6e7ef441)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/e17a6a18-8200-4626-a7f3-3ad450461879)
 기존의 R-CNN BB를 사용한 결과보다 VOC 2007 test set에서 더 좋은 결과를 낸다.
 train set을 07만 썼을 때 또는 difficult of object를 빼고 training을 했을 때 성능이 더 올라가는 것을 확인할 수 있다.
 너무 어려운 object들은 object detection에 도움이 안되기 때문에 빼고 하는 것이 성능이 올라갈 수 있다는 것을 주장하여 train set에서 빼게 된 것이다.
 Pascal VOC 2007과 2012 data를 같이 포함시켜 학습했을 때 가장 높은 mAP 결과를 보여준다.
 두 번째 figure는 model size에 따른 inference time과 같은 결과를 나타내고 있다.
 model train time에 대해 train speedup이 최대 18배까지 빨라지는 결과를 볼 수 있다.
 test rate는 image 한 장 당 걸리는 시간으로 Small model이 0.10초로 거의 1초에 10장까지도 볼 수 있는 아주 높은 성능 향상을 보인다.
 test time speedup이 R-CNN에 비해 98배나 높아진 것을 확인할 수 있고 SVD, Singular Value Decomposition을 사용한 방법으로 169배가 빨라진 성능을 보인다.
 SVD를 사용했을 때 mAP향상도 크다는 것을 알 수 있다.
 Fast R-CNN의 classifier를 SVM, 즉 sigmoid를 사용한 결과와 softmax를 사용한 결과를 비교한 표로 softmax로 학습을 하고 evaluation을 했을 때 softmax가 모든 model에서 조금 더 학습이 뚜렷하게 잘 되었다는 것을 알 수 있다.
 위와 같은 engineering을 참고했을 때 요즘 softmax plus entropy loss를 많이 사용하고 있는 것에 대한 토대로 볼 수 있다.




