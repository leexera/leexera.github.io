---
layout: post
title: "Linear Classification"
description: "이화여자대학교 강제원 교수님(Electronic & Electrical Engineering)"
date: 2023-02-24
tags: study
comments: true
---

Supervised Learning의 한 종류인 Linear Classification에 대해 살펴본다.
classification은 model의 출력이 disvrete한 값을 가지게 된다.
문제에서 입력의 category를 결정하고 분류하기 위해서 data set에서 입력과 정답으로 구성된, 즉 label이 있는 data set을 사용하게 된다.

---

# 지도 학습

## Linear classification

 * Predict a discrete output <i>y</i> (classification ID) from <i>x</i> when <i>D = (x, y)</i> is given
    - ID = 0 or 1 (binary classification)
    - ID = 0, 1, ..., N - 1(multi classification)

 * Hypothesis set Η : a set of lines
 > <i>h<sub>w</sub>x = w<sub>0</sub> + w<sub>1</sub>x<sub>1</sub> + ... + w<sub>d</sub>x<sub>d</sub> = w<sup>T</sup>x</i>
 ###### <i>w</i> : model parameter (learnable parameter)
 > <i>h<sub>w</sub>x = w<sub>0</sub> + w<sub>1</sub>Φ(x<sub>1</sub>) + ... + w<sub>d</sub>Φ(x<sub>d</sub>) = w<sup>T</sup>Φ(x)</i>
 ###### Linear model witha set of features

 **Hyper plane(decision boundary)**

 ![image](https://user-images.githubusercontent.com/122149118/221138126-25043da0-a7c6-43fd-87c4-982edf013600.png)

 Linear classification 역시 linear regression model과 같이 위 수식과 같은 linear model을 사용한다.
 linear model이란 hypothsis 함수 H가 입력 feature와 그에 해당하는 parameter set에 linear combination으로 구성이 되는 model을 의미한다.
 이 식에서 w는 model parameter를 의미하고 x는 입력 feature를 의미한다.
 linear regression에서와 같이 입력 feature와 θ를 d + 1, dimensional한 vector로 구성하게 된다.
 이렇게 구성한 linear model같은 경우 입력 feature의 coordinate에서 hyper plane으로 사용하게 된다.
 위의 그림에서 점선으로 표시한 직선이 현재 2차원 coordinate를 구분하게 되는 Hyper plane이라고 할 수 있다.
 이 그림에서 positive sample은 함수 h(x)에 positive sample을 입력하였을 때 이 값이 0보다 크게되면 positive sample이라고 결정할 수 있다.(h(x) > 0)
 반대로 negative sample 역시 h(x)에다가 입력을 넣었을 때 이 값이 0보다 작다면 negative sample로 구성할 수 있다.(h(x) < 0)
 이러한 hyper plane은 어떠한 방정식을 가지게 되는가?
 이 식은 h(x)가 0인 식이 될 것이다.(h(x) = 0)
 우리의 목적은 이러한 hyper plane을 구해 data set에 있는 positive sample과 negative sample을 linear combination에 의해서 구분을 하는 것이 목적이 된다.
 linear regression에서와 같이 linear model이 갖는 여러 장점, 즉 단순하며 해석 가능성이 있고 다양한 환경에서 일반적으로 안정적인 성능을 제공할 수 있게 된다.

## Example: image recognition

 ![image](https://user-images.githubusercontent.com/122149118/221142228-8761775d-d686-44f5-ad73-cf614cbaaaaf.png)

 multiclass classification의 문제를 보인다.
 Binary classification과 비슷하지만 약간 다른 점은 입력 신호 공간에서 hyper plane이 다수 존재하여 classification을 수행한다는 것이다.

## Problem formulation

 * X = R<sup>d</sup> is an input space
    - R<sup>d</sup> : a <i>d</i>-dimensional Eucildean space
    - input vector <i>x</i> ∈ <i>X</i>: <i>x</i> = (x<sub>1</sub>, x<sub>2</sub>,..., x<sub>d</sub>), e.g. <i>d</i> = 2
 * Y = {+1, -1} is an output space
    - Binary (yes/no) decision
 * Now, we want to approximate a target function <i>f</i>
    - <i>f</i> : <i>X → Y</i> Unknown ideal function)
    - Data (x<sup>1</sup>, y<sup>1</sup>), ..., (x<sup>N</sup>, y<sup>N</sup>) ; dataset where y<sup>N</sup> = <i>f(x<sup>N</sup>)</i>
    - Correct label is ready for a training set
    - <u>**Hypothesis**</u> <i>h: **X → Y**</i> (ML model to approximate <i>f</i>) : <i>h ∈ **Η**</i>

 앞에서 언급한 문제를 조금 더 정형화하고 일반화한다면 위와 같이 표현 가능하다.
 앞의 문제에서는 예시로 2차원 공간에서의 문제를 정의했지만, 일반적으로 d차원의 공간에 입력 feature vector가 있다고 할 수 있다.
 이 때 출력은 binary classification의 문제인 경우 0아니면1, 즉 yes or no 문제라고 생각할 수 있다.
 앞서 설명한 바와 같이 target function f를 approximation하는 hypothesis h를 학습하는 것이 목적이다.

## Linear classification framework

 **Hypothesis function to build a decision boundary**

 ![image](https://user-images.githubusercontent.com/122149118/221147384-09957081-e5d6-43f7-afde-417d6956e2ff.png)

 linear classification은 그림에서와 같이 decision boundary의 정확한 추정을 통해서 주어진 입력에 대해 출력의 분류를 수행하는 문제가 된다.
 training data set에서 주어진 입력과 출력상으로 선형의 boundary를 학습하게 되고 그로부터 입력 feature가 hyper plane으로부터 어느 위치에 있는지를 결정하게 된다.
 예를 들어 새로운 입력 (2, 0)이 들어왔을 때 이 point는 h(x)가 0보다 작은 곳, 즉 -1을 출력하기를 기대한다.
 이러한 관계식은 (2, 0)을 넣으면 -1의 label이 나오도록 classifier h를 학습을 함으로써 기대할 수 있다.
 이러한 목표를 위해 다음과 같은 과정이 필요하다.
 ![image](https://user-images.githubusercontent.com/122149118/221149071-1fb1021a-e31b-496b-b2b8-ed6a20612f5b.png)
 어떤 predictor를 이용할 것인가를 결정하고 model parameter를 fitting하기 위한 loss function은 어떻게 설정하는가이다.
 linear regression 문제에서는 MSE를 사용한다.
 하지만 classification을 사용하는 loss는 Zero-one loss, Hinge loss, Cross-entropy loss와 같은 다른 종류의 loss function을 사용하게 된다.
 다음으로 어떻게 parameter를 최적화하는지 역시 고려해야한다.
 gradient descent algorithm을 사용해야 한다.
 앞선 예시를 수식을 통해 조금 더 정확하게 표현한다.

## Linear classification model

 * The linear formula <i>g ∈ **H**</i> can be wrtten as

 ![image](https://user-images.githubusercontent.com/122149118/221150503-128556e4-dcba-4ae1-b990-953e37cfb95a.png)
 ###### <i>w<sub>0</sub> : a bias term</i>
 ###### <i>x<sub>0</sub></i> : 1

 ![image](https://user-images.githubusercontent.com/122149118/221150715-079a17c9-9a2e-4735-9d38-b6ead9c7425a.png)

 <i>h(x) = w<sub>0</sub> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> = 0</i>

 ![image](https://user-images.githubusercontent.com/122149118/221151069-5846544b-70ab-4e8a-8d33-9fb4cdae379b.png)

 입력 변수와 parameter의 곱으로 먼저 score를 계산한다.
 이 때 w<sub>0</sub>는 bias 또는 offset값이다. 
 마찬가지로 입력 feature와 parameter는 d + 1 dimensional의 vector가 되게 된다.
 score 값을 계산을 한 이후에는 그 출력에 sine 함수를 적용하게 된다.
 sine 함수는 내부의 있는 값이 음이면 -1, 0이거나 양이면 1을 출력하는 함수이다.
 그림에서는 예시를 보여준다.
 h(x)는 1차 선형 함수로 구성된 hypothesis이고 그 기준을 중심으로 왼쪽은 h(x)가 0보다 큰 positive sample을 정의하게 되고 오른쪽은 h(x)가 0보다 작은 negative smaple을 정의하게 된다.

## Example of linear classifier

 ![image](https://user-images.githubusercontent.com/122149118/221152098-b2c6bc04-1812-490a-be0d-229fd22bb186.png)

 hyper plane의 parameter w<sub>1</sub>과 w<sub>2</sub>이 각각 -1과 1이라고 생각하면, 이 때 0과 2의 새로운 입력 값이 들어올 경우에 이 model은 어떻게 sample을 판별할 것인가?
 바로 [-1, 1], [0, 2]를 내적을 한 값을 계산하게 되면 이 함수에 있는 내부의 값은 2가 된다.
 여기에 sine 함수를 취하게 되면 이 값은 1을 출력하게 된다.
 그래서 이 hypothsis에 의해서 이 decision boundary에서 model은 이 좌표를 positive sample로 분류로 한 결과가 된다.
 반대로, 같은 model을 활용하기 때문에 decision boundary가 [-1, 1]인 hyper plane을 이용해 [1, -1]을 분류해보면 [1, -1]같은 경우 지금 현재 푸른색의 point로 결정되어있고 이 때 model, 즉 model parameter가 [-1, 1]을 갖게 되는 plane과 비교했을 때 그 결과값이 -1로 negative sample로 잘 분류되었음을 알 수 있다.
 이 함수에 들어가는 입력 score, 즉 w<sup>T</sup>x의 값은 이 score 값이 커지게 되면 이 h(x)로 부터 해당하는 좌표까지의 거리가 커지는 것을 알 수 있다.
 각 점에서 h(x)의 projection을 수행했을 때 두 점은 같은 거리에 있음을 살펴볼 수 있다.
 graph에서는 예컨데 푸른색의 점을 현재 hyper plane에 projection을 한 곳과의 거리와 지금 노란색에 있는 point를 projection했을 때 hyper plane까지 닿는 거리가 같은 것을 알 수 있다.
 바로 score 값이 동일하기 때문이다.
 
 원래 다시 풀고자하는 문제로 돌아오면 문제는 parameter w를 학습하는 것이다.
 w가 바뀜에 따라 sample들의 판별 결과가 당연히 바뀔 것이다.

## Hypothesis class : which classifier?

 <i>h(x) = sign([-1, 1][x<sub>1</sub>, x<sub>2</sub>]<sup>T</sup>)</i>
 <i>h(x) = sign([0.5, 1][x<sub>1</sub>, x<sub>2</sub>]<sup>T</sup>)</i>

 <i>h(x) = w<sub>0</sub> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> = 0</i>

 ![image](https://user-images.githubusercontent.com/122149118/221157458-b8c317f0-bd65-40fd-87a5-df448981f173.png)

 예를 들어 w<sub>0</sub>와 w<sub>1</sub>이 [-1, 1]이면 sample을 바로 판별하겠지만 [0.5, 1]이면 현재 그림에서 보라색 선과 같은 hyper plane이 그려지게 되고 이 때에는 오류가 발생하게 된다.
 일부 positive sample을 negative sample로 판별하게되는 것이다.
 regression에서도 이러한 model 오류가 parameter에 의해서 함수 꼴로 나타냈던 것을 기억해야 한다.
 🔍 Classification 문제에서는 Error를 어떻게 판단할 수 있는가?
 ➡ 하나의 예시로 Zero-One Loss를 생각할 수 있다.
 이 loss는 내부의 logic을 판별하여 맞으면 0 틀리면 1을 출력하는 함수이다.
 
 **For optimization**
 **Define a metric and compute an error**
 
  Loss<sub>0-1</sub> = 1[<i>f<sub>w</sub></i>(x) ≠ <i>y</i>] **zero-one loss**
  Loss([0, 2], 1, [0.5, 1]) = 1[sign([0.5, 1] · [0, 2] ≠ 1)] = 0
  Loss([-2, 0], 1, [0.5, 1]) = 1[sign([0.5, 1] · [-2, 0] ≠ 1)] = 1
  Loss([1, -1], 1, [0.5, 1]) = 1[sign([0.5, 1] · [1, -1] ≠ 1)] = 0

 위 수식은 zero-one loss를 계산하는 과정이다.
 1로 표현한 이 함수를 zero-one loss function이다.
 내부에 들어가는 값은 [0.5, 1]과 [0, 2]를 내적했을 때 이 때 값은 1과 다른 것을 알 수 있다.
 따라서 1은 zero-one loss가 된다.
 [0.5, 1]과 [0, 2]를 내적을 한 값을 sign을 취했을 때 나타나게 되는 값은 바로 1임을 알 수 있다.
 1 과 1이 서로 다르다라고 하는 logic을 판별하게 되면 False인 것을 알 수 있다.
 False이기 때문에 결과값으로 0을 출력한다.
 즉 loss가 0이 되게 되는 것이다.
 model이 classification을 수행하는 동안에 score 값을 이용해서 판별한다는 것을 알았다.

## Score and margin

 * Input data : <i>x</i>
 * Predicted label : <i>h(x) = sign(w<sup>T</sup>Φ(x))</i>
 * Target label : <i>y</i>
 
 > ✔ Score : the score on an example <i>(x, y)</i> is <i>w · Φ(x)</i>, how **confident** we are in prediction + 1
 ✔ Margin : the margin on an example <i>(x, y)</i> is <i>(w · Φ(x))y</i>, how **correct** we are.

 이 score 값은 결정 과정에서 model이 얼마나 confident한지를 측정할 수 있다.
 이와 유사하게 margin이라고 하는 것은 다음 수식에서와 같이 score에 y 값을 곱하여 계산하게 된다.
 (w · Φ(x))y는 앞에 w와 Φ(x)를 곱한 것은 model의 confidence를 의미하는 score라고 이해할 수 있다.
 이 때 y를 같이 곱한다고 하는 것은 y가 만약 1인 경우 그리고 score 값이 positive real 값인 경우에는 이 margine이 굉장히 커지게 될 것이다.
 score가 +라고 하는 것은 model prediction이 positive sample을 의미한다고 이야기 할 수 있다.
 즉, y가 1인 경우는 정답을 맞혔다고 이야기할 수 있는 것이다.
 그 때에는 margin 값이 굉장히 늘어나게 된다.
 또한 마찬가지로 score 값이 -이면서 y가 동시에 -1을 갖게 되는 것 역시 score가 -이기 때문에 negative sample로 판별하게 되고 y가 -1이기 때문에 정답을 맞혔다고 생각할 수 있다.
 둘의 값을 곱하게 되면 마찬가지로 강한 positive 값을 산출하게 된다.
 이 역시 margin 값이 굉장히 증가한다고 볼 수 있게 되는 것이다.
 하지만 반대의 경우도 존재한다.
 score가 만약에 -값을 가지게 됐고 y가 +1을 가지게 되는 경우이다.
 score가 -라고 하는 것은 model이 negative sample을 예측하였다는 것이지만 y가 1이다라고 하는 것은 정답이 1이었다, 즉 positive sample이었다는 것이다.
 이 두 개의 값을 곱하게 되면 margin이 -값을 가지게 되고 model prediction이 실패했다는 것을 의미한다.
 마찬가지로 score가 +이면서 y가 -1인 경우도 유사한 경우라고 생각할 수 있다.
 이러한 zero-one loss를 gradient descent algorithm에 적용하려면 이 loss function의 partial derivative term을 구해야 한다.

## Zero-one loss

 ![image](https://user-images.githubusercontent.com/122149118/221162673-100f19eb-0d4d-4073-b364-793d11c62e3b.png)

 ![image](https://user-images.githubusercontent.com/122149118/221162750-e3106277-c091-41ac-b3fc-aa877c6d4649.png)
 Gradient is zero almost everywhere!

 The goal is to minimize the loss
 To run gradient descent, compute the gradient:
 ![image](https://user-images.githubusercontent.com/122149118/221163537-c75d6969-6dd7-4d2f-9617-3d0ade7ab385.png)

 그러나 이 함수의 미분 결과는 gradient가 0이 된다.
 gradient가 0이 되면 model이 학습을 할 수 없는 문제가 생기게 된다.
 이러한 문제를 해결하기 위하여 classification에서는 hinge loss를 사용한다.

## Hinge loss

 **Loss<sub>hinge</sub>(<i>x, y, z</i>) = max{1 - (w · Φ(x))y, 0}**

 * Zero loss if it is classified confidently and correctly
 * Misclassification incurs a linear penalty w.r.t confidence

 ![image](https://user-images.githubusercontent.com/122149118/221761117-e86c7df3-866a-43a5-8e49-b3af597b1899.png)

  Hinge loss의 함수는 max값을 취하게 되는데, 1 - (w · Φ(x))y, 0 두 값 중에 가장 큰 값을 고르게 된다.
 만약 margin 값이 크다고 하면 즉, model이 정답을 잘 맞추고 있다고 한다면 1 - (w · Φ(x))y의 값은 negative 값을 가질 것이다.
 graph 상에서 y축이 0인 값을 나타내게 될 것이다.
 이 경우에는 강한 minus 값과 0와의 max값을 취하기 때문에 이 때 loss 값은 0을 가진다.
 반대로 (w · Φ(x))y값이 음의 값을 갖게 되어 1 - (w · Φ(x))y 값이 +값이 된다고 하면 max값은 margin 값에 선형적으로 비례하여 증가한다고 볼 수 있다.
 이에 대해서 loss 역시 선형적으로 증가하게 되는 함수를 가지게 된다.

 ![image](https://user-images.githubusercontent.com/122149118/221761199-7f5648be-bd13-408c-8be0-6c3acab310e7.png)

 (w · Φ(x))y 값이 1보다 작게 되면 -Φ(x)y 값이 되고 margin값이 충분히 크다면 gradient가 0이될 것이다.

## Cross-entropy loss

 * Considers two probability mass functions (pmf) {p, 1 - p} and {q, 1 - q} with abinary outcomes
 * Cross entropy for these two pmfs : defined by

 cross-entropy loss는 classification model을 학습할 때 가장 많이 사용하는 대표적인 loss function이다.
 이 함수의 원형은 정보 뉴런에서 두 개 서로 다른 pmf를 가지는 확률 함수 사이에 가까운 정도, 또는 서로 다른 정도를 측정하기 위한 이른바 K-L divergence에서 표현이 된다.

 ![image](https://user-images.githubusercontent.com/122149118/221764400-8887df40-0d7f-449f-b34f-04adb9bdc33f.png)

 ![image](https://user-images.githubusercontent.com/122149118/221763467-ff257f5e-2b9b-418e-85e3-cf17d868976a.png)
 위 식에서 왼쪽 항은 relative entropy라고 하는 값으로 이 값은 p에 대한 entropy,H(p)에 K-L divergence값을 더해서 얻게 된다.
 이 때 entropy(H(p))값은 변하지 않기 때문에 왼쪽에 있는 수식은 K-L divergence에 의해서 값이 바뀐다.
 ![image](https://user-images.githubusercontent.com/122149118/221763628-ec45e601-f5e9-491e-b39e-dcd4cb3844b1.png)
 K-L divergence 함수 D는 위와 같이 표현한다.
 이 때 K-L divergence는 두 개의 서로 다른 pmf의 차이이다.

 * Cross entropy measures the error when approximating an observed pmf {p, 1 - p} between a fitted pmf {q, 1 - q}

 즉, cross-entropy 역시 두 개의 서로 다른 pmf p와 q가 서로 유사한지, 그렇지 않은지 정도에 따라서 error의 정도가 바뀌게 된다.
 만약 p와 q가 서로 유사하다면 이 loss는 줄어들게 될 것이고, 서로 굉장히 다르다면 이 loss는 커질 것이다.

 문제는 지금까지 계산한 model의 score 값은 실수 값이라는 것이다.
 cross entropy 값은 확률 값을 서로 간에 비교 하게 된다.
 🔍 계산한 Score 값은 어떻게 이러한 확률 값으로 Mapping할 수 있는가?
 ➡ fitting을 하고자 하는 label은 1또는 0인 값이 되게 되는데 score는 실수 값이기 때문에 그 실수 값을 확률 함수를 통해서 mapping을 해야 된다고 생각할 수 있다.
 mapping에 사용하는 함수가 sigmoid함수이다.

 Real value <i>h = w<sup>T</sup>Φ(x)</i> 0 or 1
 ![image](https://user-images.githubusercontent.com/122149118/221765368-021663ac-db9d-44f7-bced-26c5e03a4f5f.png)

 ![image](https://user-images.githubusercontent.com/122149118/221765463-5620cf50-7482-4c6f-8eb6-87d8752466d0.png)

 ![image](https://user-images.githubusercontent.com/122149118/221765524-e0b5dd65-63fc-48ec-ba79-3036ed524770.png)
 σ(z)라고 하는 함수가 sigmoid함수로서 이 함수는 s curve와 같은 형태를 가지고 있다.
 이 함수의 개형을 살펴보게 되면 만약에 + 방향으로 real 값이 굉장히 증가하게 된다면 확률 값 1에 근사하게 될 것이며, 반대로 - 값으로 굉장히 커지게 된다면 확률 값 0에 근사하게 될 것이다.
 반대로 0의 값을 가지게 되면 이 값은 ½의 확률을 갖는 함수가 된다.
 계산한 score 값 즉, h(x)는 w<sup>T</sup>Φ(x)의 값을 sigmoid 함수에 집어넣게 되면 score 실수 값을 0부터 1 사이의 값으로 mapping을 할 수 있게 될 것이다.
 그러한 형태를 logistic model이라고 이야기 한다.

## Sigmoid function

 * Squash the output of the linear function
    σ(-w<sup>T</sup>x) = <sup>1</sup>/<sub>1 + e<sup>-w<sup>T</sup>x</sup></sub>
 * A better approach : interpret as a probability
    <i>P<sub>w</sub></i>(y = 1|x) = σ(-w<sup>T</sup>x) = <sup>1</sup>/<sub>1 + e<sup>-w<sup>T</sup>x</sup></sub>
    <i>P<sub>w</sub></i>(y = 0|x) = 1 - σ(-w<sup>T</sup>x) = <sup>e<sup>-w<sup>T</sup>x</sup></sup>/<sub>1 + e<sup>-w<sup>T</sup>x</sup></sub>
 sigmoid함수는 score 값을 0에서 1 사이의 값으로 눌러주기 위하여 사용하게 된다.
 만약 y가 1이면 즉, positive sample에 대해서는 확률 값이 <sup>1</sup>/<sub>1 + e<sup>-w<sup>T</sup>x</sup></sub>으로 계산된다.
 반대로 y가 -1인 경우 negative sample에 대해서는 확률에 대한 값이 <sup>e<sup>-w<sup>T</sup>x</sup></sup>/<sub>1 + e<sup>-w<sup>T</sup>x</sup></sub>으로 결정된다.

## Cross-entropy loss

 ![image](https://user-images.githubusercontent.com/122149118/221767630-dee8c07d-ecd2-493e-8d66-631071124eb7.png)

 왼쪽에는 Y(bar) 즉, estimated된 확률 값이 sigmoid함수를 통해서 산출된 값을 보이고 있다.
 이 때 첫 번째 vector에 해당하는 0.7, 두 번째 0.2, 세 번째 0.1은 각 3차원 공간상에서의 해당하는 값을 확률적으로 표현한 값이다.
 실제 label 값은 마찬가지로 3차원 공간에서 1.0, 0.0, 0.0과 같은 좌표 공간에 표현되어 있다.
 즉, 첫 번째 category에 1로 표현되어 있는 어떠한 classification id를 표현한다고 생각할 수 있다.
 오른쪽에서 볼 수 있는 것처럼 1과 0으로 구성되어 있지만 이 값들 역시 총 합이 1인 확률(∑y<sub>i</sub> = 1)이라고 생각할 수 있다.
 어떤 label은 강하게 1이고, 어떤 label은 강하게 0인 그런 함수가 되는 것이다.
 왼쪽에 있는 estimation 역시 오른쪽에 있는 label 정보를 추정하게끔 값이 산출하게 된다.
 만약 model이 더욱 정확해진다면 이 값은 1, 0, 0에 가까워지도록, 예컨데 0.9, 0.1, 0 점점 더 값이 update가 되게끔 cross entropy loss가 줄어들게 될 것이다.
 corss entropy loss는 서로 다른 p와 q의 pmf의 거리이다.
 오른쪽에는 1, 0, 0의 값을 갖는 확률이라고 한다면 왼쪽은 그에 유사하게끔 새로운 loss 값을 update를 해나아가면서 학습이 진행되게 된다.

 **Understanding this Cost Function**
 Suppose that <i>L</i> = [1, 0, 0],
 * If Y(bar) = [1, 0, 0], then D = -1 · log 1 - 0 · log 0 - 0 · log 0 = -1 · 0 - 0 · (-∞) - 0 · (-∞) = 0 (no cost)
 * If Y(bar) = [0, 1, 0], then D = -1 · log 0 - 0 · log 1 - 0 · log 0 = -1 · (-∞) - 0 · 0 - 0 · (-∞) = ∞ (huge cost)
 * If Y(bar) = [0, 0, 1], then D = -1 · log 0 - 0 · log 0 - 0 · log 1 = -1 · (-∞) - 0 · (-∞) - 0 · 0 = ∞ (huge cost)

 loss function에 label 정보가 현재 1, 0, 0인 경우에 Y(bar)가 위와 같은 경우의 값을 가질 때 어떠한 loss를 갖는지 살펴본다.
 만약 Y(bar)가 [1, 0, 0]이라고 한다면 정확하게 우리의 label값과 동일하다고 생각할 수 있다.
 이 경우에는 굉장히 작은, cost가 없는, loss가 없는 형태가 되지만, 반대로 label 정보가 다른 [0, 1, 0]의 값을 맞추고 있다면 이 때 loss는 마찬가지로 산출을 해보면 ∞로 굉장히 높은 cost를 가지게 될 것이다.

 **Gradient Descent Method**
 > <i>W ← W - α<sup>∂</sup>/<sub>∂W</sub>CE</i>

 이렇게 얻게된 loss의 값들은 gradient descent algorithm에 의해서 cross entropy의 loss term을 이용하여 새로운 parameter W를 update하는데 사용한다.

## Training a linear classifier

 linear classifier를 학습하는데 실제 gradient descent algorithm이 어떻게 사용이 되고 있는지에 대한 방식을 본다.

 * Iterative optimization using gradient descent
    1. Initialize weights at time step <i>t = 0</i>
    2. Compute the gradients
    ![image](https://user-images.githubusercontent.com/122149118/221772949-52a83dd2-d9d0-4ed5-b019-8a525fba53c7.png)
    3. Set the direction to move : 
       <i>v<sub>t</sub> = -∇E<sub>train</sub>(w<sub>t</sub>)</i>
    4. Update weights
       <i>w<sub>t + 1</sub> = w<sub>t</sub> + αv<sub>t</sub></i>
    5. Iterate to next step until converging

 gradient descent algorithm의 framework와 상당히 유사한 것을 볼 수 있다.
 먼저 weigh값을 initialization한다.
 그 다음엔 gradient 값을 계산해야 한다.
 이 때 필요로 하는 값은 cross entropy loss 즉,train loss의 미분 term이 되게 되는 것이다.
 새로운 parameter w<sub>t</sub>는 α에다 새로운 update term v<sub>t</sub>을 곱하게 되어 새로운 w<sub>t + 1</sub>을 얻게 된다.
 이러한 방식으로 weight를 update 해 나가면서 수렴할 때까지 다음 단계로 계속해서 진행 하게 된다.

## Multiclass classification

 * Not all classification predictive models support multi-class classication.
 * Split the multi-clas classification dataset into multiple binary classification datasets and fit a binary classification model on each.

 ![image](https://user-images.githubusercontent.com/122149118/221775255-6c6e8024-11b8-4058-8a88-f07696671b21.png)

 위 예시는 임시 recognition 문제에서의 multi-class classification 문제에 대한 문제이다.
 입력으로 입력 image들이 다음과 같이 들어오게 될 때 이 입력 image들이 어떠한 label에 속하게 되는지 예컨데 cat인지, dog인지, mug인지, hat인지 각각의 category를 맞추는 문제라고 이해할 수 있다.
 이 역시 binary classification의 문제에서와 같이 n차원의 coordinate상에서 다음과 같이 signal space 상에서 입력 feature를 plotting한 다음 이 입력 feature들을 적절하게 구분지을 수 있는 hyper plane을 학습을 하면서 얻게 된다.
 어떠한 modle같은 경우에는 multiclass classification문제에서 바로 class id 값을 출력을 하는 경우들도 있지만 보통은 binary classification 문제를 multiclass classification문제로 확장을 하는 경우도 생각할 수 있다.

 **One-Vs-All**

 ![image](https://user-images.githubusercontent.com/122149118/221776509-46263841-ea8d-4840-8546-2239e61bcb59.png)

 그림에서 보는 바와 같이 3개의 hyper plane을 그어서 multiclass classification 문제를 binary class classification의 model로 하여금 풀 수 있게끔 할 수 있다.
 첫 번째 hyper plane은 C인지 그렇지 않은지를 구분하는 model이다.
 다음 binary classiciation model은 B인지 그렇지 않은지를 학습하게 되고, 또 다른 model은 A인지 그렇지 않은지를 판단하게 된다.
 그에 관한 학습 model들이 그림 아래와 같이 각각의 parameter w에 관해서 구성되어있다고 생각해보면 model A를 위한 parameter term을 w<sub>A1</sub>, w<sub>A2</sub>, label B를 위한 model parameter들을 w<sub>B1</sub>, w<sub>B2</sub>, 마찬가지로 sample C를 분류하기 위한 model parameter로써 w<sub>C1</sub>, w<sub>C2</sub>가 있다고 생각할 때 metrix를 연산하게 되면 각각 sample A, B, C의 score 값을 얻을 수 있게 된다.
 이렇게 얻게된 score 값들에 sigmoid함수를 사용하게 되면 확률 값으로 mapping을 할 수가 있게 된다.
 그리고 label을 지정하게 될 때 사용했던 One Hot Encoding을 이용하게 되면 두 개의 서로 다른 표 사이에 거리를 가깝게 하면서 학습을 할 수 있다.
 one hot encoding이라고 하는 용어는 전혀 다른 것이 아니라 앞서 보았던 multiclass classificaiton에서의 label을 지정하는 문제에서 각각 vector마다 [1, 0, 0], [0, 1, 0], [0, 0, 1]과 같이 해당하는 위치에 1을 signaling을 함으로써 label의 정보를 기록하는 것을 one hot encoding이라고 한다.
 ![image](https://user-images.githubusercontent.com/122149118/221778368-a657d354-e36b-49ca-97a9-3f2f65d5d53f.png)

 이렇게 one hot encoding된 label값과 그리고 sigmoid model이 출력하는 확률 값을 서로 간에 비교하여 loss function을 통해 error를 계산함으로써 학습을 할 수 있게 된다.

## Advantage of liear classiciation

 * Simple
 * Interpretability (example in Murphy 2012)
    - x<sub>1</sub> : the number of cigarettes per day, x<sub>2</sub> : minutes of exercise per day
    - The goal is to predict <i>P(Y</i> = lung cancer<i>)</i>
    - Assume we have estimated the best parameter w = (1.3, -1.1) to have <i>h(x) = 1.3x<sub>1</sub> - 1.1x<sub>2</sub></i>
    → For every cigarettes per day, the risk increased by a factor of e<sup>1.3</sup>
    <i><sup>p(y = +1|x)</sup>/<sub>p(y = -1|x)</sub> = e<sup>w<sup>T</sup>x</sup> = e<sup>w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub></sup></i>

 linear classification model의 장점 역시 linear regression model에서의 장점과 비슷한 장점들이 여럿 있다.
 예를 들어 linear classification model과 같은 경우는 대단히 간단하다는 장점이 있다.
 간단하다고 하는 것은 쉽게 구현할 수 있고 쉽게 test할 수가 있다고 하는 것이다.
 따라서 Linear Classification Model은 가장 처음에 시도하기에 적합한 형태의 model이라고 할 수 있다.
 두 번재로는 intergretability 즉, 해석 가능성 역시 상당히 증가한다고 볼 수 있다.
 예를 들어 하루에 피는 담배의 개수를 x<sub>1</sub>이라고 기록하고, 하루에 운동하는 시간을 x<sub>2</sub>라고 기록한다.
 그리고 목적은 이 사람이 폐암을 가지게 될지 아닐지를 예측하는 model을 수립한다고 생각한다.
 이 예측 model의 결과 추정한 best parameter w는 1.3과 -1.1 즉, hyper plane model인 h(x)가 1.3x<sub>1</sub> - 1.1x<sub>2</sub>라고 이해한다.
 날마다 담배를 피는 경우 risk를 계산 해본다면 확률 값에 의해서 given x에 대해서 폐암일 확률과 폐암이 아닐 확률의 비율을 계산해보면 위와 같은 수식을 얻을 수 있다.
 이 때 w<sup>T</sup>x가 바로 hyper plane w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub>가 된다.
 이 식을 통해 계산을 해보면 담배의 위험성은 e<sup>1.3</sup>이다.
 이와 같이 각 요소 별로 요소가 1 단위 증가를 할 때마다 전체 score 값이 어떻게 변하게 되는지를 추정함으로서 해석 가능성을 제공할 수 있게 된다.

## Quiz

 **What answers are correct?**

 **A.** Ina linear classification model, a hyperplane is used for a decesion boundary to classify training samples, assuming samples are linearly separable.
 linear classification model에서는 hyperplane이 decesion boundary로 사용이 된다고 했을 때 samplee들은 선형적으로 separable하다라고 가정할 수 있다.
 **A. Correct** 

 ![image](https://user-images.githubusercontent.com/122149118/221785035-c51ed5ea-68cd-4f68-a168-4d73cb654b22.png)
 선형 model에서는 positive, negative sample들이 선형을 hyperplane에 의해서 선형적으로 구분이된다고 가정을하고 linear classification model을 수립하게 된다.

 **B.** Cross-entropy loss represents an error or a dissimilarity between two real values, and therefore it can be directly used to compute an error of a score value
 cross entropy loss가 error의 값을 표현하게 되는데 이 때 서로 다른 두 개의 실수값의 사이에 서로 다른 차이를 표현한다.
 **B. False** Cross-entropy loss measures a dissimilarity of two pmfs.
 A sigmoid function is first applied to convert a real value into a probability between 0 and 1, and the the loss is used to compute the error value.
 ![image](https://user-images.githubusercontent.com/122149118/221786334-306fafd7-19e7-4ec9-afff-1293f3a8efc3.png)
 cross entropy loss는 두 개의 서로 다른 pmf 사이에 dissimilarity를 측정하는 도구이다.
 따라서 임의의 실수값이 있다고 한다면 sigmoid 함수 등을 통해 확률 값으로 mapping을 한 뒤에 loss를 계산해야 한다.

 **C.** A binary linear classifier can be extended to a multiclass linear classifier
 binary linear classifier같은 경우 multiclass linear classifier로 확장이 가능하다.
 **C. Correct** A binary linear classifier can be extended to a multiclass classifier by applying an one-Vs-all classification per class, although a binary linear classifier ingerently estimates only true/false.
 ![image](https://user-images.githubusercontent.com/122149118/221787180-c2779658-22b0-44d7-ba93-b45e2f2978a1.png)
 이러한 방식을 One-Vs-All 이라고 해서 binary linear classifier를 여러 개 사용을 함으로써 multiclass classification문제를 해결할 수 있다.

## Summary

 * Linear classification model
    - Uses a hyperplane as a decision boundary to classify samples based on a linear combination of its explanatory variables
    - It has several advantages ; simplicity and interpretability
    - Cross-entropy loss measures the performance of a classification model whose output is a prbability value between 0 and 1.
    A sigmoid function is used to map a score value into a probability value.
    - Multi-classificatio problem can be solved through one-vs-all.

 hyperplane을 이용해서 decision boundary를 수립하게 되는데 이때 hyperplane은 바로 입력 변수와 parameter의 linear combination으로 구성된다.
 linear classification model 역시 몇 가지의 장점이 있다.
 첫 번째는 단순하며,두 번째는 해석 가능하다고 하는 것이다.
 이러한 linear classification model을 학습을 하기 위해서는 cross entropy loss 등과 같은 loss 함수를 사용하게 되는데 특히 cross entropy 함수같은 경우 대표적인 loss 함수로써 확률 값을 계산한 이후에 두 개의 서로 다른 확률 함수의 dissimilarity를 계산하여 그 error로 하여금 hyper plane을 학습한다.
 마지막으로 multi classification 문제는 one-vs-all과 같은 형태로 binary classification 문제를 확장하여 해결할 수 있다.