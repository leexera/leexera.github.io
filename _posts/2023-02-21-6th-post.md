---
layout: post
title: "SL Foundation"
description: "이화여자대학교 강제원 교수님(Electronic & Electrical Engineering)"
date: 2023-02-21
tags: study
comments: true
---

image, video 3차원 데이터와 같이 미디어를 구성하는 여러 가지 데이터에 대한 인공지능 algorithm 연구

최근에 우리가 즐기는 미디어는 주로 사람이 만들고 소모를 하였지만 요즘은 기계가 대신하고 있음. 
따라서 기존과 같이 사람의 소통 이외에도 사람과 기계, 기계와 기계 사이의 소통을 매개로 하는 미디어에 대한 연구

Supervised Learning의 기본 개념과 원리

Supervised Learning은 인공지능 모델의 정답과 학습 문제를 알려주어 새로운 문제에 대해 새롭게 답을 할 수 있는 학습 방식

---

# 지도 학습

## Learning from data

![image](https://user-images.githubusercontent.com/122149118/220206186-a7a5fe04-cacc-4322-bf11-3e8b73a0a3bc.png)

 * What is this animal?
    You would answer the question in few seconds

 * Will you need a zoological(mathematical) definition to distinguish it?
    Yes or **No**
 **We have learned a lot from data (pattern) despite being ignorant of a rigorous definition of a lion**

 이 동물이 무엇인지 물어보게 되면 즉각 사자라고 답을 하게 될 것이다.
 그런데 이 동물이 사자인지 어떻게 알게 되었는지 묻는다면 아마 대부분 동물학적으로 엄밀한 정의로부터 알게되었다기보다는 경험적으로 알게 되었다고 말을 할 수가 있을 것이다.
 선생님이나 부모님 또는 책에서 이 그림은 사자라고 계속해서 교육을 받게 되면 이후에도 네 발을 가지고 이빨이 날카롭고 그리고 목 주위에 갈기를 가진 것과 같은 패턴을 가진 동물은 사자임을 이해 하게 될 것이다.
 그리고 이후로도 비슷하게 지속되는 입력을 받는다고 한다면 계속해서 그 지식을 공고하게 가지는 학습 과정을 거치게 될 것이다.
 <mark>Machine Learning도 이와 같은 사람의 경험적인 학습 과정과 유사하게 data로 부터 내재된 패턴을 학습하는 과정이라고 할 수 있다.</mark>

## Machine learning problems

 1. Is it a spam mail or not?
 2. Image recognition
 ![image](https://user-images.githubusercontent.com/122149118/220376517-aaf61bb5-86a0-4415-ac34-7c1db82ee1a6.png)
 3. House prices

 주위에는 다양한 Machine Learning Task들이 있다.
 예를 들어 받은 메일이 스팸 메일인지 아닌지를 판단하는 문제라든가 아니면 입력 이미지를 이용해서 개인지 고양이인지 아니면 사자인지 등과 같이 수백 또는 수천 개의 카테고리 중에 하나로 분류하는 문제, 이러한 문제를 Image recognition 문제라고 한다.
 Image Recognition 문제는 ImageNet Large Scale Visual Challenge 등에서와 같이 최근에 Deep Learning 연구가 기존의 연구 방법 대비 컴퓨터 비전 등에서 대단히 우수한 성능을 제공한다는 상징적인 결과를 보이기도 했다.
 또 집값의 추이를 여러 환경적인 요인으로부터 예측을 하거나 통계적으로 분석하는 등의 문제 등이 있다.
 이러한 문제들은 고유한 Machine Learning 문제 중 하나이다.
 📌Machine Learning 문제
 > Binary Classification

 > Multiclass Classification

 > Regression

 Supervised Learning의 한 종류이다.
 Machine Learning은 여러 가지 학습 문제로 구분할 수 있다.

 ![image](https://user-images.githubusercontent.com/122149118/220401188-6e3f2ba7-cbd7-4408-91b3-220a130aef79.png)

 그 중에 대표적으로 Supervised Learning과 Unsupervised Learning으로 구분할 수 있다.
 이 중에는 물론 Reinforcement Learning이라고 하는 Machine Learning의 다른 종류의 학습 방식도 있지만 <mark>여기에서 Unsupervised Learning과 비교를 하여, Supervised Learning은 data의 label이 있다고 하는 것이 가장 큰 차이가 된다.
 Supervised Learning에는 Regression과 Classification 문제가 있으며 각각 출력이 연속 변수인지 이산 변수인지에 따라 구분을 하게 된다.</mark>

## Supervised learning

 Supervised Learning의 Data set 구성에 대해 알아본다.

 * Given a set of labeled examples (x<sup>1</sup>,y<sup>1</sup>),...,(x<sup>n</sup>, y<sup>n</sup>), learn a mapping function g : <i>X → Y</i>, such that given an unseen sample x', associated output y' is predicted.

 ![image](https://user-images.githubusercontent.com/122149118/220402567-abc0fd16-322d-4cf8-84ff-4f113498b0a3.png)

 Supervised Learning에서 사용하는 data sample은 입력 X와 출력 y의 쌍으로 구성되어 있다.
 <mark>이 때 출력 y를 label 또는 정답이라고 이야기 한다.</mark>
 예를 들어 오른쪽 아래 예시를 보면 각 이미지들이 입력 x로 사용 되고 있고, 이 그림에서의 cat, dog, mun 등과 같은 label 들이 출력 y로 사용 되고 있다.
 이러한 data set의 구성을 이용하여 달성하고자 하는 목적은 바로 <i>X → Y</i>로 가는 함수 h를 학습하는 것이다.
 즉, 새로운 입력(영상)이 들어왔을 때, 해당 영상의 category label을 맞추게 되는 그러한 함수 h를 학습을 하게 되는 것이다.

## Learning pipline

 Supervised Learning의 과정을 더 자세하게 도식화해서 본다.

 ![image](https://user-images.githubusercontent.com/122149118/220404787-27cba1bc-57de-4ed2-9d41-c80cae1a5a26.png)

 크게 두 가지 단계로 구분이 되어있다.
 첫 번째는 model의 training 과정이다.
 처음에는 model의 출력이 정확하지 않을 것이다.
 Machine learning model이 다음과 같은 출력을 제공하게 되면 현재 가장 초기 단계에서의 machine learning model은 정답을 정확하게 맞추지 못할 것이다.
 하지만 그 정답을 계속해서 machine learning model이 학습을 하는 과정이 표현되어 있다.
 machine learning model이 제공하는 답안을 무엇으로부터 교정을 할 수 있는가?
 가지고 있는 data set의 label 즉 가지고 있는 정답으로부터 Machine Learning model이 이 출력을 정확하게 맞추고 있는 것인지 그렇지 않은지에 대해서 알려주게끔 하는 것이다.
 그리고 Machine Learning model은 이러한 정답을 보다 더 정확하게 맞추게끔 model의 parameter 값을 변경해 나갈 수가 있을 것이다.
 이와 같이 Supervised Learning에서는 model output과 정답과의 차이인 error를 통해서 그 error를 줄여가면서 학습이 진행 되게 된다.
 바로 학습 sample의 label이 주어짐으로 가능한 일이며 이것이 바로 Supervised Learning의 기본적인 아이디어가 된다.
 이어서 두 번째 단계인 즉, test 단계에서는 model이 실제 환경에 적용되는 것을 의미하게 된다.
 이때는 training 단계에서 보지 못했던 새로운 입력 영상을 이용하게 된다.
 이 때 model의 정확도가 진정한 성능이 될 것이다.

## Example: family car

 Supervised Learning 문제의 formulation을 위해 family car를 분류하는 문제를 예시로 생각해본다.

 * Class <i>C</i> of a "family car"
    - Prediction is this car a family car?
 * Output:
    Positive (+) and negative (-) examples, or multi-class examples
 * Input representations:
    x<sub>1</sub>: price, x<sub>2</sub>: engine power
 ![image](https://user-images.githubusercontent.com/122149118/220407518-82b075cb-c812-4ea9-97a1-d3ed4f47a253.png)
 주어진 문제는 다양한 종류의 차량이 입력으로 들어오게 될 때 이 차량이 family car인지 그렇지 않은지를 분류하는 문제이다.
 이 때 차량 data의 입력 표현으로 차량의 가격과 엔진 파워를 고려한다.
 이러한 입력 표현을 입력 feature라고도 이야기 한다.
 입력 feature는 풀고자 하는 문제에 관하여 어느 정도의 domain knowledge를 알고 있어야 사용할 수 있기도 한다.
 즉, 차에 관해 지식이 전무하다면 이러한 classification 문제에서 효과적인 input feature를 도입하기 어려울 것이다.
 입력 feature의 design은 Machine Learning Engineer가 할 수도 있지만 관련 분야의 전문성을 가진 전문가와 함께 해결할 수도 있다.
 물론 최근의 Deep Learning model과 같은 경우는 이러한 feature 역시 스스로 학습하기 때문에 domain knowlege로부터 비교적 자유로운 편이다.

## Problem formulation

 차량 sample은 정의한 입력 feature에 의해 다음과 같은 좌표 공간에 표현이 가능하다.

 ![image](https://user-images.githubusercontent.com/122149118/220408900-58d9151f-b82b-427d-ac5b-9404d3e8dbb7.png)

 x축으로는 price 차량의 가격을 표시하게 되고 y축으로는 차량의 engine power를 표시하게 된다면 각각의 차량의 sample들을 우리가 xy coordinate 상에서 표현을 할 수 있게된다.
 그림에서 보는 바와 같이 (+) 표현이 되어 있는 것은 family car라고 categorization을 한 positive sampl이 되게 되는 것이고 (-)라고 표현을 하게 된 것은 familu car가 아닌 negative sample을 의미 하게 되는 것이다.
 앞서 언급한 문제를 조금 더 정형화하고 일반화한다면 다음과 같이 표현할 수 있다.
 앞의 문제에서는 예시로 2차원 공간에 문제를 정의했지만 보다 일반적으로 d차원의 공간에서 입력 feature vector가 있다고 할 수 있다.
 출력은 binary classification의 문제인 경우 yes 또는 no 문제이다.

 * X = R<sup>d</sup> is an input space
    - R<sup>d</sup>: a <i>d</i>-dimensional Euclidean space
    - input vector x ∈ X: x = (x<sub>1</sub>, x<sub>2</sub>,..., x<sub>d</sub>)
 * Y is an output space
    - Binary (yes/no) decision
 * Now, we want to approximate a target function <i>f</i>
    - <i>f</i>: <i>X → Y</i> (unknown ideal function)
    - Data (x<sup>1</sup>, y<sup>1</sup>),..., (x<sup>N</sup>, y<sup>N</sup>); dataset where y<sup>N</sup> = <i>f(x<sup>N</sup>)</i>
    - Correct label is ready for a training set
    - **<u>Hypothesis</u>** <i>g: X → Y</i> (ML model to approxivate <i>f</i>): <i>g ∈ **H**</i>
 Target function은 입력 x를 출력 y로 mapping을 하게되는 정답함수가 된다.
 하지만 이 함수는 동시에 달성하기 어려운 즉, 이상적인 함수가 된다.
 그 이유는 모든 입력 sample에 대해 family car인지 그렇지 않은지를 분류를하고 그 성능을 보장하기 위해서는 전 세계 모든 sample들을 다 관찰한 후에야 가능하게 될 것이다.
 그리고 model은 그러한 케이스에 대해서 모두 성공적인 결과를 달성해야한다.
 하지만 현실적으로 그것은 불가능한 일이다.
 다만 할 수 있는 것은 그 문제를 대표할 수 있지만 제한적인 숫자 예를 들어 보통 수백에서 수천의 sample로 구성되어 있는 dataset만을 활용하여 이러한 target function f의 근접한 함수를 만드는 것이 할 수 있는 일이다.
 이러한 함수를 hypothesis H라고 정의 한다.
 Machine Learning Model은 바로 이러한 함수의 역할을 하게 되는 것이다.

## Learning model

 ![image](https://user-images.githubusercontent.com/122149118/220413737-6e9f7d4a-7101-4da4-84d1-3f3c057fce06.png)

 🔍 hypothesis 함수의 학습 과정을 순서대로 보이고 있는 것이다. 단계별로 어떠한 요소를 고려해야 하는가?
 ➡ 우선 목적은 앞에서 이야기한 바와 같이 target function f를 모사하는 것이고, 이러한 방법적인 수단으로 real world에서 나타나는 sample들의 realization으로서의 data set을 활용한다.
 이어서 model을 학습하는 과정에서는 크게 features selection, model selection, optimization 과정을 거치게 된다.
 앞선 과정들은 보통 machine learning engineer가 개입을 할 수도 있지만 일반적으로 주어지는 문제라고 볼 수 있다.
 그 뒤에 나오게 되는 문제가 앞으로 machine learning engineer가 풀어야할 보다 더 본격적인 문제가 된다.
 먼저 Model selection은 풀고자 하는 문제에 가장 적합한 model을 선택하는 과정이다.
 예를 들어 target function f가 푸른색 박스에서 보이는 바와 같은 분포로 있을 것으로 생각된다면 그와 같은 decision boundary 즉 사각형을 가지는 model을 선택하는 것이 바람직할 것이다.
 그 중에는 선형 model도 있고, 아니면 neural network와 같은 비선형 model도 있다.
 <mark>Optimization은 model parameter를 최적화하여 model이 가장 우수한 성능을 제공하도록 하는 것이다.</mark>
 이렇게 학습한 model은 새로운 sample에 대해서도 정확하면서도 일반적인 성능을 제공해야될 것이다.
 Machine Learning은 그 자체로 Data의 결핍으로 인한 불확실성을 포함하고 있다.
 학습 과정에서 모든 data sample들을 관찰할 수가 없기 때문이다.

## Model generalization

 * Learning is an ill-posed problem; data is limited to find a unique solution
 * **Generalization(Goal): a model needs to perform well on unseen data**
    - Generalization error E<sub><i>gen</i><sub>; the goal isto minimize this error, but it is impractical to compute in the real world
 > Learning from data → Learning from error (supervision)
 * Use training/Validation/test set errors for the proxy

 Machine Learning model의 학습 과정에서 가장 중요한 것 중에 하나는 바로 Generalization 일반화이다.
 즉, model이 학습 과정에서 우리가 관찰을 하지 못한 sample에 대해서도 바로 우수한 성능을 제공할 수가 있어야 된다.
 이러한 model의 일반화된 성능을 측정을 하기 위한 measurement로써 바로 generalization error E를 정의해본다.
 목적은 generalization errorE를 최소화하는 것이다.
 이 error function을 우리가 최소화할 길은 없다.
 이상적인 함수가 되기 때문이다.
 따라서 Supervised Learning에서는 training error, validation error, test error를 통해 generalization error를 최소화하도록 하는 노력을 하게 된다.

## Errors

 * Pointwise erroris measured on an each input sample: <i>e(h(x), y)</i>
 * Examples:
    ✔squared error <i>e(h(x<sup>i</sup>, y<sup>i</sup>)) = (h(x<sup>i</sup>) - y<sup>i</sup>)<sup>2</sup></i>
    ✔binary error <i>e(h(x<sup>i</sup>, y<sup>i</sup>)) = 1[h(x<sup>i</sup>) ≠ y<sup>i</sup>]</i>
 * From a pointwise error to overall errors
    ✔<i>E[(h(x<sup>i</sup>) - y<sup>i</sup>)<sup>2</sup>]</i>

    If an input sample is chosen from training, validation, and testing datasets, the errors are called a training error (<i>E<sub>train</sub></i>), a validation error (<i>E<sub>val</sub></i>), and a testing error (<i>E<sub>test</sub></i>)
 Error는 각 sample 별로 pointwise로 계산한다.
 수식에서 h(x)는 model의 출력이고, y는 정답이다.
 대표적인 error 함수로 squared error가 있다.
 model 출력과 정답과의 차이를 제곱하여 계산한다.
 또한 binary error가 있다.
 내부의 logic을 판별하여 맞으면 0 틀리면 1인 함수이다.
 즉, 이 함수는 model 출력과 정답이 틀리면 1을 출력하는 error 함수가 된다.
 최종적으로는 <mark>data sample에서 발생하는 모든 sample들의 pointwise error를 합쳐서 overall error를 계산한다.
 이러한 overall error를 손실함수, loss function 혹은 cost function이라고 불린다.</mark>
 학습을 하게 되며 error를 측정하게될 sample들이 만약 training set, validation set, 그리고 test를 위한 sample set에서 뽑아 추출을 한다고 하였을 때 각 sample에서 발생하는 error를 E<sub>train</sub>, E<sub>val</sub>, E<sub>test</sub>라고 이야기 한다.

 * Training error <i>E<sub>train</sub></i> measured on a training set, which may or may not represent <i>E<sub>gen</sub></i>; used for fitting a model
 * Testing error <i>E<sub>test</sub></i> (not used in training), which can be used for a proxy of <i>E<sub>gen</sub></i>
 **Goal**: E<sub>test</sub> ≈ E<sub>gen</sub> ≈ 0
 **How to achieve the goal in practice?

 E<sub>train</sub>은 model을 주어진 data set에 맞추어 학습하는데 사용하는 error이다.
 즉, 주어진 sample에서 model parameter를 최적화 하도록 사용한다.
 그렇기 때문에 이 error는 E<sub>general</sub>을 approximation하는데 적합하지 않다.
 대신에 training sample과 overlap이 되지 않도록, 전체 data set에서 일부 sample을 따로 빼서 test sample을 정의한다.
 이 sample에서 나타나는 error를 E<sub>test</sub>로 정의한다.
 이 error는 model이 real world에서 적용될 때 나타나는 generalization error를 표현하는 것이라고 생각할 수 있다.
 다음 목적은 E<sub>test</sub>가 0으로 근사하도록 하여 E<sub>general</sub> 역시 0으로 근사할 수 있다는 기대를 갖게 하는 것이다.
 이러한 과정을 어떻게 수행할 수 있는가?
 2가지의 단계로 나누어 수행하게된다.
 * Split into two objectives:
 <i>1. E<sub>test</sub> ≈ E<sub>train</sub></i>
 <i>2. E<sub>train</sub> ≈ 0</i>
    Objective 1: make <i>E<sub>test</sub> ≈ E<sub>train</sub></i>
       - Failure : <u>overfitting</u> → high variance
       - Cure : <u>regularization, more</u> data
    Objective 2: make <i>E<sub>train</sub> ≈ 0</i>
       - Failure : <u>underfitting</u> → high bias
       - Cure : optimization, <u>more</u> complex model
 첫 번째 단계는 E<sub>test</sub>가 E<sub>train</sub>과 가까워 지도록 학습하는 것이다.
 두 번째 단계는 E<sub>train</sub>이 0으로 가까워지도록 학습을 하게 된다.
 각각의 학습 방식은, 서로 유사해 보이지만 사실 굉장히 다르다.
 먼저 첫 번째 목적인 E<sub>test</sub>가 E<sub>train</sub>과 가까워 지도록하는 방식은 우리가 학습한 model이 일반적인 성능을 제공하도록 하는 성능을 갖도록 하는 것이다.
 일반적인 성능이라고 하는 것은 variance, 분산이 작다.
 하지만 이러한 형태가 실패를 한다면 이것을 overfitting, 과적합 문제라고 한다.
 즉 우리가 학습한 training의 환경이 일반적인 test환경에서 적용을 했을 때 그 model의 성능이 달라지는 것을 의미한다.
 두 번째로는 E<sub>train</sub>이 0으로 가까워지도록 학습을 하는 것이다.
 E<sub>train</sub>이 0으로 가까워진다는 의미는 model의 학습이 잘 되어지고 있다, 즉 model의 정확도가 올라가고 있다라는 것이다.
 이것은 편차, bias가 낮아진다라고 이야기할 수 있다.
 이러한 경우가 실패를 한다면 underfitting, high bias의 문제를 가지고 있다고 한다.
 이때는 보다 복잡한 model을 사용하거나 최적화를 잘 수행하는 것이 해법이 된다.
 각각의 문제는 해결 하는 방향 자체가 약간의 서로 다른 방향성을 가지고 있다는 것을 알 수 있다.
 📌 model 정확도 ⬆

 > bias ⬇

 > model 일반성 ⬆

 > variance ⬇
 
 model의 정확도를 올리는 일은 bias를 낮추는 방법과 model의 일반성을 높이고 variance를 낮추는 종종 서로 상반된 해결책이 필요한 경우가 있다.
 특히 model의 복잡도를 결정할 때 특별히 더 그렇다.

## Bias and Variance
 
 * Bias - error because the model can not represent the concept
 * Variance - error because a model overreacts to small changes(noise) in the training data

 Total loss = Bias + Variance (+noise)
 > bias
 
 🔃 Trade off 관계
 
 > variance

 이러한 개념을 bias와 variance의 trade off 관계가 있다.

## Underfitting

 **Try a simple model**

 ![image](https://user-images.githubusercontent.com/122149118/220595124-5cfffc9a-df42-4199-b96c-cacbfda78dea.png)

 Underfitting problem beacause of using too simpler model than actual data distribution (high bias)

 underfitting에 의한 high bias문제를 보이고 있다.
 예를 들어 다음과 같은 wave를 생각했을 때 예를들어 positive sample과 negative sample이 그림에서와 같이 존재하고 있다.
 boundary decision이 이상적으로 존재한다고 할 때 wave 위 쪽에 존재하는 sample들은 positive sample들이며 signer wave 아래에 위치하는 sample들은 negative sample들이다. 이러한 boundary를 우리의 model을 이용하여 학습을 한다고 생각했을 때 가장 먼저 시도해볼 수 있는 것은 그림에서 보는 바와 같이 선형 model이 될 것이다. 
 선은 signer wave approximation해주는 decision boundary가 될 것이다. 
 이 대각선에 의해서 위쪽에 있는 sample들은 positive sample들이 될 것이고 선 아래쪽에 있는 sample들은 negative sample으로 판정하게 된다.
 이 사이에 존재하는 sample들 예컨데 왼쪽 좌측 하단 동그라미친 부분에 있는 sample들은 효과적으로 분류하지 못하고 있다는 것을 알 수 있다.
 그 이유는 실제로 존재하게되는 decision boundary를 우리의 model이 즉, linear한 model이 효과적으로 approximation할 수가 없기 때문이다.
 이렇게 발생하는 오차를 high bias라고 한다.

## Overfitting

 **Try a complex model**

 ![image](https://user-images.githubusercontent.com/122149118/220675921-c5bdc588-b09d-452c-80b1-7f6cee8bc508.png)

 Overfitting problem because of using more complex nodel than actual data distribution (high variance)

 반대로 이러한 문제를 해결하기 위해 이렇게 지나치게 복잡한 model을 도입하게 되면 발생하는 문제에 대해 알아본다.
 예를 들어 sine wave로 구성되어있는 decision boundary를 모사하기 위해서 그림과 같이 복잡한 model을 도입하여 분류하고 있다고 생각해본다.
 그러면 최소한 이 phase에 나와있는 negative sample들, 그리고 positive sample들은 model을 가지고 정확하게 다 분류하고 있다는 것을 알 수 있다.
 현실 세계에서 이것이 과연 정확하다고 할 수 있는가?
 현실 세계에서는 우리가 알고있기로는 왼쪽에 positive, 오른쪽에 negative sample들이 존재하게 되는데 따라서 이러한 model을 도입하게 되면 model에서 푸른색으로 표현이 되어있는 부분들은 전부 negative sample들이 존재하고 있는 영역이 된다.
 하지만 model을 통해서는 전부 positive sample로 구분하고 있는 것을 알 수 있다.
 이러한 문제는 이 model이 지나치게 복잡하게 tuning, 학습이 되어 오분류가 일어나고 있다.
 이 문제를 overfitting이라고 한다.

## Bias-variance trade-off

 이와 같이 model의 복잡도에 의해 두 가지의 목적은 서로 trade-off의 관계를 가지고 있다.

 * Split into two objectives:
    <i>1. E<sub>test</sub> ≈ E<sub>train</sub></i>
    <i> 2. E<sub>train</sub> ≈ 0</i>
 * Objective 1: make <i>E<sub>test</sub> ≈ E<sub>train</sub></i>
       - Failure : <u>overfitting</u> → high variance and low bias
       - if a model is too complex
 * Objective 2: make <i>E<sub>train</sub> ≈ 0</i>
       - Failure : <u>underfitting</u> → high bias and low variance
       - if a model is too simple
 
 ![image](https://user-images.githubusercontent.com/122149118/220680602-79c4a97f-4c77-47b5-8381-80d433bfaea0.png)

 model이 복잡해지면 overfitting이 발생하기 쉬우며 bias는 줄어들지만 variance가 증가하게 되어 model이 새로운 sample에 일반적인 성능을 제공하기가 어렵다.
 반대로 model이 지나치게 단순하면 underfitting이 발생하여 bias가 높아져 우수한 성능을 제공하기 어렵다.
 이러한 두개의 factor를 균형있게 맞춰 generalization error를 최소화하도록 하는 것이 학습과정에서 중요하다.
 
 * The two objectives have trade-off between approximation and generalization w.r.t model complexity

 ![image](https://user-images.githubusercontent.com/122149118/220680940-9724d344-3251-414b-a553-3e77e422b601.png)

 오른쪽으로 model complexity가 늘어나게 되면 overfitting이 발생하기 쉬우며 이 때는 training error와 test error의 간극이 벌어지고 있는 것을 알 수 있다.
 바로 variance가 증가하게 되는 것이다.
 반대로 model complexity가 감소하게 되면 이것을 underfitting zone이라고 이야기 하며 이 때는 bias가 높아지는 것을 알 수 있다.
 즉 이 두 개의 trade-off를 조절하여 generalization error를 가장 최소한으로 만드는 것이 숙제이다.

 Deep Learning과 같은 오늘날의 Machine Learning model은 이미지나 비디오 등과 같은 고차원의 data를 다루기 때문에 그 복잡도가 굉장히 증가하고 있다.
 📌복잡도 증가 속도 > Data set sample 수
 ➡ Overfitting 문제 ⬆
 하지만 복잡도가 증가하는 속도에 비해서 data sample의 숫자는 우리가 쉽게 늘리지 못하는 문제가 있어 요즘의 문제들은 overfitting의 문제가 현저히 늘어나게된다.
 이러한 문제를 **Curse of dimension 차원의 저주 문제**라고 이야기 한다.
 만약 입력 data 또는 입력 feature의 차원이 증가한다면 지수적으로 sample의 숫자가 늘어나야하지만 그렇게 하기 어렵다.

## Avoid Overfitting

 * **Problem** 
 In today's ML problems, a complex model tends to be used to handle high-dimensional data (and relativelu insufficient number of data) ; prone to an overfitting problem
 * **Cures of dimension** Will you increase the dimensrion of the data to improve the performance as wee as maintain the density of the examples per bin> If so, you need to increase the data exponentially.

 ![image](https://user-images.githubusercontent.com/122149118/220686798-4420b9cb-02da-4e4d-92ea-525f387adde9.png)

 이러한 문제를 해결하기 위한 가장 직접적인 수단으로는 <mark>Data를 늘리는 것이다.</mark>
 간단한 일처럼 보이지만 충분한 숫자의 data들을 확보하고 만드는 것은 쉽지 않다. 
 거기에 드는 비용과 노력이 굉장히 많이 소요되기 때문이다.
 이를 위해 다양한 data augmentation 방법이 있다.
 data를 변형할 수도 있고 최근엔 computer로 sample을 생성하거나 합성하여 별도의 생성 model을 개발함으로서 sample 숫자를 늘리기도 한다.
 현실적으로는 data sample의 숫자를 늘리기 어려운 경우에 이를 해결하기 위한 몇 가지 기술적 수단이 있다.

 * **Remedy**
    ✔ **Data augmentation**
    ✔ Regularization to penalize complex models (variance reduction) ; make a model not too sensitive to noise or outliers (e.g. drop-out, LASSO)
    ✔ Ensemble : average over a number of models
 
  ![image](https://user-images.githubusercontent.com/122149118/220699366-82705f90-eeda-4e04-941d-ec4f36693e36.png)
 
 첫 번째 기술적인 수단으로 Regularization 방식이 있다.
 두 번째로는 앙상블 모델에 대한 방법이 있다.

## Cross-validation (CV)

 **k-fold cross-validation**

 ![image](https://user-images.githubusercontent.com/122149118/220704013-b85d63f0-1d1d-403b-86b1-7fe0997e72ff.png)

 * Training data set - used to train a model to fit data
 * Validation data set - used to provide unbiased evaluation of the model's fitness
 * Test data set - never been used in the training

 → **cross-validaton** allows a better model to avoid overfitting (but more complexity)
 그림 상단에서와 같이 원래 data set가 구성이 되어있을 때 training set와 test set로 구분하여 학습을 하고 평가를 한다.
 이 때 training set를 이런식으로 구분하게 된다면 data를 효과적으로 학습을 하는데 활용하지 못할 수 있다.
 그 때 사용하는 것이 바로 cross-validation이라고 한다.
 cross-validation에서는 training set를 크게 k개의 그룹으로 구분하게 된다. 
 그리고 총 k - 1개의 그룹을 training에 활용하게 되며 나머지 1개의 그룹을 validation으로 이용한다.
 training은 model parameter를 fitting 하는데 사용하게 되고 validation은 이 model의 최적화를 위해 사용하게 된다.
 지금 현재 model에서는 k가 5인 model인 5 fold cross-validation을 보이고 있다.
 이러한 과정을 5번 연속 수행하여 data sample들을 자연스럽게 augmentation을하여 학습하는데 활용하게 되면 조금 더 model을 일반화시키는데 도움을 줄 수 있다.
 물론 model의 최종 성능은 바로 test dataset를 이용하여 측정한다.

## Quiz

 **1.** What are two examples of classification?

 **A.** Determine when a heater is on or off based on weather data 
 **B.** Translate the numbers or letters form a handwritten message to ASCII text
 **C.** Develop a mathmatical relationship between heater level (0-100%) and temperature(20-70℃)
 A는 날씨에 따라 히터를 키거나 끄는 문제, B는 필기체 언어를 digital 숫자로 변환하는 문제, C는 온도에 따라 변환을 하는 문제

 **A Correct.** The classifier distinguishes between on or off with temperature and temperature derivatives as the features.

 ![image](https://user-images.githubusercontent.com/122149118/220705157-6c75b47d-37cf-4ca9-b6f1-aa46a94d1b86.png)

 주어진 입력 feature가 heater를 키거나 끄는 문제, 즉 binary classification 문제라고 할 수 있다.
 **B Correct.** The classifier analyzes the pixels of each letter to determine the alpha-numeric value.

 ![image](https://user-images.githubusercontent.com/122149118/220705443-3caf0ff4-a258-4ff2-9179-db9ce65b0d9f.png)

 그림에서와 같은 필기체가 주어진다면 0부터 9에 해당하는 class id, 0에서 9까지 중에 하나로 분류하는 multi-class classification문제가 된다.

 C는 연속 변수를 출력하는 task이므로 classification이 아니라 regression문제가 된다.

 **2.** What answers are correvt for supervised learning?

 **A.** Requires labeled data that reveals the measured or true outcome
 **B.** Training and test samples can be overlapped

 **A Correct.** Supervised learning uses labeled data to compute an error with a model output.
 supervised learning에서는 label data를 이용해 이 label data로 하여금 이 model의 error를 측정하여 학습에 반영하도록 하는 machanism을 가지고 있다.

 **B False.** Training and test samples must not be overlapped
 training과 test sample이 overlap이 되어서는 결코 안된다.

## Summary

 * **Introduction to supervised learning**
    - Regression and calssification
    - Learning pipline of a supervised learning
       - Learning from data (error)
    - Overfittind Vs underfitting (Bias-variance trad-off)
    - Model generalization
       - Avoid overfitting and cross validation

 Supervised Learning에서는 regression과 classification문제가 있다.
 data set에 주어진 정답 즉 label과 비교하여 error를 줄이며 학습한다.
 학습 과정에서 overfitting과 underfitting에 대한 문제와 그 관계를 살펴보았다.
 Machine Learning에서는 model의 정확도를 올리는 일 외에도 처음 보는 sample들에 대한 일반적인 성능을 제공하는 일 역시 대단히 중요하다.