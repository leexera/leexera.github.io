---
layout: post
title: "Classical Object Detection - HOG"
description: "Part 2. 컴퓨터비전 특화 이론과 실습", "Ch05. 객체탐지(Object Detection)와 분할(Segmentation)"
date: 2023-03-15
tags: study
comments: true
---

classical objective detection의 feature extraction방법인 histogram of Oriented Gradient (HOG) 방식에 대하여 배워본다.

---
# Histogram of Oriented Gradients (HOG)

 * Gradient image computation
    - No Gaussian smoothing
    - Filters to compute horizontal-vertical gradient images:
    <i>f<sub>x<sub></i> = [-1 0 +1]
    <i>f<sub>y</sub></i> = [-1 0 +1]<sup>T</sup>
    ![image](https://user-images.githubusercontent.com/122149118/225199185-35415aa1-84fa-40a2-b2bf-8414018f7b22.png)
 * Use color infotmation when available
    - Compute gradient in each channel and choose the maximum gradient

 HOG는 image gradient 정보를 사용한다.
 image gradient의 orientation, 방향성을 구하는 것이다.
 방향성을 구하는 방법은 histogram형태로 구하게된다.
 먼저 image의 gradient를 구한 후 이 때 Gaussian smoothing을 하지않는데 그 이유는 Gaussian smoothing을 하게되면 방향성의 정보가 많이 사라지게 되므로 smoothing을 기본적으로 하지 않는다.
 Gaussian smoothing을 하면 noise 부분들이 없어질 수는 있겠지만 좀 더 선명한 정보를 얻기 위해 하지 않는 것이다.
 horizontal과 vertical gradient image를 얻는다.
 f<sub>x</sub> * I로 image gradient 표현을 해준다.
 x 방향의 gradient와 y 방향의 gradient, 조도가 얼마나 변하는지에 대한 정보로 y 방향은 y 방향으로 넘어갈 때 잡히게 되고 x 방향은 x 방향으로 넘어갈 때 잡히게 된다.
 kernel모양은 아주 간단하다.
 [-1 0 +1]을 통과시켜 x를 판단하게 되고 [-1 0 +1]을 transpose한 kernel을 통과시키면 y 방향의 gradient를 얻을 수 있게된다.
 color information이 available한 경우에는 color information을 사용한다.
 gray scale로 만들어 histogram gradient를 뽑기도 하지만 color RGB space 정보가 있다면 각 channel에 대해서 gradient를 구하고 모두 다 사용하는 것이 아니라 maximum한 gradient를 선택, 즉 maxpooling하여 사용하는 것이다.
 그러면 h X w X 1 channel의 HOG값이 나올 것이다.
 
 * Weighted vote into quantized orientations
 ![image](https://user-images.githubusercontent.com/122149118/225200770-1f00c2e9-6653-4a99-9238-bef9a5635b3e.png)
 * Each pixel cats a weighted vote by gradient magnitude for an oriented histogram
 ![image](https://user-images.githubusercontent.com/122149118/225200870-91f1ef5c-afcb-4608-a60e-4343ca93549b.png)

 HOG값이 아닌 x와 y방향의 gradient인데, 그 값을 quantize하여 방향성을 찾아주는 것이다.
 x 방향의 gradient와 y방향의 gradient의 값을 사용하여 어디 방향성을 정하는지 알 수 있다.
 위 그림과 같이 orientation 7과 orientation 8사이의 값을 가리킬 수 있다.
 이 값들은 전체 방향을 45˚씩으로 나누어주는 값이므로 o<sub>1</sub>이 0˚라고 했을 때 o<sub>7</sub>은 270˚가 될 것이다.
 이 값을 quantize하여 o<sub>7</sub>과 o<sub>8</sub> 사이로 soft voting하여 o<sub>7</sub>에는 일정 양만큼 나뉘고 o<sub>8</sub>에는 다른 일정 양만큼 나뉘는 histogram이 생성된다.
 그리고 X는 dust bin값을 넣어준 것이다.
 hard voting을 하는 것은 o<sub>7</sub>이 가장 가까우므로 o<sub>7</sub>값만 커질텐데 soft voting을 하여 interpolation을 한 후 o<sub>7</sub>과 o<sub>8</sub>에 나누어져서 voting을 하는 histogram값이 나오게 된다.
 한 pixel에 대해 이러한 histogram 값이 계속 나올 것이고 w by h by 9, chennel이 9인 feature map이 나오게 될 것이다.
 각 pixel은 gradient magnitude에 따른 weighted vote를 얻게된다.
 위 그림에서는 방향성만 나타낸 것이고 방향성 뿐만아니라 gradient magnitude 2가지를 모두 반영한 histogram값을 얻게될 것이다.
 방향성만 가지고 있는 값에 gradient값을 scailing으로 값을 곱해주면 된다.
* Cell
   * 8X8 image area
   * A unit area to compute orientation histogram
  ![image](https://user-images.githubusercontent.com/122149118/233432933-f6e59313-5385-4fc5-a563-e37f2380b834.png)
* Block
   * Composed of 2X2 cells (16X16 image area)
   * Partially overlapped
   * Concatenating 4 histograms
   * Per-block histogram normalization to consider spatial distribution of gradient magnitudes
  ![image](https://user-images.githubusercontent.com/122149118/233433462-00c4a637-b422-4f1e-ba6a-4221bd95efa5.png)
* Window
   * 8X16 cells(64X128 image)
   * Concatenating all block descriptors

각 pixel별로 histogram이 생성될텐데, 이 것을 cell로 나누어준다.
image area의 8 by 8 위치를 나눈 후 orientation histogram의 unit area를 구성하는 것이 하나의 cell이다.
이 cell에 대해서 orientation을 각각 지니는 histogram이 있으므로 dominent orientation을 voting하여 만약 가능성을 9개로 나타냈다면 0˚, 45˚, 90˚, 135˚, 180˚, 225˚, 270˚, 315˚, 360˚로 어느 방향이 더 dominent한지 값이 나오게 될 것이다.
hog에서 block은 cell의 2 by 2를 나누는 것으로 즉, 16 by 16 pixel을 지닌 image area를 말한다.
위 4가지 histogram은 좌측 상단, 좌측 하단, 우측 상단, 우측 하단으로 펼쳐진다.
partially overlap되도록 형성할 수도 있다.
4개의 histogram을 concat한 것이고, block별로 normalize를 따로 한다.
4개의 cell이 붙은 것에 대해 L<sub>2</sub> normalize를 하게되고 gradient magnitude의 spatial distribution을, 어떤 지역적인 distribution을 고려하게 되는 block이 나온다.
window는 어떤 block에 대해서 8X16 cell을 나타내는 것으로 즉, 64X128 pixel의 image에서 64X128 region을 다루게 되는 것이다.
모든 block descriptor를 concat을 하여 64X128 size를 커버하는 어떤 descriptor를 만들게 된다.
block 4 X 8, 32개의 histogram이 붙어있는 형태가 window가 되는 것이다.

# HOG + SVM for Pdedstrian Detection

* Training dataset: Inria Person Dataset
   * Positive examples
  ![image](https://user-images.githubusercontent.com/122149118/233437058-4ec7c585-165d-41d9-bedc-9691647032e7.png)
   * Negative examples
  ![image](https://user-images.githubusercontent.com/122149118/233437183-982ca5e7-d178-41d5-b338-9b6ddb7af118.png)
  Typically, <i>N<sub>p</sub> << N<sub>n</sub></i>, It is important to find many hard negative examples for performance improvement

hog라는 feature를 뽑고, soft vector machine으로 classifier를 하여 pedestrian detection문제를 고전적으로 많이 풀었다.
train dataset으로는 Inria(프랑스에 있는 연구 기관) Person Dataset을 사용하였는데, 이 dataset 안에는 positive example과 negative example이 annotation된 training set이 있다.
일반적으로 positive example보다 negative example이 훨씬 많다.
많은 hard negative example을 학습을 해야 성능이 많이 증가하기 때문이다.
사람인 것과 사람이 아닌 것을 구분하기 위해서는 model 구조가 negative를 조금 더 많이 학습을 해야한다.

* Classification by linear SVM with soft margin
![image](https://user-images.githubusercontent.com/122149118/235708439-37791435-2830-4c29-8e7c-e990688793dc.png)
![image](https://user-images.githubusercontent.com/122149118/235708616-80043245-851a-4493-a1a4-5444632b4dde.png)
pedestrian detection task를 풀기 위해 HOG와 SVM을 학습한다고 했을 때 soft margin을 포함한 linear SVM model을 classification으로 사용하고, 위 수식은 Soft Vector Machine에서 사용되는 것으로 첫 번째 항은 hyper plane을 푸는 항이며, 두 번째 항은 soft margine의 식을 나타낸다.
C는 hyper parmeter로써 찾아주어야 하는 값이고 이러한 수식을 풀기위해 optimization constraint는 뒤에 있는 식과 같다.
slack variable과 hyper plane의 각 data point들을 넣은 값을 넣어 조건을 만족하는 경우에 대해서 optimization 수식을 만족하는 w와 b 값을 찾는 것이다.
이 때 data point는 x<sub>i</sub>와 y<sub>i</sub>이고 x<sub>i</sub>는 localize된 bounding box가 어떤 feature space로 projection된 값이며 결국 x<sub>i</sub>는 HOG feature를 나타내는 것이다.
y<sub>i</sub>는 label로 사람인지 아닌지 supervised learning이기 때문에 사람이면 1, 아니라면 -1이 된다.
image에 대해서 HOG feature를 뽑았을 때 각각 각 cell들은 값을 나타내게 된다.
방향성을 다양하게 나타내고 있지만 positive한 w를 찾았을 때의 값과 관련이 없는 negative한 w를 찾았을 때는 다른 값들을 찾아내는 것을 위의 그림에서 확인할 수 있다.
* Classification by linear SVM with soft margin
   * Result of sliding window
   ![image](https://user-images.githubusercontent.com/122149118/235712293-1ab317b6-5380-4396-9b15-06b5b6e40147.png)
   * Non-maximal suppression is essential
pedestrian detection에서 linear한 SVM을 사용하여 결과를 찾았을 때 sliding window라는 region proposal, bounding box 후보들을 사용하여 결과를 보았을 때 빨간색으로 나타난 부분이 높은 classfication score를 가지고 image 상에서 어디에 사람들이 위치하고 있는지 파악하는 결과를 보여준다.
초록색이나 노란색의 영역들을 잘 제거해주기 위하여 non-maximal suppression, max값이 아닌 부분을 제거하는 것은 필수적이다.
즉, thresholding을 하는 것이다.
예를 들어, 빨간색에 가까우면 1, 파란색에 가까울수록 0일때 0.5에서 0.7정도로 thresholding을 하면 노란색이나 파란색, 초록색 부분이 제거되어 빨간색 score만 남아 이 부분에 대한 bounding box를 정해줬을 때 또는 sliding window로 찾아진 region proposal들을 찾았을 때 사람을 잘 detection해준다.
고전적으로 HOG feature를 사용하고 SVM classifier를 사용해서 objectdetection하는 방법을 알아보았다.

# Pedestrian Detection Results using HOG+SVM
![image](https://user-images.githubusercontent.com/122149118/235714486-90070fff-fc3e-474a-a485-a40bb1c8cd49.png)
작은 image에 대해서도 보행자를 잘 찾아내는 것을 확인할 수 있다.