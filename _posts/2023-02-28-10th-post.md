---
layout: post
title: "Advanced Classification"
description: "ì´í™”ì—¬ìëŒ€í•™êµ ê°•ì œì› êµìˆ˜ë‹˜(Electronic & Electrical Engineering)"
date: 2023-02-28
tags: study
comments: true
---
# ì§€ë„ í•™ìŠµ
## Linear classification

 ![image](https://user-images.githubusercontent.com/122149118/221790149-39b56aef-0b7b-47f8-aea2-c10080e60caa.png)

 Linear classification ë¬¸ì œì—ì„œ ë°°ìš´ ë°”ì™€ ê°™ì´ sampleì˜ ë¶„ë¥˜ëŠ” hyper planeì„ ê¸°ì¤€ìœ¼ë¡œ score ê°’ì„ ê³„ì‚°í•˜ì—¬ classificationì„ ìˆ˜í–‰í•œë‹¤.
 ì´ ë•Œ hyper planeì„ êµ¬ì„±í•˜ëŠ” model parameterê°€ wì´ë©´ hyper planeì˜ normalí•œ ë°©í–¥ìœ¼ë¡œ hyper parameter w vectorë¥¼ êµ¬ì„±í•˜ê²Œ ëœë‹¤.
 score ê°’ì„ ê³„ì‚°í•˜ê²Œ ë˜ë©´ w<sup>T</sup>xê°€ 0ë³´ë‹¤ í° ê²½ìš°ê°€ positive sampleì´ ëœë‹¤.
 0ë³´ë‹¤ ì‘ì€ ê²½ìš°ëŠ” negative sampleì´ ëœë‹¤.
 ì´ hyper planeì— ìœ„ì¹˜í•˜ëŠ” h(x)ëŠ” 0ì´ ë˜ê²Œ ëœë‹¤.
 ì´ëŸ¬í•œ hyper planeì„ sample ì‚¬ì´ ì¤‘ê°„ì— ê¸‹ëŠ”ë° ë§ì€ ì„ íƒì˜ ë¬¸ì œê°€ ìƒê¸°ê²Œ ëœë‹¤.

## Multiple solutions

 ![image](https://user-images.githubusercontent.com/122149118/223774259-def8e7ab-187b-43c0-90c5-cc3c9e12e157.png)
 Same on empirical loss; Different on test/expected loss

 í˜„ì¬ ê·¸ë¦¼ì—ì„œ positive sampleê³¼ negative sampleì„ êµ¬ë¶„í•˜ëŠ”ë° ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ hyper planeì´ ìˆìŒì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤.
 ì˜ˆë¥¼ ë“¤ì–´ w<sub>1</sub>ê³¼ ê°™ì€ hyper planeì„ ê·¸ì„ ìˆ˜ë„ ìˆì„ ê²ƒì´ê³  w<sub>2</sub>ì™€ ê°™ì€ hyper planeì„ ê·¸ì„ ìˆ˜ë„ ìˆì„ ê²ƒì´ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ w<sub>3</sub>ì™€ ê°™ì€ hyper planeì„ ê·¸ì„ ìˆ˜ë„ ìˆì„ ê²ƒì´ë‹¤.
 ì´ì™€ ê°™ì´ ì„œë¡œ ë‹¤ë¥¸ hyper planeì„ ê·¸ì—ˆì„ ë•Œ, ìµœì†Œí•œ ì—¬ê¸° ìˆëŠ” data sampleë“¤ì— ëŒ€í•´ì„œëŠ” ì•„ë§ˆë„ ê°™ì€ loss, ë¹„ìŠ·í•œ lossë¥¼ ì œê³µí•˜ê²Œ ë  ê²ƒì´ë‹¤.
 ì—¬ê¸°ì— ìˆëŠ” sampleë“¤ì€ ëª¨ë‘ í›Œë¥­í•˜ê²Œ ë¶„ë¥˜í–ˆê¸° ë•Œë¬¸ì´ë‹¤.
 í•˜ì§€ë§Œ ì´ modelì„ ì‹¤ìƒí™œì—ë‹¤ ì ìš©ì„ í•˜ê²Œ ë˜ëŠ” ê²½ìš°ì—ëŠ” data sampleì—ëŠ” ë³´ì´ì§€ ì•ŠëŠ” êµ‰ì¥íˆ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ sampleë“¤ì´ ë‚˜íƒ€ë‚  ìˆ˜ê°€ ìˆê²Œ ë  ê²ƒì´ê³  ì´ ë•Œ ì„¤ì •í•œ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ hyper planeë“¤ì€ ì„œë¡œ ë‹¤ë¥¸ ì„±ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤.

## What about <i>w<sub>1</sub></i>?

 ![image](https://user-images.githubusercontent.com/122149118/223775887-dd5d366d-ea8d-415c-aa61-e72d6430dd67.png)

 ë¨¼ì € w<sub>1</sub>, hyper parameterë¥¼ ì´ìš©í•œ hyper planeì„ ë‹¤ìŒê³¼ ê°™ì´ ê·¸ì–´ modelì„ ë§Œë“¤ì—ˆë‹¤ê³  ìƒê°í•´ë³¸ë‹¤.
 ì´ ë•Œ ì—¬ê¸°ì— ë³´ì´ëŠ” sampleë“¤ì€ ì˜ ë¶„ë¥˜í•  ìˆ˜ ìˆì§€ë§Œ ì•„ë§ˆ ì´ hyper plane ê·¼ì²˜ì—ì„œ ì¦‰, positive sampleë“¤ ê·¼ì²˜ì—ì„œ ë˜ë‹¤ë¥¸ positive sampleì´ ìœ„ì™€ ê°™ì€ í˜•íƒœë¡œ ë‚˜íƒ€ë‚  ê°€ëŠ¥ì„±ì´ ëŒ€ë‹¨íˆ í¬ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.
 ì´ëŸ¬í•œ ê°€ì •ì€ êµ‰ì¥íˆ í•©ë¦¬ì ì¸ ê°€ì •ì´ë‹¤.
 ê·¸ ì´ìœ ëŠ” ìœ„ì™€ ê°™ì´ ìœ„ì¹˜í•œ ìƒˆë¡œìš´ positive sampleì€ ì£¼ìœ„ì— ìˆëŠ” positive sampleê³¼ êµ‰ì¥íˆ ì„œë¡œ ê°„ì— ê±°ë¦¬ê°€ ê°€ê¹ê¸° ë•Œë¬¸ì´ë‹¤.
 ë°˜ëŒ€ë¡œ negative sampleë“¤ ì‚¬ì´ì˜ ê±°ë¦¬ëŠ” ë©€ë‹¤ë¼ê³  í•  ìˆ˜ ìˆë‹¤.
 ë”°ë¼ì„œ ì´ì™€ ê°™ì€ ìƒˆë¡œìš´ test sampleì´ ë“¤ì–´ì˜¤ê²Œ ë˜ì—ˆì„ ë•Œ ì„¤ì •í•œ w<sub>1</sub>ì˜ hyper planeì€ ì˜¤ë¥˜ë¥¼ ë‚³ì„ í™•ë¥ ì´ ë†’ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.

# What about <i>w<sub>3</sub></i>?

 ![image](https://user-images.githubusercontent.com/122149118/223777490-2c57e01e-dd6e-405b-aa7c-9516fb6b1bef.png)

 ë˜í•œ ë‹¤ë¥¸ ì˜ˆì‹œì™€ ìœ ì‚¬í•˜ê²Œ ë§Œì•½ w<sub>3</sub>ì— í•´ë‹¹í•˜ëŠ” hyper planeì„ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í–ˆë‹¤ê³  í•  ë•Œ ë¹„ìŠ·í•œ ì´ìœ ë¡œ negative sampleì— í•´ë‹¹í•˜ëŠ” sampleì´ ìƒˆë¡œìš´ test sampleì—ì„œ negative sampleë“¤ê³¼ ì„œë¡œ ê°„ì— ê°€ê¹Œìš´ ê±°ë¦¬ì—ì„œ ë°œìƒí•  í™•ë¥ ì´ ë†’ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.
 ì´ëŠ” ë§ˆì°¬ê°€ì§€ë¡œ positive sampleê³¼ëŠ” ê±°ë¦¬ê°€ ë©€ê¸° ë•Œë¬¸ì— negative sampleìª½ì— í›¨ì”¬ ë” ë‚˜íƒ€ë‚˜ê²Œ ë  í™•ë¥ ì´ ë†’ì€ ê²ƒì´ë‹¤. 
 ì´ì™€ ê°™ì´ w<sub>3</sub>ë¥¼ ë°˜ëŒ€ë¡œ negative sampleìª½ì— hyper planeì„ ì„¤ì •í•˜ê²Œ ëœë‹¤ë©´ ì´ ì—­ì‹œ negative sampleìª½ì—ì„œ ì˜¤ë¥˜ë¥¼ ë‚³ì„ í™•ë¥ ì´ ìƒë‹¹íˆ ë†’ë‹¤ê³  í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

## Most confident: <i>w<sub>2</sub></i>

 ![image](https://user-images.githubusercontent.com/122149118/223778725-7d6f1b74-65e1-4faa-8e37-8988cafc2fdd.png)

 ë”°ë¼ì„œ ì„ íƒí•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì¢‹ì€ ìœ„ì¹˜ë¼ê³  í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ë°”ë¡œ positive sampleê³¼ negative sample ì¤‘ê°„ ì–´ë”˜ê°€ì— hyper planeì„ ê¸‹ëŠ” ê²ƒì´ ê°€ì¥ ìµœì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.
 positive sampleê³¼ negative sample ì‚¬ì´ì— ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ hyper planeì„ ê·¸ì–´ì•¼í•  ê²ƒì¸ê°€ê°€ ë°”ë¡œ modelì„ ìˆ˜ë¦½í•˜ê¸° ìœ„í•œ ìˆ™ì œë¼ê³  í•  ìˆ˜ ìˆë‹¤.
 SVM(Support Vector Machine)ì—ì„œëŠ” ì´ëŸ¬í•œ ìˆ™ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ì§€ ì•Œì•„ë³¸ë‹¤.
 SVMì—ì„œëŠ” marginì´ë¼ê³  í•˜ëŠ” ê²ƒì„ ì •ì˜í•˜ê²Œ ëœë‹¤.
 Marginì´ hyper planeì„ ê²°ì •í•˜ëŠ” SVMì˜ í•µì‹¬ì ì¸ ì•„ì´ë””ì–´ê°€ ëœë‹¤.

# Intuition: margin

 ![image](https://user-images.githubusercontent.com/122149118/223779854-20202f4b-2046-4478-b0d3-55bb869c57a8.png)

 ê·¸ë¦¼ì—ì„œì™€ ê°™ì´ ê°€ì¥ hyper planeì— ê°€ê¹Œìš´ positive smapleì´ ìˆì„ ìˆ˜ ìˆê³  ë°˜ëŒ€ë¡œ negarive sample ì—­ì‹œ hyper planeì˜ ê°€ì¥ ê°€ê¹Œìš´ sampleë¡œ ì¡´ì¬í•  ìˆ˜ ìˆë‹¤.
 ê·¸ëŸ¬ë©´ hyper planeì€ í˜„ì¬ ê°€ì¥ ê°€ê¹Œìš´ positive sampleì„ ì§€ë‚˜ê°€ëŠ” ì´ ì ì„ , ê·¸ë¦¬ê³  negative sampleì„ ì§€ë‚˜ê°€ëŠ” ì´ ì ì„ ìœ¼ë¡œ êµ¬ì„±ëœ hyper planeì˜ ë‘˜ ì‚¬ì´ì— ê°€ì¥ ì„œë¡œ ê°„ì˜ ìœ„ì¹˜ê°€ ë™ì¼í•œ hyper planeì´ ë°”ë¡œ ì´ ë‘˜ positive sampleê³¼ negative sample ì‚¬ì´ì— ìµœëŒ€ marginì„ í™•ë³´í•  ìˆ˜ ìˆëŠ” ìµœì í™” ë°©ì‹ì´ ë˜ê²Œ ë  ê²ƒì´ë‹¤.
 ì´ë ‡ê²Œ êµ¬ì„±ì´ ëœ w<sub>2</sub>ì˜ hyper parameterëŠ” ì´ ë‘ ê°œì˜ ì ì„  ì‚¬ì´ì— ì¤‘ê°„ì—ì„œ ì„¤ì •ì´ ë˜ì–´ ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

## Support Vector Machine

 * Choose the linear separator (hyperplane) with the largest **margin** on either side
    - Maximum margin hyperplane with **support vectors**
    - Robust to outliers

 **Support vector** : an instance with the minimum margin, which will be the most sensible data points to affect the performance

 ![image](https://user-images.githubusercontent.com/122149118/223781420-c500198e-cae6-4d41-972b-cf2d515da15f.png)
 <i>h(x) = w<sup>T</sup>x + b</i>

 Support Vector Machineì—ì„œëŠ” ì´ëŸ¬í•œ ê°œë…ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ì„œ support vectorë¥¼ ì •ì˜í•œë‹¤.
 support vectorë¼ê³  í•˜ëŠ” ê²ƒì€ positive sampleê³¼ hyper plane ì‚¬ì´ì— ìˆëŠ” ê±°ë¦¬ ì¤‘ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ sampleì„ ì˜ë¯¸í•˜ê²Œ ë˜ê³ , ë°˜ëŒ€ë¡œ negative sample ì¤‘ì—ì„œë„ ê°€ì¥ ê°€ê¹Œìš´ marginì„ ê°–ëŠ” vectorë¼ê³  í–ˆì„ ë•Œ ì´ëŸ¬í•œ support vectorë“¤ì€ ê²°êµ­ ì„±ëŠ¥ì„ ê°€ì¥ ì¢Œì§€ìš°ì§€í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ë¯¼ê°í•œ data pointë¼ê³  í•  ìˆ˜ ìˆë‹¤.
 ì´ëŸ¬í•œ support vectorë“¤ë¼ë¦¬ì˜ ê±°ë¦¬ë¥¼ ê°€ì¥ ìµœëŒ€í™” í•˜ë„ë¡ í•˜ëŠ” maximum marginì„ ì„¤ì •í•˜ëŠ” ê²ƒì´ ìµœì í™” ì „ëµì´ ëœë‹¤.
 ì´ ë°©ì‹ì€ unseen test dataê°€ ë°œìƒí–ˆì„ ë•Œ ì–´ë– í•œ outlierë“¤ì— ëŒ€í•´ì„œë„ ë³´ë‹¤ë” ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ì œê³µí•˜ë„ë¡ í•˜ëŠ” ìµœì í™” ë°©ì‹ì´ ëœë‹¤.

## Margin

 * Twice the distance from the hyperplane to the nearest instance on either side

 * <i>w</i> is orthogonal to the hyperplane

 * Lemma : <i>x</i> has distance <sup>|<i>h<sub>wb</sub>(x)</i>|</sup>/<sub>||<i>w</i>||</sub> to the hyper plane <i>h<sub>wb</sub>(x) = w<sup>T</sup>x + b = 0</i>

 ![image](https://user-images.githubusercontent.com/122149118/223784264-087ea83e-85cf-4a85-9487-a2cf34b8e1fd.png)

 ğŸ” Marginì€ ì–´ë–»ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆëŠ”ê°€?

 â¡ ìˆ˜ì‹ì—ì„œ ë³´ì´ëŠ” ë°”ì™€ ê°™ì´ ê°€ìš´ë°ì— ìˆëŠ” hyper planeì€ h(x) = 0ì¸ hyper planeì´ë‹¤.
 hyper planeì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ support vectorê°„ ê±°ë¦¬ëŠ” í•œ vectorì˜ ê¸¸ì´ì˜ ë‘ ë°°ë¼ê³  í•  ìˆ˜ ìˆë‹¤.
 model parameter wëŠ” ì´ hyper planeì˜ nomalí•œ ë°©í–¥ìœ¼ë¡œ ì„¤ì •ì´ ë˜ì–´ ìˆë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.
 ì´ëŸ¬í•œ support vector xì™€ hyper plane hì™€ì˜ ì‚¬ì´ ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ë³´ë©´ <sup>|<i>h<sub>wb</sub>(x)</i>|</sup>/<sub>||<i>w</i>||</sub>ì™€ ê°™ì´ êµ¬í•  ìˆ˜ ìˆë‹¤.

## Margin distance

 Proof:
 * Let <i>x = x<sub>âŠ¥</sub> + r<sup>w</sup>/<sub>||w||</sub></i>, then |<i>r</i>| is the distance
 * Multiply both sides by <i>w<sup>T</sup></i> and add <i>b</i>
 * Left hand side: <i>w<sup>T</sup>x + b = h<sub>w,b</sub>(x)</i>
 * Right hand side: <i>w<sup>T</sup>x<sub>âŠ¥</sub> + r<sup>w<sup>T</sup>w</sup>/<sub>||w||</sub> + b = 0 + r||w||</i>

 ![image](https://user-images.githubusercontent.com/122149118/223786301-5f6ed27c-b8c5-4d12-a1db-dcc0f32bc4b7.png)

 ## Optimization

  * Optimal weight <i>w</i> and bias <i>b</i>
     - Classifies points correctly as well as achieves the largest possible margin
     - **Hard margin SVM** - assumes linear seperability
     - Soft margin SVM - extends to non-separable cases
     - Nonlinear transform & kernel trick

 ![image](https://user-images.githubusercontent.com/122149118/223787348-6ba03e2b-d9af-4cc8-b1ad-8fe6beb17511.png)

 ì´ë ‡ê²Œ ì„¤ì •í•œ margin ì¦‰, hyper planeìœ¼ë¡œë¶€í„° ë–¨ì–´ì ¸ ìˆëŠ” support vector ê°„ ê±°ë¦¬ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ì„œëŠ” SVMì—ì„œëŠ” ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ oprimization ë°©ì‹ì„ ì´ìš©í•œë‹¤. 
 ê·¸ ì¤‘ì˜ í•˜ë‚˜ë¡œ hard margin SVMì´ ìˆë‹¤.
 hard margin SVM ê°™ì€ ê²½ìš° ì´ sampleë“¤ì´ linear separableí•˜ë‹¤ëŠ” ê²ƒì„ ê°€ì •í•˜ê³  ìˆë‹¤.
 ì¦‰, ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ hyper planeì´ ìˆê³  ê° support vectorë“¤ì„ ì—°ê²°í•˜ëŠ” planeë“¤ì´ ìˆë‹¤ë¼ê³  í–ˆì„ ë•Œ ê·¸ ë‘˜ ì‚¬ì´ì˜ ì˜ì—­ì—ì„œëŠ” ì–´ë– í•œ sampleë„ ìˆì§€ ì•ŠëŠ” ê²ƒì„ ì˜ë¯¸í•˜ê²Œ ëœë‹¤.
 ë°˜ëŒ€ë¡œ soft margin SVMê³¼ ê°™ì€ ê²½ìš° ì–´ëŠ ì •ë„ì˜ errorë¥¼ ìš©ì¸í•˜ëŠ” ë²”ìœ„ì—ì„œì˜ optimization ë°©ë²•ì„ ì„¤ëª…í•œë‹¤.
 SVMì—ì„œëŠ” nonlinear transform, kernel trickì„ ì´ìš©í•œ optimization ë°©ì‹ ì—­ì‹œ ì‚¬ìš©í•˜ê³  ìˆë‹¤.
 ì´ëŸ¬í•œ linear transformê³¼ ê°™ì€ ê²½ìš° SVMì´ linear separableí•œ hyper planeì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— linearí•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ë‹¨ì ì„ ê·¹ë³µí•˜ê¸° ìœ„í•˜ì—¬ ë§Œë“¤ì–´ì¡Œë‹¤.
 ![image](https://user-images.githubusercontent.com/122149118/223787197-2cf15c51-51e6-451e-91fa-f2b3a524e8cb.png)
 ì¦‰, SVMì„ ì‚¬ìš©í•˜ê²Œ ë  ë•Œ kernelì„ ì´ìš©í•˜ì—¬ ì˜ˆì»¨ë° í˜„ì¬ data sampleë“¤ì´ ìœ„ì™€ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆë‹¤ê³  í•  ë•Œ ì´ sampleë“¤ì€ ê²°ì½” í•˜ë‚˜ì˜ ì¼ì§ì„ ìœ¼ë¡œ ì„ í˜• modelë¡œì„œ classificationì„ ìˆ˜í–‰í•˜ê¸°ê°€ ì–´ë µë‹¤.
 í•˜ì§€ë§Œ nonlinear transform, í˜¹ì€ kernel trickì„ ì´ìš©í•˜ê²Œ ë˜ë©´ 2ì°¨ì›ì˜ sampleë“¤ì„ ë³´ë‹¤ ë” ê³ ì°¨ì›ì˜ sampleë“¤ë¡œ mappingì„ í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ê²Œ ëœë‹¤.
 ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ 3ì°¨ì› ê³µê°„ìœ¼ë¡œ sampleë“¤ì„ mappingí•  ìˆ˜ ìˆë‹¤ê³  í•˜ë©´ 2ì°¨ì›ì˜ hyper planeì„ ì´ìš©í•˜ì—¬ positive sampleê³¼ negative sampleì„ ìˆ˜ì§ìœ¼ë¡œ ë¶„í• í•˜ì—¬ êµ¬ë¶„í•  ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.

## Optimization
### constraints: linearly separable; hard-margin linear SVM

 <i>h(x) = w<sup>T</sup>x + b â‰¥ 1 for y = 1
 h(x) = w<sup>T</sup>x + b â‰¤ -1 for y = -1</i>
 â¬‡{: .center}
 
 support vector ê°’ë“¤ì— ì˜í•´ì„œ hypothesis h(x)ê°€ ì–´ë–»ê²Œ ê²°ì •ì´ ë˜ëŠ”ì§€ ì•Œì•„ë³¸ë‹¤.

##### Center
{: .center}

##### Right
{: .right}

## 2. Body Text

Lorem ipsum dolor sit amet, [test link](https://www.google.com) adipiscing elit. **This is strong.** Nullam dignissim convallis est. Quisque aliquam. *This is emphasized.* Donec faucibus. Nunc iaculis suscipit dui. 5<sup>3</sup> = 125. Water is H<sub>2</sub>O. Nam sit amet sem. Aliquam libero nisi, imperdiet at, tincidunt nec, gravida vehicula, nisl. <u>Underline</u>. Maecenas ornare tortor. Donec sed tellus eget `COPY filename` sapien fringilla nonummy. Mauris a ante. Suspendisse quam sem, consequat at, <del>Dinnerâ€™s at 5:00.</del> commodo vitae, feugiat in, nunc. Morbi imperdiet augue <mark>mark element</mark> quis tellus.

## 3. Images

![Large example image](http://placehold.it/800x400 "Large example image")

![Medium example image](http://placehold.it/400x200 "Medium example image")
![Small example image](http://placehold.it/200x200 "Small example image")

### 3-1. Image Alignment

![Center example image](http://placehold.it/200x200 "Center")
{: .center}

## 4. Blockquotes

> Lorem ipsum dolor sit amet, test link adipiscing elit. Nullam dignissim convallis est. Quisque aliquam.

## 5. List Types

### Unordered List

* Lorem ipsum dolor sit amet, consectetur adipiscing elit.
* Nam ultrices nunc in nisi pellentesque ultricies. Cras scelerisque ipsum in ante laoreet viverra. Pellentesque eget quam et augue molestie tincidunt ac ut ex. Sed quis velit vulputate, rutrum nisl sit amet, molestie neque. Vivamus sed augue at turpis suscipit fringilla.
* Integer pretium nisl vitae justo aliquam, at varius nisi blandit.
  1. Nunc vehicula nulla ac odio gravida vestibulum sed nec mauris.
  2. Duis at diam eget arcu dapibus consequat.
* Etiam vel elit in purus iaculis pretium.

### Ordered List

1. Quisque ullamcorper leo non ex pretium, in fermentum libero imperdiet.
2. Donec eu nulla euismod, rhoncus ipsum nec, faucibus elit.
3. Nam blandit purus gravida, accumsan sem in, lacinia orci.
  * Duis congue dui nec nisi posuere, at luctus velit semper.
  * Suspendisse in lorem id lacus elementum pretium nec vel nibh.
4. Aliquam eget ipsum laoreet, maximus risus vitae, iaculis leo.

### Definition Lists

kramdown
: A Markdown-superset converter

Maruku
: Another Markdown-superset converter

## 6. Tables

| Header1 | Header2 | Header3 |
|:--------|:-------:|--------:|
| cell1   | cell2   | cell3   |
| cell4   | cell5   | cell6   |
|----
| cell1   | cell2   | cell3   |
| cell4   | cell5   | cell6   |
|=====
| Foot1   | Foot2   | Foot3


## 7. Code Snippets

### Highlighted Code Blocks

```css
#container {
  float: left;
  margin: 0 -240px 0 0;
  width: 100%;
}
```

### Standard code block

    <div id="awesome">
      <p>This is great isn't it?</p>
    </div>
