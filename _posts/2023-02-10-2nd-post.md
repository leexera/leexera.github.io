---
layout: post
title: "Convolutional Neural Networks and Image Classification"
description: "KAIST 주재걸 교수님"
date: 2023-02-10
tags: study
comments: true
---
---
## Introduction
convolution의 핵심 원리인 전체 이미지 상에서 부분, 부분 패턴을 추출하고 이를 bottom up 방식으로 잘 통합하여 점점 더 복잡한 패턴을 추출함으로써 고차원적인 다양한 물체들을 인식할 수 있도록 하는 기법을 이해

convolutional neural network를 기반으로 한 실제 많이 활용되고 있는 VGGNet이나 ResNet, 특히 ResNet에서 skip connection이라는 핵심 아이디어를 통해 최근 Deep learning에서 굉장히 많이 layer를 늘림으로써 점점 더 Deep learning의 능력을 한층 더 발전


# ③ 합성곱 신경망(CNN)의 동작 원리 및 이를 통한 이미지 분류

### Various Neural Network Architectures

![image](https://user-images.githubusercontent.com/122149118/217877402-aed4ac7b-2dd2-4a6c-9db1-fef8fe1a60d8.png) 
###### Christian Wojek, Stefan Walk, Stefan Roth, Konrad Schindler, Bernt Schiele: Monocular Visual Scene Understanding: Understanding Multi-Object Traffic Scenes. IEEE Trans. Pattern Anal. Mach. Intell. 35(4): 882-897 (2013)
 multi-layer perceptron의 경우 각 layer에서 입력 노드가 출력 노드 모두와 특정한 가중치의 형태로 연결이 된 network를 fully-connected layer 또는 fully-connected neural network

 computer vision 혹은 영상 처리에서 많이 쓰이는 convolutional neural network 줄여서 ConvNet, CNN이라는 구조를 가진 Deep learning 모델

 sequence data나 Time-Series, 시계열 data에 대해 적절하게 적용될 수 있는 RNN 기반의 구조

#### ConvNets

![image](https://user-images.githubusercontent.com/122149118/217981739-8e122b73-49b8-4a1b-a3ea-7c6a3a54702b.png)
###### [Krizhevsky, Sutskever, Hinton, 2012]

 computer vision task의 경우 convolution neural network가 거의 default로 사용되는 핵심 Deep learning 구조

 이미지 분류에서 주어진 이미지가 치타인지, 호랑이인지, 강아지인지,자동차인지를 분류하는 task 또는 자연어로 된 query문을 주었을 때 그 query에 부합하는 관련성이 높은 이미지들을 검색해 주는 이미지 검색 문제

![image](https://user-images.githubusercontent.com/122149118/218243511-9e59fcb1-a2c6-4ddb-b8cd-258e19579114.png)
###### [Toshev, Szegedy 2014], [Guo et al. 2014] 

 사람 신체를 대상으로 하여 사람의 자세가 어떠한지를 추정하는 자세 추정 문제

 게임 화면들도 하나하나의 사진이라고 본다면 여기서 필요로하는 정보를 인식하는 용도로 활용될 수 있음

![image](https://user-images.githubusercontent.com/122149118/218243625-99d9d262-3ecd-4ae6-8490-15c51802ee7d.png)
###### [Ciresan et al. 2013], [Sermanet et al. 2011] 

 의료 영상이나 문자 인식의 경우에도 핵심 모델로 사용

![image](https://user-images.githubusercontent.com/122149118/218243673-36a8243f-f4cb-40b9-9cd5-1111d9dff0b6.png)
###### [BBC News. (2016, March 12). Artificial intelligence: Google’s AlphaGo beats Go master Lee Se-dol.] 

 알파고의 경우에도 핵심 알고리즘으로서의 강화 학습을 실행하기 위해 먼저 바둑판을 한 장의 사진으로 보고 사진에서 총 19 by 19 라는 pixel 수를 가지고 각각의 pixel에서 흑돌 또는 백돌이 놓여져 있거나 돌이 없는 세 개 중에 하나로 pixel 값이 구성되는 작은 이미지라고 볼 수 있음

 이미지를 잘 인식하고 필요한 정보를 추출하는 데에 Convnet이 활용되고 여기서 추출된 정보를 바탕으로 강화학습을 통해 최적의 의사결정을 하는 방식으로 알파고 알고리즘이 동작

#### Challenges in Computer Vision Tasks
##### 다양한 computer vision task의 Deep learning 특히 convolution neural network이 나오기 전까지 다양한 approach들에서 겪었던 어려움

![image](https://user-images.githubusercontent.com/122149118/218434093-9f18056d-f988-4541-aef8-e77f844d3ff2.png)

 가령 모든 사진들이 고양이라고 인식하기 위해서 주어진 이미지가 어두웠을 때나 밝았을 때(Illumination), 다양한 종류의 고양이의 사진들이 있을 때(Intra-class varivation), 그리고 고양이의 전체 형태 중 많은 부분이 가려져 있을 때(Occlusion), 평범하지 않은 자세를 취하고 있을 때나(Deformation) 배경과 잘 구분이 되지 않는 경우(Background Clutter)에도 robust하게 영상 인식을 하는 알고리즘이 잘 동작할 수 있어야 함

#### Basic Idea of ConvNets

![image](https://user-images.githubusercontent.com/122149118/218436201-e0afa7ac-572f-4f36-81e2-54c6eb5fcb59.png)

 convolution neural network 이전에는 이런 다양한 challenge들에 대해 적절히 대응하지 못했음

 convolution neural network 등장이후 핵심 아이디어로서 다양한 변화요소들이 한 이미지 내에 존재할 수 있는 가운데에 특정한 하나의 물체를 규정짓는 부분, 부분의 요소 패턴들이 있다라는 것을 활용하여 요소 패턴들을 잘 검출하고 인식하는 과정을 통해 Convnet이 동작하게 됨

 2가지의 배경 또는 고양이의 포즈 등이 상이한 경우에도 고양이를 구성하는 귀는 공통적으로 일관되게 나타나고 있고 눈의 경우에도 일관되기 나타나는 것을 알 수 있음

 고양이가 특정한 자세를 취하거나 색깔을 가지고 여러 배경들이 있었을 때에 모든 요소들을 다 일일이 규정해서 고양이라는 특성을 정의하려고 하기 보단 고양이에게서 일관되게 나타나는 부분 별 특징들을 bottom up 방식으로 잘 검출해내고 그 정보들을 잘조합하여 최종적으로 고양이를 일관되게 인식할 수 있도록 하는 방식으로 Convnet이 동작하게 됨

#### Power of CNN

![image](https://user-images.githubusercontent.com/122149118/218439250-6ef894bc-078e-4116-94a4-b0ccbeecb539.png)
###### Langlotz et al., (2019). A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging: From the 2018 NIH/RSNA/ACR/The Academy Workshop. Radiology. 291. 190613. 10.1148/radiol.2019190613.

 computer vision task 내에서 주어진 이미지가 정해놓은 특정 카테고리들 중에 어떤 카테고리에 속하는가를 분류하는 이미지 classification task를 굉장히 오래 전부터 사람들이 일종의 대회를 열어 task를 수행해 내고자 하는 노력을 꾸준히 기울여옴

 2012년도부터 convolution neural network 기반의 Deep learning을 활용한 이미지 분류 성능이 매우 빠르게 향상되어 왔음

 상당히 높은 error를 내는 데에 이 알고리즘 성능이 그쳐왔다면 2012년도에 AlexNet이라는 모델이 나온 이후로 성능이 급격히 좋아져 결국 convolution neural network 기반의 Deep learning 기술이 점차 발전의 발전을 거듭하며 2015년도에는 비로소 사람의 물체 인식 성능보다 더 좋아지는 양상을 보임

### How ConvNet work
#### A Toy ConvNet: X's and O's

![image](https://user-images.githubusercontent.com/122149118/218440566-2b56999c-0580-40d1-80bd-c2fcde8a1b6b.png)

 어떠한 size의 이미지가 있을 때 그것이 'X'표를 의미하는지 'O'표를 의미하는지 분류하는 task를 수행

![image](https://user-images.githubusercontent.com/122149118/218441035-125cc9eb-1f72-45dc-9a34-fb6b19497246.png)

 'X'나 'O'라는 물체가 정확하게 이미지 상의 한 가운데에 있고 각도도 전혀 틀어지지 않은 경우에 'X', 'O'라고 잘 인식할 수 있는 상황

##### Trickier Cases
![image](https://user-images.githubusercontent.com/122149118/218444234-33ef28ed-d526-42fd-8bd7-e826fb2ebf40.png)

 'X'라는 물체가 한쪽으로 치우치거나(Translation) 크기가 작거나(Scaling) 각도가 틀어져 있거나(Rotation) 또는 더 굵은 형태로 나타내어지는(Weight) 다양한 변화 요소들에도 일관되게 'X'라고 잘 분류할 수 있어야 함

 'O'에 대해서 마찬가지로 변화 요소들에 일관되게 잘 분류할 수 있어야 하는 요구사항을 가짐

##### Deciding is Hard

![image](https://user-images.githubusercontent.com/122149118/218444937-cbba67a4-a7ad-4b56-a018-86c66451ad74.png) 

 가장 표준화된 형태의 'X' 그리고 조금 변형된 형태의 'X' 2개가 여전히 같은 class에 속한다고 구분하기 위한 방법

##### What Computers See

![image](https://user-images.githubusercontent.com/122149118/218449131-0330a565-f1cf-4a47-ba91-fad9c7690807.png)

 주어진 이미지는 Deep learning이나 기타 머신러닝 알고리즘의 입력으로 줄 때 하나의 숫자들로 이루어진 이러한 2차원 배열로서 나타나게 됨

 하얀색 pixel에 해당하는 값을 1이라고 하고 어두운 pixel에 해당하는 값을 -1이라고 지정

![image](https://user-images.githubusercontent.com/122149118/218449652-894b66f7-bb65-4279-b98a-b1f0543ecc36.png)

 2개의 이미지를 그대로 포개었을 때 수많은 부분들 중에서 빨간색으로 표기한 부분들이 실제로 pixel 값이 다른 부분에 해당되므로 2개의 이미지를 일관되게 'X'라고 인식하기에 어려움

##### Computers are Literal 

![image](https://user-images.githubusercontent.com/122149118/218450309-d514b5f7-2698-4d65-a1bf-a01f710b0f55.png)

##### ConvNets Match Pieces of the Image

![image](https://user-images.githubusercontent.com/122149118/218450682-8a4da507-9289-4dcb-a10e-143d1d97d82e.png)

 그럼에도 불구하고 크게 보았을 때 'X'는 부분, 부분의 요소들을 보면 일관된 패턴들이 존재하는 것을 알 수 있음

 'X'라는 전체 모양에서 좌측 상단을 보면 사선 2 by 2라는 작은 size의 패치는 왼쪽이나 오른쪽에서 공통적으로 나타나고 있으며 가운데에 존재하는 작은 'X'의 형태와 좌측 하단에 존재하는 각도로 이루어진 이러한 사선도 2개의 이미지에서 일관되게 공통적으로 등장하는 것을 알 수 있음 

![image](https://user-images.githubusercontent.com/122149118/218451314-55a282b9-c49e-41b2-b151-6de77a9562c7.png)

 이에 착안한 convolution neural network는 특정 class에 존재할 수 있는 작은 특정 패턴들을 정의하고 패턴들이 주어진 이미지 상에 있는지를 판단하게 됨

 위와 같은 3 by 3 size의 패턴들을 대표적인 예시로 들 수 있음

![image](https://user-images.githubusercontent.com/122149118/218451966-36525dee-87df-4d08-94dd-cfd90bc172ea.png)

 'X'라는 큰 size의 물체의 형태를 정의하는 작은 size의 부분적인 패턴을 위와 같이 정의했다면 해당하는 특정 패턴들이 주어진 이미지 상에 어느 위치에 나타나는지 그리고 만약 패턴이 나타난다면 얼마나 정확하게 혹을 얼마나 패턴이 강하게 나타났는지 생각해볼 수 있음

 패턴을 파란색 영역에 위치시켜보았을 때 다른 부분들은 모두 맞지만 좌측 상단에 있는 하얀색 pixel이 일치하지 않는 것을 알 수 있음

![image](https://user-images.githubusercontent.com/122149118/218452676-b9261e90-64eb-4827-b95b-c5978b2145cd.png)

 다른 영역에 패턴을 위치시키면 패턴이 완벽히 일치되는 것을 확인할 수 있음

![image](https://user-images.githubusercontent.com/122149118/218452897-14b5b27a-50c4-48a8-a761-43bfcd5cc444.png)

![image](https://user-images.githubusercontent.com/122149118/218453127-d228d5ea-c81d-4fad-b454-839d2c89b3ef.png)

 가운데 패턴, 세 번째로 정의된 패턴 또한 이미지 상에서 패턴이 매칭되는 특정한 위치들이 존재

![image](https://user-images.githubusercontent.com/122149118/218453338-768ab3a1-8c24-4b79-a255-9093c431d210.png)

![image](https://user-images.githubusercontent.com/122149118/218455664-8608e2fe-7b37-4f27-86b5-6ff0b4046bbe.png)

##### Filtering: the Math Behind the Match

![image](https://user-images.githubusercontent.com/122149118/218456757-938ea8dd-3c91-4ef2-8450-5d5aeb3833c6.png)

 주어진 이미지 상에서 작은 3 by 3 size의 이미지 패치를 특정한 위치에 오버랩을 시켰을 때에 해당하는 위치에서 주어진 특정 패턴과의 매칭되는 정도를 정량적으로 정의해볼 수 있음

![image](https://user-images.githubusercontent.com/122149118/218456962-86338038-d644-4681-a03a-661a0707391d.png)

 수행 과정은 3 by 3 패치를 주어진 이미지에 오버랩 시킨 후 패치에 정의된 pixel 값과 이미지의 같은 위치에 있는 값을 곱함

![image](https://user-images.githubusercontent.com/122149118/218457109-743ac7a0-e2ef-4778-9272-15f5cb10ff34.png)

 위의 예시에서는 1과 1이 곱해져 +1이라는 값 도출

![image](https://user-images.githubusercontent.com/122149118/218457203-93f9f5bb-a714-4105-bc97-af2acb9a9890.png)

 옆의 pixel의 경우 일치하기 때문에 -1과 -1을 곱해주면 +1이라는 값으로 매칭이 됐다, 일치한다는 정보를 알 수 있음 

![image](https://user-images.githubusercontent.com/122149118/218459953-e7721775-e957-44ce-a163-a38e93dd3a6e.png)

 이러한 방식으로 파란색 사각형 내에 3 by 3 패치를 오버랩시켜 각 pixel 별로 매칭 여부를 두 값들 간의 곱셈으로 알 수 있음

![image](https://user-images.githubusercontent.com/122149118/218466127-8035d890-afc2-45af-a5ec-47baff627f01.png)

![image](https://user-images.githubusercontent.com/122149118/218466251-8cbf4525-f765-4367-b532-8dbda1008343.png)

![image](https://user-images.githubusercontent.com/122149118/218466368-576626b7-675e-485c-b196-a337ca8434a4.png)

![image](https://user-images.githubusercontent.com/122149118/218466499-cb4844ab-52c5-477a-ab5c-836f3f5b9417.png)

![image](https://user-images.githubusercontent.com/122149118/218466607-33744395-6837-4dea-88fc-c414849313d6.png)

![image](https://user-images.githubusercontent.com/122149118/218466752-ae936a27-c2e4-4ee2-90c9-63eaa8a2a89b.png)

![image](https://user-images.githubusercontent.com/122149118/218466912-c3e99275-e9ae-43b7-9786-bef802c51040.png)

 이 값을 다 합한 후 이 패치의 총 pixel의 개수인 9로 나눈 것이 총 매칭된 정도로서 위의 위치의 경우 100% 매칭 값을 얻을 수 있음

![image](https://user-images.githubusercontent.com/122149118/218467719-bcfc64f9-a675-426e-a161-e77eea4f2194.png)

![image](https://user-images.githubusercontent.com/122149118/218468006-678a6b11-b25f-4e84-9c84-15a541d97656.png)

 이전의 예시와 동일한 패턴을 다른 위치에 오버랩 시켰을 때 매칭되는 정도를 계산해보면 현재 pixel 위치는 주어진 이미지 패치에 있는 -1과 이미지의 1이 매칭되지 않기 때문에 두 개의 값을 곱했을 때 -1이라는 값이 도출됨

![image](https://user-images.githubusercontent.com/122149118/218469201-7cfc8d09-4b75-48d6-ac34-585c4f84650e.png)

 매칭되지 않은 pixel의 위치가 두 군데에서 발견

![image](https://user-images.githubusercontent.com/122149118/218469563-935c13bb-05ba-4b87-a369-2033b4fc3b00.png)

 55%의 매칭 정도를 특정 파란색 위치에 대해서 얻을 수 있음

 매칭의 정도를 주어진 이미지에 3 by 3 패치를 가능한 모든 위치들에 위치시켜 해당 매칭 되는 정도를 또 다른 이미지 형태로 얻어낼 수 있게 됨

##### Convolution: Trying Every Possible Match

![image](https://user-images.githubusercontent.com/122149118/218470635-6bb509d8-e430-473a-bedb-edb95f447a08.png)

 55% 매칭 정도는 가운데 pixel 위치의값을 기록하는 식으로 주어진 행렬을 완성하게 되면 매칭의 정도를 나타내는 또 다른 이미지를 얻을 수 있음

 매칭의 정도를 나타내는 이러한 결과 이미지를 activation map, 활성화 지도라고 함

 특정 활성화 지도는 특정한 covolution filter 또는 위와 같은 3 by 3 패치를 주어진 입력 이미지에 가능한 모든 위치에 오버랩 시켜 매칭 되는 정도를 얻었을 때 나오는 결과 이미지

![image](https://user-images.githubusercontent.com/122149118/218471403-7d019c27-a642-4b44-82ca-65a6c42c3fb2.png)

 이러한 연산을 convolution 연산 혹은 operation이라고 정의

![image](https://user-images.githubusercontent.com/122149118/218471667-b7286407-481b-4399-9711-9de2af135d71.png)

 같은 이미지에 특정 패턴들에 대한 각기 나름의 활성화 지도, activation map을 얻을 수 있게됨

activation map을 얻기 위해서
1. Overlap the convolution filter and the image patch.
 특정 convolution filter를 이미지 상의 각각의 특정 위치에 위치시켜 그에 해당하는 이미지 패치와 align
2. Multiply each image pixel by the corresponding filter coefficient.
 align한 pixel 값들을 서로 곱함
3. Add them up.
4. Divide by the total number of pixels in the feature. (optional)
 다 더한 후 total pixel 개수로 나누어 줌

4번 과정은 보통의 경우 생략하는 경우가 많음

그런 경우 앞선 예시에서 매칭의 최대 값은 9가 될 것

#### Convolution Layer

![image](https://user-images.githubusercontent.com/122149118/218474182-eaaf5dc3-9243-4d42-9186-21358cab6462.png)

 하나의 convolution layer를 생각해볼 때 convolution layer에서는 여러 개의 특정한 3 by 3 size의 고유한 패턴을 가지는 다수의 filter 혹은 convolution filter가 존재

 convolution filter 혹은 패치를 각각 주어진 입력 이미지에 적용했을 때 filter별로 activation map이 output으로 등장하게 됨

 한 장, 한 장의 activation map을 하나의 이미지라고 본다면 주어진 이미지 한 장을 가지고 filter 개수만큼의 이미지를 만들어냄

![image](https://user-images.githubusercontent.com/122149118/218481432-552b5f41-5604-4d3a-89e2-3b8201d7957e.png)

 convolution layer를 여러 계층으로 쌓았을 때 어떠한 deep neural network로서의 convolution neural network을 구성했을 때에 한 convolution layer 내에 주어지는 입력이 꼭 한 장의 사진뿐만이 아니라 여러 장의 사진으로 이루어진 입력을 생각해볼 수 있음

 위와 같이 입력 이미지가 총 세 장의 이미지로 구성되어있는 경우에, 여기서 세장의 이미지가 채널이라고 하며 세 개의 채널로 이루어진 입력 이미지가 있을 때 특정한 하나의 3 by 3 size convolution filter는 첫 번째 채널 혹은 첫 번째 장의 이미지에 오버랩을 할 filter 패치와 두 번재 채널에 오버랩을 할 convolution filter 패치, 세 번째 채널 즉, 입력 채널 각각에 대응하는 3 by 3 이미지 패치가 하나의 convolution filter를 이루게 되고 이 경우 하나의 activation 값을 얻으려고 하면 filter를 각각 대응되는 곳에 오버랩시켜 해당하는 값들끼리 곱하고 모두 더하는 과정을 각각의 채널에서 수행한 후에 모두 다 합침

 최종적인 매칭 값이 scalar 값 하나로 도출될 것

 이런 방식으로 진행하여 하나의 convolution filter에 대해 역시 또 한 장의 사진 혹은 activation map을 만들어냄

![image](https://user-images.githubusercontent.com/122149118/218485417-aae3cb95-0adf-4f50-b235-55ce743fd12e.png)

 다른 시각으로 바라보았을 때, 주어진 입력 이미지가 32 by 32의 가로, 세로 size를 가지고 채널 혹은 depth라고 부르기도 하는데 depth가 3채널, 3인 위와 같은 입력 이미지가 주어진다면 하나의 convolution filter는 filter의 가로, 세로의 크기가 3 by 3이 아닌 5 by 5 size의 convolution filter로 이루어져 있다면 한 convolution filter는 입력 채널 3에 대응하는 같은 채널 개수를 가지는 형태로 한 convolution filter가 구성되어 있을 것

![image](https://user-images.githubusercontent.com/122149118/218485604-98dcd213-96a9-4734-92f3-5cd24f6ef5df.png)

 convolution filter를 주어진 특정한 위치에 오버랩을 시켰을 때의 convolution filter coefficients와 pixel 값을 모두 곱하고 다 더하게 되면 scalar 값 하나가 도출될 것이고 filter 위치를 바꾸었을 때 각각 scalar 값 하나에 activation 값을 도출해 결과적으로 한 장의 사진을 만들어낼 수가 있는 것

 ![image](https://user-images.githubusercontent.com/122149118/218487112-1df52e0c-21c9-4b08-9090-f74942b4932b.png)

 한 convolution layer에서는 5 by 5 by 3의 size를 가지는 하나의 convolution filter가 여러 개, 다수의 convolution filter가 존재할 수 있게 되고 두 번째 convolution filter가 있을 때 그 filter가 이미지의 여러 위치들에 걸쳐서 activation 값들을 도출해내고 그걸 또 하나의 이미지로, output activation map으로 구성하게되면 또 다른 activation map 한 장이 두 번째 filter에 대해서 나오게 됨

![image](https://user-images.githubusercontent.com/122149118/218488494-2a37aafe-5a0f-4ef4-8962-8e727f0637fe.png)

 주어진 convolution layer에서의 convolution filter가 3 개일 때, 위처럼 입력 이미지는 3 채널 입력 이미지가 주어졌고 한 convolution filter는 역시 3 채널의 filter로 구성되어 있고 각각의 convolution filter들이 activation map 한 장씩을 만들어내어 총 output activation map의 채널 수는 filter 개수와 동일한 개수로 나오게 됨

![image](https://user-images.githubusercontent.com/122149118/218489315-d4a5170e-8fa1-4381-a48b-074d6a4793b8.png)

 6개의 5 by 5 size의 convolution filter가 있다면, 입력 채널의 수는 입력 activation map의 채널 수와 동일하기 때문에 생략

 따라서 실제로 한 convolution filter는 5 by 5 by 3 size로 구성되고 이것이 6개가 존재하는 convolution layer의 경우 output activation map은 총 여섯 개의 서로 다른 사진들로 출력이 구성됨

![image](https://user-images.githubusercontent.com/122149118/218490104-58168de3-337d-4fc4-98cd-dff55b823a27.png)

![image](https://user-images.githubusercontent.com/122149118/218490476-c263338a-bac6-4525-97b7-47583b2cb624.png)

 convolution layer를 위와 같이 쭉 쌓았을 때 만약 첫 번째 convolution layer의 입력 이미지의 채널 수가 3이고 filter 수도 3이라고 하면 output activation map의 채널 수는 3이 됨

 다음 layer로 적용되는 convolution filter는 역시 또 한 filter에 주어진 입력 이미지의 채널 수와 같은 채널 수를 가져야하므로 한 filter가 3 장의 사진 혹은 채널이 3개인 형태로 구성됨

 두 번째 convolution filter에서 filter 수는 하나라고 한다면 최종적으로는 한 장의 output activation map을 얻게 됨

#### Pooling

![image](https://user-images.githubusercontent.com/122149118/218491799-c75db6eb-df5f-4c64-ba06-831101df2784.png)

 convolution neural network을 구성하는
##### Center
{: .center}

##### Right
{: .right}

## 2. Body Text

Lorem ipsum dolor sit amet, [test link](https://www.google.com) adipiscing elit. **This is strong.** Nullam dignissim convallis est. Quisque aliquam. *This is emphasized.* Donec faucibus. Nunc iaculis suscipit dui. 5<sup>3</sup> = 125. Water is H<sub>2</sub>O. Nam sit amet sem. Aliquam libero nisi, imperdiet at, tincidunt nec, gravida vehicula, nisl. <u>Underline</u>. Maecenas ornare tortor. Donec sed tellus eget `COPY filename` sapien fringilla nonummy. Mauris a ante. Suspendisse quam sem, consequat at, <del>Dinner’s at 5:00.</del> commodo vitae, feugiat in, nunc. Morbi imperdiet augue <mark>mark element</mark> quis tellus.

## 3. Images

![Large example image](http://placehold.it/800x400 "Large example image")

![Medium example image](http://placehold.it/400x200 "Medium example image")
![Small example image](http://placehold.it/200x200 "Small example image")

### 3-1. Image Alignment

![Center example image](http://placehold.it/200x200 "Center")
{: .center}

## 4. Blockquotes

> Lorem ipsum dolor sit amet, test link adipiscing elit. Nullam dignissim convallis est. Quisque aliquam.

## 5. List Types

### Unordered List

* Lorem ipsum dolor sit amet, consectetur adipiscing elit.
* Nam ultrices nunc in nisi pellentesque ultricies. Cras scelerisque ipsum in ante laoreet viverra. Pellentesque eget quam et augue molestie tincidunt ac ut ex. Sed quis velit vulputate, rutrum nisl sit amet, molestie neque. Vivamus sed augue at turpis suscipit fringilla.
* Integer pretium nisl vitae justo aliquam, at varius nisi blandit.
  1. Nunc vehicula nulla ac odio gravida vestibulum sed nec mauris.
  2. Duis at diam eget arcu dapibus consequat.
* Etiam vel elit in purus iaculis pretium.

### Ordered List

1. Quisque ullamcorper leo non ex pretium, in fermentum libero imperdiet.
2. Donec eu nulla euismod, rhoncus ipsum nec, faucibus elit.
3. Nam blandit purus gravida, accumsan sem in, lacinia orci.
  * Duis congue dui nec nisi posuere, at luctus velit semper.
  * Suspendisse in lorem id lacus elementum pretium nec vel nibh.
4. Aliquam eget ipsum laoreet, maximus risus vitae, iaculis leo.

### Definition Lists

Deformation
: A Markdown-superset converter

Maruku
: Another Markdown-superset converter

## 6. Tables

| Header1 | Header2 | Header3 |
|:--------|:-------:|--------:|
| cell1   | cell2   | cell3   |
| cell4   | cell5   | cell6   |
|----
| cell1   | cell2   | cell3   |
| cell4   | cell5   | cell6   |
|=====
| Foot1   | Foot2   | Foot3


## 7. Code Snippets

### Highlighted Code Blocks

```css
#container {
  float: left;
  margin: 0 -240px 0 0;
  width: 100%;
}
```

### Standard code block

    <div id="awesome">
      <p>This is great isn't it?</p>
    </div>
