---
layout: post
title: "Convolutional Neural Networks and Image Classification"
description: "KAIST 주재걸 교수님"
date: 2023-02-10
tags: study
comments: true
---
---
## Introduction
convolution의 핵심 원리인 전체 이미지 상에서 부분, 부분 패턴을 추출하고 이를 bottom up 방식으로 잘 통합하여 점점 더 복잡한 패턴을 추출함으로써 고차원적인 다양한 물체들을 인식할 수 있도록 하는 기법을 이해한다.

convolutional neural network를 기반으로 한 실제 많이 활용되고 있는 VGGNet이나 ResNet, 특히 ResNet에서 skip connection이라는 핵심 아이디어를 통해 최근 Deep learning에서 굉장히 많이 layer를 늘림으로써 점점 더 Deep learning의 능력을 한층 더 발전되었다.


# ③ 합성곱 신경망(CNN)의 동작 원리 및 이를 통한 이미지 분류

### Various Neural Network Architectures

![image](https://user-images.githubusercontent.com/122149118/217877402-aed4ac7b-2dd2-4a6c-9db1-fef8fe1a60d8.png) 
###### Christian Wojek, Stefan Walk, Stefan Roth, Konrad Schindler, Bernt Schiele: Monocular Visual Scene Understanding: Understanding Multi-Object Traffic Scenes. IEEE Trans. Pattern Anal. Mach. Intell. 35(4): 882-897 (2013)
 
 multi-layer perceptron의 경우 각 layer에서 입력 노드가 출력 노드 모두와 특정한 가중치의 형태로 연결이 된 network를 fully-connected layer 또는 fully-connected neural network라고 한다.

 computer vision 혹은 영상 처리에서 많이 쓰이는 convolutional neural network 줄여서 ConvNet, CNN이라는 구조를 가진 Deep learning 모델이다.

 sequence data나 Time-Series, 시계열 data에 대해 적절하게 적용될 수 있는 RNN 기반의 구조이다.

#### ConvNets

![image](https://user-images.githubusercontent.com/122149118/217981739-8e122b73-49b8-4a1b-a3ea-7c6a3a54702b.png)
###### [Krizhevsky, Sutskever, Hinton, 2012]

 computer vision task의 경우 convolution neural network가 거의 default로 사용되는 핵심 Deep learning 구조이다.

 이미지 분류에서 주어진 이미지가 치타인지, 호랑이인지, 강아지인지,자동차인지를 분류하는 task 또는 자연어로 된 query문을 주었을 때 그 query에 부합하는 관련성이 높은 이미지들을 검색해 주는 이미지 검색 문제가 있다.

![image](https://user-images.githubusercontent.com/122149118/218243511-9e59fcb1-a2c6-4ddb-b8cd-258e19579114.png)
###### [Toshev, Szegedy 2014], [Guo et al. 2014] 

 사람 신체를 대상으로 하여 사람의 자세가 어떠한지를 추정하는 자세 추정 문제가 있다.

 게임 화면들도 하나하나의 사진이라고 본다면 여기서 필요로하는 정보를 인식하는 용도로 활용될 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218243625-99d9d262-3ecd-4ae6-8490-15c51802ee7d.png)
###### [Ciresan et al. 2013], [Sermanet et al. 2011] 

 의료 영상이나 문자 인식의 경우에도 핵심 모델로 사용된다.

![image](https://user-images.githubusercontent.com/122149118/218243673-36a8243f-f4cb-40b9-9cd5-1111d9dff0b6.png)
###### [BBC News. (2016, March 12). Artificial intelligence: Google’s AlphaGo beats Go master Lee Se-dol.] 

 알파고의 경우에도 핵심 알고리즘으로서의 강화 학습을 실행하기 위해 먼저 바둑판을 한 장의 사진으로 보고 사진에서 총 19 by 19 라는 pixel 수를 가지고 각각의 pixel에서 흑돌 또는 백돌이 놓여져 있거나 돌이 없는 세 개 중에 하나로 pixel 값이 구성되는 작은 이미지라고 볼 수 있다.

 이미지를 잘 인식하고 필요한 정보를 추출하는 데에 Convnet이 활용되고 여기서 추출된 정보를 바탕으로 강화학습을 통해 최적의 의사결정을 하는 방식으로 알파고 알고리즘이 동작한다.

#### Challenges in Computer Vision Tasks
##### 다양한 computer vision task의 Deep learning 특히 convolution neural network이 나오기 전까지 다양한 approach들에서 겪었던 어려움

![image](https://user-images.githubusercontent.com/122149118/218434093-9f18056d-f988-4541-aef8-e77f844d3ff2.png)

 가령 모든 사진들이 고양이라고 인식하기 위해서 주어진 이미지가 어두웠을 때나 밝았을 때(Illumination), 다양한 종류의 고양이의 사진들이 있을 때(Intra-class varivation), 그리고 고양이의 전체 형태 중 많은 부분이 가려져 있을 때(Occlusion), 평범하지 않은 자세를 취하고 있을 때나(Deformation) 배경과 잘 구분이 되지 않는 경우(Background Clutter)에도 robust하게 영상 인식을 하는 알고리즘이 잘 동작할 수 있어야 한다.

#### Basic Idea of ConvNets

![image](https://user-images.githubusercontent.com/122149118/218436201-e0afa7ac-572f-4f36-81e2-54c6eb5fcb59.png)

 convolution neural network 이전에는 이런 다양한 challenge들에 대해 적절히 대응하지 못했다.

 convolution neural network 등장이후 핵심 아이디어로서 다양한 변화요소들이 한 이미지 내에 존재할 수 있는 가운데에 특정한 하나의 물체를 규정짓는 부분, 부분의 요소 패턴들이 있다라는 것을 활용하여 요소 패턴들을 잘 검출하고 인식하는 과정을 통해 Convnet이 동작하게 되었다.

 2가지의 배경 또는 고양이의 포즈 등이 상이한 경우에도 고양이를 구성하는 귀는 공통적으로 일관되게 나타나고 있고 눈의 경우에도 일관되기 나타나는 것을 알 수 있다.

 고양이가 특정한 자세를 취하거나 색깔을 가지고 여러 배경들이 있었을 때에 모든 요소들을 다 일일이 규정해서 고양이라는 특성을 정의하려고 하기 보단 고양이에게서 일관되게 나타나는 부분 별 특징들을 bottom up 방식으로 잘 검출해내고 그 정보들을 잘조합하여 최종적으로 고양이를 일관되게 인식할 수 있도록 하는 방식으로 Convnet이 동작하게 되었다.

#### Power of CNN

![image](https://user-images.githubusercontent.com/122149118/218439250-6ef894bc-078e-4116-94a4-b0ccbeecb539.png)
###### Langlotz et al., (2019). A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging: From the 2018 NIH/RSNA/ACR/The Academy Workshop. Radiology. 291. 190613. 10.1148/radiol.2019190613.

 computer vision task 내에서 주어진 이미지가 정해놓은 특정 카테고리들 중에 어떤 카테고리에 속하는가를 분류하는 이미지 classification task를 굉장히 오래 전부터 사람들이 일종의 대회를 열어 task를 수행해 내고자 하는 노력을 꾸준히 기울여왔다.

 2012년도부터 convolution neural network 기반의 Deep learning을 활용한 이미지 분류 성능이 매우 빠르게 향상되어 왔다.

 상당히 높은 error를 내는 데에 이 알고리즘 성능이 그쳐왔다면 2012년도에 AlexNet이라는 모델이 나온 이후로 성능이 급격히 좋아져 결국 convolution neural network 기반의 Deep learning 기술이 점차 발전의 발전을 거듭하며 2015년도에는 비로소 사람의 물체 인식 성능보다 더 좋아지는 양상을 보였다.

### How ConvNet work
#### A Toy ConvNet: X's and O's

![image](https://user-images.githubusercontent.com/122149118/218440566-2b56999c-0580-40d1-80bd-c2fcde8a1b6b.png)

 어떠한 size의 이미지가 있을 때 그것이 'X'표를 의미하는지 'O'표를 의미하는지 분류하는 task를 수행하는 예시이다.

![image](https://user-images.githubusercontent.com/122149118/218441035-125cc9eb-1f72-45dc-9a34-fb6b19497246.png)

 'X'나 'O'라는 물체가 정확하게 이미지 상의 한 가운데에 있고 각도도 전혀 틀어지지 않은 경우에 'X', 'O'라고 잘 인식할 수 있는 상황을 보여준다.

##### Trickier Cases
![image](https://user-images.githubusercontent.com/122149118/218444234-33ef28ed-d526-42fd-8bd7-e826fb2ebf40.png)

 'X'라는 물체가 한쪽으로 치우치거나(Translation) 크기가 작거나(Scaling) 각도가 틀어져 있거나(Rotation) 또는 더 굵은 형태로 나타내어지는(Weight) 다양한 변화 요소들에도 일관되게 'X'라고 잘 분류할 수 있어야 한다.

 'O'에 대해서 마찬가지로 변화 요소들에 일관되게 잘 분류할 수 있어야 하는 요구사항을 가진다.

##### Deciding is Hard

![image](https://user-images.githubusercontent.com/122149118/218444937-cbba67a4-a7ad-4b56-a018-86c66451ad74.png) 

 가장 표준화된 형태의 'X' 그리고 조금 변형된 형태의 'X' 2개가 여전히 같은 class에 속한다고 구분하기 위한 방법이다.

##### What Computers See

![image](https://user-images.githubusercontent.com/122149118/218449131-0330a565-f1cf-4a47-ba91-fad9c7690807.png)

 주어진 이미지는 Deep learning이나 기타 머신러닝 알고리즘의 입력으로 줄 때 하나의 숫자들로 이루어진 이러한 2차원 배열로서 나타나게 된다.

 하얀색 pixel에 해당하는 값을 1이라고 하고 어두운 pixel에 해당하는 값을 -1이라고 지정하였다.

![image](https://user-images.githubusercontent.com/122149118/218449652-894b66f7-bb65-4279-b98a-b1f0543ecc36.png)

 2개의 이미지를 그대로 포개었을 때 수많은 부분들 중에서 빨간색으로 표기한 부분들이 실제로 pixel 값이 다른 부분에 해당되므로 2개의 이미지를 일관되게 'X'라고 인식하기에 어렵다.

##### Computers are Literal 

![image](https://user-images.githubusercontent.com/122149118/218450309-d514b5f7-2698-4d65-a1bf-a01f710b0f55.png)

##### ConvNets Match Pieces of the Image

![image](https://user-images.githubusercontent.com/122149118/218450682-8a4da507-9289-4dcb-a10e-143d1d97d82e.png)

 그럼에도 불구하고 크게 보았을 때 'X'는 부분, 부분의 요소들을 보면 일관된 패턴들이 존재하는 것을 알 수 있다.

 'X'라는 전체 모양에서 좌측 상단을 보면 사선 2 by 2라는 작은 size의 패치는 왼쪽이나 오른쪽에서 공통적으로 나타나고 있으며 가운데에 존재하는 작은 'X'의 형태와 좌측 하단에 존재하는 각도로 이루어진 이러한 사선도 2개의 이미지에서 일관되게 공통적으로 등장하는 것을 알 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218451314-55a282b9-c49e-41b2-b151-6de77a9562c7.png)

 이에 착안한 convolution neural network는 특정 class에 존재할 수 있는 작은 특정 패턴들을 정의하고 패턴들이 주어진 이미지 상에 있는지를 판단하게 된다.

 위와 같은 3 by 3 size의 패턴들을 대표적인 예시로 들 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218451966-36525dee-87df-4d08-94dd-cfd90bc172ea.png)

 'X'라는 큰 size의 물체의 형태를 정의하는 작은 size의 부분적인 패턴을 위와 같이 정의했다면 해당하는 특정 패턴들이 주어진 이미지 상에 어느 위치에 나타나는지 그리고 만약 패턴이 나타난다면 얼마나 정확하게 혹을 얼마나 패턴이 강하게 나타났는지 생각해볼 수 있다.

 패턴을 파란색 영역에 위치시켜보았을 때 다른 부분들은 모두 맞지만 좌측 상단에 있는 하얀색 pixel이 일치하지 않는 것을 알 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218452676-b9261e90-64eb-4827-b95b-c5978b2145cd.png)

 다른 영역에 패턴을 위치시키면 패턴이 완벽히 일치되는 것을 확인할 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218452897-14b5b27a-50c4-48a8-a761-43bfcd5cc444.png)

![image](https://user-images.githubusercontent.com/122149118/218453127-d228d5ea-c81d-4fad-b454-839d2c89b3ef.png)

 가운데 패턴, 세 번째로 정의된 패턴 또한 이미지 상에서 패턴이 매칭되는 특정한 위치들이 존재한다.

![image](https://user-images.githubusercontent.com/122149118/218453338-768ab3a1-8c24-4b79-a255-9093c431d210.png)

![image](https://user-images.githubusercontent.com/122149118/218455664-8608e2fe-7b37-4f27-86b5-6ff0b4046bbe.png)

##### Filtering: the Math Behind the Match

![image](https://user-images.githubusercontent.com/122149118/218456757-938ea8dd-3c91-4ef2-8450-5d5aeb3833c6.png)

 주어진 이미지 상에서 작은 3 by 3 size의 이미지 패치를 특정한 위치에 오버랩을 시켰을 때에 해당하는 위치에서 주어진 특정 패턴과의 매칭되는 정도를 정량적으로 정의해볼 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218456962-86338038-d644-4681-a03a-661a0707391d.png)

 수행 과정은 3 by 3 패치를 주어진 이미지에 오버랩 시킨 후 패치에 정의된 pixel 값과 이미지의 같은 위치에 있는 값을 곱한다.

![image](https://user-images.githubusercontent.com/122149118/218457109-743ac7a0-e2ef-4778-9272-15f5cb10ff34.png)

 위의 예시에서는 1과 1이 곱해져 +1이라는 값 도출된다.

![image](https://user-images.githubusercontent.com/122149118/218457203-93f9f5bb-a714-4105-bc97-af2acb9a9890.png)

 옆의 pixel의 경우 일치하기 때문에 -1과 -1을 곱해주면 +1이라는 값으로 매칭이 됐다, 일치한다는 정보를 알 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218459953-e7721775-e957-44ce-a163-a38e93dd3a6e.png)

 이러한 방식으로 파란색 사각형 내에 3 by 3 패치를 오버랩시켜 각 pixel 별로 매칭 여부를 두 값들 간의 곱셈으로 알 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218466127-8035d890-afc2-45af-a5ec-47baff627f01.png)

![image](https://user-images.githubusercontent.com/122149118/218466251-8cbf4525-f765-4367-b532-8dbda1008343.png)

![image](https://user-images.githubusercontent.com/122149118/218466368-576626b7-675e-485c-b196-a337ca8434a4.png)

![image](https://user-images.githubusercontent.com/122149118/218466499-cb4844ab-52c5-477a-ab5c-836f3f5b9417.png)

![image](https://user-images.githubusercontent.com/122149118/218466607-33744395-6837-4dea-88fc-c414849313d6.png)

![image](https://user-images.githubusercontent.com/122149118/218466752-ae936a27-c2e4-4ee2-90c9-63eaa8a2a89b.png)

![image](https://user-images.githubusercontent.com/122149118/218466912-c3e99275-e9ae-43b7-9786-bef802c51040.png)

 이 값을 다 합한 후 이 패치의 총 pixel의 개수인 9로 나눈 것이 총 매칭된 정도로서 위의 위치의 경우 100% 매칭 값을 얻을 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218467719-bcfc64f9-a675-426e-a161-e77eea4f2194.png)

![image](https://user-images.githubusercontent.com/122149118/218468006-678a6b11-b25f-4e84-9c84-15a541d97656.png)

 이전의 예시와 동일한 패턴을 다른 위치에 오버랩 시켰을 때 매칭되는 정도를 계산해보면 현재 pixel 위치는 주어진 이미지 패치에 있는 -1과 이미지의 1이 매칭되지 않기 때문에 두 개의 값을 곱했을 때 -1이라는 값이 도출된다.

![image](https://user-images.githubusercontent.com/122149118/218469201-7cfc8d09-4b75-48d6-ac34-585c4f84650e.png)

 매칭되지 않은 pixel의 위치가 두 군데에서 발견된 것을 볼 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218469563-935c13bb-05ba-4b87-a369-2033b4fc3b00.png)

 55%의 매칭 정도를 특정 파란색 위치에 대해서 얻을 수 있다.

 매칭의 정도를 주어진 이미지에 3 by 3 패치를 가능한 모든 위치들에 위치시켜 해당 매칭 되는 정도를 또 다른 이미지 형태로 얻어낼 수 있게 된다.

##### Convolution: Trying Every Possible Match

![image](https://user-images.githubusercontent.com/122149118/218470635-6bb509d8-e430-473a-bedb-edb95f447a08.png)

 55% 매칭 정도는 가운데 pixel 위치의값을 기록하는 식으로 주어진 행렬을 완성하게 되면 매칭의 정도를 나타내는 또 다른 이미지를 얻을 수 있다.

 매칭의 정도를 나타내는 이러한 결과 이미지를 activation map, 활성화 지도라고 한다.

 특정 활성화 지도는 특정한 covolution filter 또는 위와 같은 3 by 3 패치를 주어진 입력 이미지에 가능한 모든 위치에 오버랩 시켜 매칭 되는 정도를 얻었을 때 나오는 결과 이미지이다.

![image](https://user-images.githubusercontent.com/122149118/218471403-7d019c27-a642-4b44-82ca-65a6c42c3fb2.png)

 이러한 연산을 convolution 연산 혹은 operation이라고 정의한다.

![image](https://user-images.githubusercontent.com/122149118/218471667-b7286407-481b-4399-9711-9de2af135d71.png)

 같은 이미지에 특정 패턴들에 대한 각기 나름의 활성화 지도, activation map을 얻을 수 있게된다.

activation map을 얻기 위해서
1. Overlap the convolution filter and the image patch.
 특정 convolution filter를 이미지 상의 각각의 특정 위치에 위치시켜 그에 해당하는 이미지 패치와 align한다.
2. Multiply each image pixel by the corresponding filter coefficient.
 align한 pixel 값들을 서로 곱한다.
3. Add them up.
4. Divide by the total number of pixels in the feature. (optional)
 다 더한 후 total pixel 개수로 나누어 준다.

4번 과정은 보통의 경우 생략하는 경우가 많다.

그런 경우 앞선 예시에서 매칭의 최대 값은 9가 될 것이다.

#### Convolution Layer

![image](https://user-images.githubusercontent.com/122149118/218474182-eaaf5dc3-9243-4d42-9186-21358cab6462.png)

 하나의 convolution layer를 생각해볼 때 convolution layer에서는 여러 개의 특정한 3 by 3 size의 고유한 패턴을 가지는 다수의 filter 혹은 convolution filter가 존재한다.

 convolution filter 혹은 패치를 각각 주어진 입력 이미지에 적용했을 때 filter별로 activation map이 output으로 등장하게 된다.

 한 장, 한 장의 activation map을 하나의 이미지라고 본다면 주어진 이미지 한 장을 가지고 filter 개수만큼의 이미지를 만들어낸다.

![image](https://user-images.githubusercontent.com/122149118/218481432-552b5f41-5604-4d3a-89e2-3b8201d7957e.png)

 convolution layer를 여러 계층으로 쌓았을 때 어떠한 deep neural network로서의 convolution neural network을 구성했을 때에 한 convolution layer 내에 주어지는 입력이 꼭 한 장의 사진뿐만이 아니라 여러 장의 사진으로 이루어진 입력을 생각해볼 수 있다.

 위와 같이 입력 이미지가 총 세 장의 이미지로 구성되어있는 경우에, 여기서 세장의 이미지가 채널이라고 하며 세 개의 채널로 이루어진 입력 이미지가 있을 때 특정한 하나의 3 by 3 size convolution filter는 첫 번째 채널 혹은 첫 번째 장의 이미지에 오버랩을 할 filter 패치와 두 번재 채널에 오버랩을 할 convolution filter 패치, 세 번째 채널 즉, 입력 채널 각각에 대응하는 3 by 3 이미지 패치가 하나의 convolution filter를 이루게 되고 이 경우 하나의 activation 값을 얻으려고 하면 filter를 각각 대응되는 곳에 오버랩시켜 해당하는 값들끼리 곱하고 모두 더하는 과정을 각각의 채널에서 수행한 후에 모두 다 합친다.

 최종적인 매칭 값이 scalar 값 하나로 도출될 것이다.

 이런 방식으로 진행하여 하나의 convolution filter에 대해 역시 또 한 장의 사진 혹은 activation map을 만들어낸다.

![image](https://user-images.githubusercontent.com/122149118/218485417-aae3cb95-0adf-4f50-b235-55ce743fd12e.png)

 다른 시각으로 바라보았을 때, 주어진 입력 이미지가 32 by 32의 가로, 세로 size를 가지고 채널 혹은 depth라고 부르기도 하는데 depth가 3채널, 3인 위와 같은 입력 이미지가 주어진다면 하나의 convolution filter는 filter의 가로, 세로의 크기가 3 by 3이 아닌 5 by 5 size의 convolution filter로 이루어져 있다면 한 convolution filter는 입력 채널 3에 대응하는 같은 채널 개수를 가지는 형태로 한 convolution filter가 구성되어 있을 것이다.

![image](https://user-images.githubusercontent.com/122149118/218485604-98dcd213-96a9-4734-92f3-5cd24f6ef5df.png)

 convolution filter를 주어진 특정한 위치에 오버랩을 시켰을 때의 convolution filter coefficients와 pixel 값을 모두 곱하고 다 더하게 되면 scalar 값 하나가 도출될 것이고 filter 위치를 바꾸었을 때 각각 scalar 값 하나에 activation 값을 도출해 결과적으로 한 장의 사진을 만들어낼 수가 있는 것이다.

 ![image](https://user-images.githubusercontent.com/122149118/218487112-1df52e0c-21c9-4b08-9090-f74942b4932b.png)

 한 convolution layer에서는 5 by 5 by 3의 size를 가지는 하나의 convolution filter가 여러 개, 다수의 convolution filter가 존재할 수 있게 되고 두 번째 convolution filter가 있을 때 그 filter가 이미지의 여러 위치들에 걸쳐서 activation 값들을 도출해내고 그걸 또 하나의 이미지로, output activation map으로 구성하게되면 또 다른 activation map 한 장이 두 번째 filter에 대해서 나오게 된다.

![image](https://user-images.githubusercontent.com/122149118/218488494-2a37aafe-5a0f-4ef4-8962-8e727f0637fe.png)

 주어진 convolution layer에서의 convolution filter가 3 개일 때, 위처럼 입력 이미지는 3 채널 입력 이미지가 주어졌고 한 convolution filter는 역시 3 채널의 filter로 구성되어 있고 각각의 convolution filter들이 activation map 한 장씩을 만들어내어 총 output activation map의 채널 수는 filter 개수와 동일한 개수로 나오게 된다.

![image](https://user-images.githubusercontent.com/122149118/218489315-d4a5170e-8fa1-4381-a48b-074d6a4793b8.png)

 6개의 5 by 5 size의 convolution filter가 있다면, 입력 채널의 수는 입력 activation map의 채널 수와 동일하기 때문에 생략되어있는 것을 볼 수 있다.

 따라서 실제로 한 convolution filter는 5 by 5 by 3 size로 구성되고 이것이 6개가 존재하는 convolution layer의 경우 output activation map은 총 여섯 개의 서로 다른 사진들로 출력이 구성된다.

![image](https://user-images.githubusercontent.com/122149118/218490104-58168de3-337d-4fc4-98cd-dff55b823a27.png)

![image](https://user-images.githubusercontent.com/122149118/219034706-b3624f32-91fa-405a-9430-cdbcd73e3bbb.png)

 convolution layer를 위와 같이 쭉 쌓았을 때 만약 첫 번째 convolution layer의 입력 이미지의 채널 수가 3이고 filter 수도 3이라고 하면 output activation map의 채널 수는 3이 된다.

 다음 layer로 적용되는 convolution filter는 역시 또 한 filter에 주어진 입력 이미지의 채널 수와 같은 채널 수를 가져야하므로 한 filter가 3 장의 사진 혹은 채널이 3개인 형태로 구성된다.

 두 번째 convolution filter에서 filter 수는 하나라고 한다면 최종적으로는 한 장의 output activation map을 얻게 된다.

#### Pooling: Shrinking the Image Stack

1. Pick a window size(usually 2).
2. Pick a stride(usually 2).
3. Walk your window across your filtered images.
4. From which window, take the maximum value.

#### Pooling

![image](https://user-images.githubusercontent.com/122149118/218491799-c75db6eb-df5f-4c64-ba06-831101df2784.png)

![image](https://user-images.githubusercontent.com/122149118/218624276-70fc7038-c649-4645-8684-05362db9a38f.png)

 convolution neural network을 구성하는 중요한 두 번째 타입의 layer는 pooling layer라고 불리며 기본적인 동작 과정은 특정한 size의 이미지 패치, 예를 들어 2 by 2 size라고 한다면 주어진 이미지에 좌측 상단부터 두 칸씩 옮겨가며 패치를 적용하게 되고 오버랩 된 이미지 내에서 가장 최대 값을 고르는 과정을 수행한다.

 위 2 by 2 안에서 0.33이 가장 큰 값이기 때문에 그 값이 선정되어 해당 output 값으로 나타난다.

 ![image](https://user-images.githubusercontent.com/122149118/218626896-9ae8ae9c-6f63-4cf3-8a29-6de18926c69d.png)

 ![image](https://user-images.githubusercontent.com/122149118/218627013-bc07baa1-3160-46f9-98dd-aea8511af496.png)

 ![image](https://user-images.githubusercontent.com/122149118/218627084-c9441ced-1a5a-4f34-a53f-b1b8afb5c91c.png)

 ![image](https://user-images.githubusercontent.com/122149118/218627161-25579263-2f85-4fdb-9098-c3361fef93f6.png)

 이미지 패치를 쭉 옮겨감으로써 또다른 output 이미지를 만들 수 있게된다.

 maxpooling이라는과정의 직관적인 의미는 원래 이미지가 특정한 size를 가지고 있었을 때 maxpooling을 수행하게 되면 결국 2 by 2 영역에서 하나의 값을 도출해내기 때문에 가로, 세로 size를 반으로 줄여주는 효과를 가진다.

 전체적으로는 이미지 size가 반으로 줄었되 2 by 2 영역 내에서 가장 크게 나타난 매칭의 정도 값, 특정 filter를 적용해서 이전 layer의 convolution 값의 layer가 활성화 지도 혹은 activation map을 얻게된다.

 특정 위치에서 값만큼의 강한 세기로 검출하고자 하는 패턴이 발견될 경우 이 값을 그대로 계승하여 가로, 세로 size가 반이 된 이미지를 얻을 수 있다.

 2 by 2 패치 4개의 pixel 위치 중 정확히 특정한 위치를 지정할 수는 없지만 영역 내에서 찾고자 하는 패턴이 가장 큰 값의 세기로 나타났다라는 것을 일종의 요약 과정을 max pooling이라는 layer를 통해 수행하게 되는 것이다.

 이 과정을 통하여 디테일하게 찾고자 하는 패턴이 4 pixel의 정확하게 위치했든 그 위치보다 조금 벗어났다고 하더라도 정보를 뭉뚱그리는 식으로, 대략적으로 좌측 상단에 패턴이 이러한 세기로 나타났다라고 하는 정보를 축약하는 과정을 통해 디테일하게 특정 위치만이 아니라 대략적으로 근처에 위치에서 찾고자 하는 패턴이 나타났다면 그것을 그대로 인정해 주는 형태로 정보를 변환해 주는 것이다.

![image](https://user-images.githubusercontent.com/122149118/218724100-f8491890-1c89-4be9-b452-135bc30a2b2a.png)

 주어진 입력 이미지의 각 채널 별로 따로 진행하며 각 채널의 activation map에서 max pooling의 output으로서 공통적으로 각 채널들이 모두 가로, 세로 크기가 반으로 줄어든 형태의 activation map을 얻게된다.

#### Pooling Layer

![image](https://user-images.githubusercontent.com/122149118/218725699-96ea8283-c5b4-48fe-bbfd-850121a292db.png)

#### Rectified Linear Units (ReLUs)

![image](https://user-images.githubusercontent.com/122149118/218726221-345051ab-6040-44ed-86ac-09153ed48a2a.png)

 convolution neural network을 구성하는 convolution layer 그리고 max pooling layer 그 다음으로 중요한 layer로서 ReLU layer가 있다.

 기본적으로 convolution 연산은 앞선 fully-connected layer에서 선형 결합을 통해 일어나는 연산이라고 볼 수 있으며 이러한 선형 연산 이후에 activation function 즉, sigmoid, tanh, ReLU 등의 활성 함수를 통과시켜줌으로써 함수를 보다 유연하게 다양한 패턴을 표현하게끔 만들어준다.

 선형 결합, 가중치를 입력에 곱하여 만들어진 1차식에 activation function을 적용해 주었듯이 convolution 과정을 통해 선형 결합을 한 후 activation function을 적용해 줄 때에 Deep Neural Networks의 학습을 용이하게 해주는 ReLU라는 특정 activation function을 적용해주게 된다.

![image](https://user-images.githubusercontent.com/122149118/218736630-c44b880b-ddf2-42ae-ba70-cf6946f8167e.png)

 이전 convolution layer에서 도출된 output activation map을 입력으로 받아 각각의 값에 ReLU function을 적용해주면 양수인 값은 그대로 유지하고 음수인 값은 0으로 clipping 해 주어 변형된 output activation map을 주게 된다.

![image](https://user-images.githubusercontent.com/122149118/218737047-2dc4c900-2b44-4aa6-949f-9a03ee3859be.png)

![image](https://user-images.githubusercontent.com/122149118/218737188-55c386ce-98db-4f6f-9804-e3f99e64d2a4.png)

#### ReLU Layer

![image](https://user-images.githubusercontent.com/122149118/218737388-c9e4e3af-7cdf-46fa-a072-7d61650f3b53.png)

 ReLU function 또한 주어진 다수의 채널로 이루어진 activation map에 대해 각 원소별로 모두 ReLU function을 적용해 주는 만큼 동일한 채널 수를 유지한 형태로 activation output을 주게 된다.

#### Layers Get Stacked

![image](https://user-images.githubusercontent.com/122149118/218737924-903d5427-e471-4a6b-bd59-b6158500d732.png)

 최종적으로 convolution neural network에서 기본적으로 선형 결합의 가중치를 적용하여 가중합을 구하게 되는 convolutional operation을 먼저 적용한 후 바로 ReLU layer가 적용된다.

 그 다음에 convolution, ReLU, convolution, ReLU를 보통 몇 번 stacking을 한 후에 이미지를 좀 더 축약된 형태 혹은 요약된 형태로 바꾸어 주는 max pooling layer를 적용해 주게 된다.

#### Deep Stacking

![image](https://user-images.githubusercontent.com/122149118/218738738-8016e3b6-3feb-43ad-94d1-f0d2052d5df9.png)

 한 neural network의 stacking된 형태를 보면 convolution, ReLU, convolution, ReLU, max pooling, convolution, ReLU, max pooling 이러한 형태의 패턴을 반복하는 형태로 Deep learning의 layer를 쌓게 된다.

#### Feature Extraction via Stacking Convolution Layers

![image](https://user-images.githubusercontent.com/122149118/218739385-37aa8724-11bd-4a84-a9ee-6057772a96eb.png)

 이러한 convolution layer들을 convolution, ReLU, max pooling 패턴으로 계속 쌓을 때 결국 뒤쪽에 있는 convolution layer는 앞쪽에서 추출된 특정한 패턴에 기반하여 activation map을 얻게되고 이것을 다시 입력 이미지로 보고 이 입력 이미지 상에서 또 정의할 수 있는 좀 더 복잡한 패턴을 정의할 수 있게 된다.

 한 예시로 얼굴 data를 입력 이미지를 주고 누구인지 구분하는 이미지 분류 task를 수행하기 위해 얼굴 이미지에 대해 학습을 한 경우 첫 번째 convolution layer에서 학습된 filter를 보면 특정한 각도로 이루어진 edge 또는 특정 경계에 대한 패턴들을 여러 filter들에 걸쳐 추출하는 것을 볼 수 있다. 

 여기서 추출된 output activation map을 또 다시금 convolution filter를 통해 조합하게 되면 그 다음 convolution layer에서는 얼굴의 각 부분을 좀 더 잘 부합할 수 있도록 하는 눈에 해당할 법한 둥그런 패턴들과 코에 해당할 법한 패턴들까지 만들어낼 수 있다.

 여러 패턴들을 잘 추출함으로써 나온 activation map을 또다시 입력으로 받아 convolution filter에 취하게 되면 누구인지, 어떤 사람이 지금 콧수염이 있는지, 웃고 있는지, 머리가 대머리인지 이러한 여러 얼굴을 인식하는 데에 좀 더 직접적으로 도움이 될 만한 패턴들을 추출할 수 있게 된다.

#### Fully Connected Layer

![image](https://user-images.githubusercontent.com/122149118/218742008-9bfec9fc-553e-4c6c-9d31-4b6218059844.png)

 convolution neural network을 전체적으로 볼 때 convolution, ReLU, convolution, ReLU, max pooling 패턴을 어느 정도의 숫자만큼 반복하여 쌓은 다음엔 특정 convolution layer에서 max pooling이 여러 번에 걸쳐 도출되기 때문에 이미지 size는 최종적으로 2 by 2라는 굉장히 작은 이미지 size로 변환이 됐고 직전 convolution layer에서 filter를 3 개 사용했기 때문에 결과적으로 3 개의 채널로 이루어진 output activation map이 만들어졌을 때 특정 시점부터는 이러한 2 by 2 size, 그리고 채널 수는 3인 activation map을 한 줄로 쭉 vector로 펴게 된다.

 총 12개, 2<sup>2</sup> 곱하기 입력 채널 수 만큼의 dimension을 가지는 한 줄짜리 vector로 만들어진다.

![image](https://user-images.githubusercontent.com/122149118/218744107-df59621e-bfcb-4866-8dbd-2ca506dc43c3.png)

 이러한 vector를 입력으로 주어 fully-connected layer를 구성하게 된다.

 ![image](https://user-images.githubusercontent.com/122149118/218744846-ea965036-d2de-43a5-952c-2188c7cc978c.png)

 fully-connected layer를 통해 'X'인지 'O'인지 구분하려 한다면 output 노드를 2개 만들게 되고 첫 번째 output 노드는 이것이 'X'라는 class에 대한 score, 두 번째 output 노드는 'O'라는 class에 대한 score를 만들어줄 수가 있게 된다.

![image](https://user-images.githubusercontent.com/122149118/218745545-6da42290-123a-448c-a9de-446a15f99d20.png)

![image](https://user-images.githubusercontent.com/122149118/218745638-b812add4-d66f-4ecb-8541-59a13139058e.png)

 학습 과정을 통해 fully-connected layer의 가중치도 특정한 값들로 최적의 값으로 도출될 것이며 지금 주어진 이미지에 대한 특정 layer의 activation map을 한 줄로 편 그 값들을 가지고 layer에 가중치를 기반으로 계산해보니 'X'라는 class 대응하는 score는 0.92가 도출되었고 이 값은 도출된 output에 sigmoid를 통과하여 나온 0에서 1 사이의 값이라고 생각해 볼 수 있다.

![image](https://user-images.githubusercontent.com/122149118/218745776-6dfbff11-c203-481e-942c-f321eba22031.png)

 두 번째 class에 대응하는 값은 0.51로 계산되는 결과를 보여주는 예시이다.

![image](https://user-images.githubusercontent.com/122149118/218746674-f7587a59-bb91-46b5-b3e5-e8e6be26b2e2.png)

 위와 같은 예시는 1번 class에 대한 값을 더 큰 값으로 예측했기 때문에 'X'로 최종 분류를 하게 될 것이다.

![image](https://user-images.githubusercontent.com/122149118/218746804-fc04a870-ec51-4d89-afc0-923fd0cc2368.png)

![image](https://user-images.githubusercontent.com/122149118/218747143-c5b97dc9-bb20-4a79-a21b-35eea4f45d5c.png)

 fully-connected layer를 한 layer를 사용했지만 여러 layer로 이루어진 fully-connected layer들 혹은 multi-layer perception을 뒤쪽에 배치시킬 수도 있게 된다.

#### Backpropagation

![image](https://user-images.githubusercontent.com/122149118/218747542-e8d32093-3f66-439e-8f2c-3ec49944617b.png)

 최종적으로 convolution, ReLU, convolution, ReLU, max pooling으로 이루어진 layer, 첫 번째 phase로 layer들이 진행되다가 fully-connected layer로 국면이 전환되어 2 개의 class 중 하나로 구분하는 전체 network를 구성하게 됐을 때 학습 과정에 특별히 다른 점은 없고 주어진 이미지가 'X' class에 대응한다면 결과 값은 최대한 1이 나오도록 하고 다른 class의 결과 값은 최대한 0이 나오도록 하는 binary cross-entrop loss나 mse loss 등을 사용하여 loss 값을 계산하고 다시 gradient descent를 수행하기 위해 backpropagation을 수행하게 되면 존재하는 parameter들이 gradient 계산을 통해 학습이 진행될 것이다.

 또 중요한 것은 pooling layer나 ReLU layer에서 trainable한 parameter가 없으나 convolution layer에서는 각각의 이미지 특정 위치들에 적용한 이미지 패치, convolution filter의 coefficient들 혹은 filter 패턴 자체 값들이 가중치 값이 되는데 이 값이 trainable한 parameter로서 gradient를 계산하고 이를 통해 gradient descent를 사용하여 filter의 coefficient를 최적의 값으로 도출하게 되는 것이다.

#### Hyperparameters

##### 하나의 convolution neural network을 구성할 때 결정해야 되는 다양한 hyperparameter

* Convolution
  * Number of filters
  * Size of filters

 한 convolution layer 내에서 몇 개의 convolution filter를 사용할지, 한 filter에 가로, 세로 size를 가령 3 by 3으로 할지, 5 by 5로 할지 등을 결정해야 한다.

* Pooling
  * Window size
  * Window stride

 이미지의 size를 반으로 만드는 max pooling 같은 경우에도 이미지에 적용하는 max pooling을 한 번할 때 사용 되는 window size를 2 by 2라고 할 수도 있겠지만 가령 3 by 3 혹은 더 큰 size로 max pooling을 적용할 수 있다.

 결국 2 by 2 내에서 최대 값 하나가 도출되고 3 by 3과 같은 여러 size 내에서 또 최대 값에 해당하는 값을 하나씩 도출되기 때문에 filter, window size 분의 1만큼으로 이미지 size가 줄어드는 효과를 보게 된다. 

 window의 stride는 한 이미지 내에서 max pooling의 window size를 2 by 2로 했을 때 그 다음 위치는 filter를 2 칸 움직여 또 다시 2 by 2 filter를 적용해준다. 

 이처럼 2 by 2의 max pooling window를 적용할 때에도 다음 칸으로 옮겨갈 때의 한번의 간격을 한 칸만 옮겨 max pooling을 적용해줄 수도 있다. 

 window를 한 번 옮길 때 몇 pixel만큼 움직이는지 결정하는 것이 window stride size이다.

 pooling layer에서는 stride를 조절함으로써 다양한 효과를 얻을 수 있다.

* Fully Connected
  * Number of layers
  * Number of neurons

 fully-connected layer에서는 layer를 몇 개 쌓을지, 한 layer 내에 몇 개의 neuron을 사용할 것인지도 결정해주어야 하는 hyperparameter이다.

#### Architecture Design Considerations

* How many of each type of layer?
* In what order?

 이런 convolution neural network은 어느 종류의 layer를 어느 위치에 그리고 어떤 순서로 배치 시키는지가 어려운 문제일 수 있다. 

 많은 연구자들이 다양한 computer vision task에 대해 잘 동작하는 특정한 convolution neural network의 architecture인 layer의 순서나 위치, 각 layer별로 convolution filter의 filter size나 filter의 개수들을 사전에 정의한 architecture들이 존재한다. 

### Advanced CNN Architectures
#### Various CNN Architectures

 * AlexNet
 * **<u>VGGNet</u>**
 * GoogLeNet
 * **<u>ResNet</u>**

  위와 같이 architecture들은 정말 무수히 많이 존재하는데 가장 대표적이고 좋은 성능을 내는 architecture들은 CNN의 시초격이었던 이미지 classification 대회인 'ImageNet 대회'에서 2012년도 다양한 부문의 task를 모두 석권하고 CNN의 중흥기의 포문을 열었던 역사적인 의미를 가지는 AlexNet이 있다.

  굉장히 심플한 구조로서 layer를 잘 많이 쌓음으로써 좋은 성능을 이끌어낸 VGGNet, 구글에서 만든 특정한 종류의 architecture를 사용하여 convolution layer 하나를 특정한 복잡한 형태로 만들고 그 형태를 계속 반복적으로 사용하여 좋은 성능을 낸 GoogLeNet, ResNet과 같은 모델들이 최근까지도 많이 사용된다.

#### VGGNet

![image](https://user-images.githubusercontent.com/122149118/218755669-c9fbed2d-733b-432d-95f4-97ac53147c1a.png)
###### [Simonyan and Zisserman, 2014]

 VGGNet의 가장 핵심 특징은 각각의 convolution layer에서 사용하는 convolution filter의 가로, 세로 size를 무조건 3 by 3으로 지정하였고 이러한 굉장히 작은 size를 통해 정의할 수 있는 특정한 패턴은 일자 패턴을 정의한다거나, X자 패턴을 정의할 수 있을 것이다.

 그렇지만 3 by 3이라는 굉장히 작은 size에서 정의할 수 있는 패턴은 제한적일 수 있을 것이다.

 이러한 제한적인 상황에서도 한 layer 내에서 이런 상황을 좀 타개하기 위해 더 큰 filter, 5 by 5나 7 by 7 size로 layer를 구성했을 때보다 3 by 3 size의 convolution filter를 사용하게되면 나타날 수 있는 단점을 layer를 굉장히 깊이 쌓음으로써 충분히 커버 가능하며 결과적으로도 좋은 성능을 낸 architecture가 VGGNet이다.

#### Residual Network (ResNet)

![image](https://user-images.githubusercontent.com/122149118/218757570-9a47c344-0cd4-46a5-ab56-5a575c3e16e7.png)

 convolution neural network 뿐만 아니라 다양한 neural network architecture에서 layer 수를 굉장히 많이 늘림에도 불구하고 학습을 용이하게 만들 수 있었던 핵심 아이디어인 residual network이 지금까지도 많이 사용되고 있는 convolution neural network architecture이다.

 residual network, ResNet의 기본 아이디어는 layer를 추가한다, 하나의 layer를 더 쌓는다는 것은 그리고 그 layer가 convolution layer라고 한다면 convolution layer를 통해 나온 output에 layer를 또 추가 하는 것이다. 

 이러한 layer를 깊이 쌓았을 때 각각의 layer들이 task를 위해 도움이 되는 순기능을 할 수도 있지만 layer의 parameter들도 결국 random initialization에서부터 시작이 되어야 하고 여기에 존재하는 수많은 layer에 있는 parameter들이 순기능을 내기까지 많은 시간이 걸릴 수 있다는 단점이 있다.

 이 단점을 해결하는 근본적인 방법을 ResNet에서 제안하였는데 그것은 layer를 필요하다면 건너뛸 수 있도록 skip할 수 있도록 하는 소위 skip connection이라는 간단하면서도 좋은 효과를 보이는 아이디어이다.

 보다 구체적으로는 이전에 Deep learning layer들이 만들어낸 중간 결과물이 있을 때 convolution, ReLU 즉, convolution layer를 한 번 더 쌓는다고 하면 layer의 output에 layer에 입력으로 주었던 것을 같이 더하는 식으로 최종 output을 구성하게 된다.

 추가한 layer를 f라고 했을 때 F(x)에 x를 더하는 방식으로 layer를 구성하는 것이다.

 Deep learning 모델이 layer를 skip 해야겠다고 생각하면 f라는 layer 내에 있는 parameter들을 거의 다 0으로 학습을 하게되고 f layer는 거의 0에 가까운 값을 주게 될 것이고 이 layer의 결과는 결국 layer의 입력이었던 x를 그대로 유지한 채 다음 layer에게 결과를 넘겨줄 수 있다.

 이처럼 layer를 skip할 수 있는 능력을 Deep learning에게 부여해 주었을 때 layer를 여러 개 쌓아도 학습이 잘 안된다거나 결과적으로 수많은 parameter들이 헤매게되어 학습이 잘 안돼 오히려 성능이 안 좋아지게 되는 단점들을 근본적으로 해결해 줄 수 있었다. 

 이 network 구조가 residual network라고 불린 이유는 만들고 싶은 출력물이 있을 때 그 출력물은 입력 대비 얼마만큼을 더해 줄지 혹은 빼줄지 그 차이 값만을 추가적인 layer에서 만들어주면 되는 것이기 때문에 layer의 역할은 입력 대비 추가하거나 빼줄 값만을 만들어주면 되는 역할을 한다는 의미에서 residual, 나머지 값을 만들어준다는 의미이다.

![image](https://user-images.githubusercontent.com/122149118/218762794-aaaea5b4-b6a4-460e-8233-a218a1a3b7a3.png)

 간단하면서도 효과적인 skip connection, residual network의 기본 아이디어를 layer를 가령 152개까지 쌓았을 때에도 성능을 꾸준히 향상시킬 수 있는 효과적인 수단으로 활용할 수 있었다.

 2015년도에 ResNet이 등장한 이후 이미지 classification 대회에서 사람 성능보다 더 좋은 성능을 내는 결과를 얻을 수 있었다.

#### ImageNet Large Scale Visual Recognition Challenge (ILSVRC) winners

![image](https://user-images.githubusercontent.com/122149118/218763605-a44e23cc-b39d-4849-b9e5-01b862d3bf90.png)

 Deep learning 특히 CNN 모델의 변천사를 볼 때 ImageNet classification task를 중심으로 성능은 점점 좋아졌던 추세를 보였던 것과 동시에 AlexNet의 layer 수였던 8 개의 layer 그리고 VGGNet의 16, 19 개의 layer, 22 개, 152 개의 layer까지 확장이 되도록 크게 많이 늘리고 그에 따른 성능 향상도 추구할 수 있는 기반을 잘 마련하게 되었다.

## Summary: CNN Architectures

* **VGG, GoogleNet, and ResNet are all in wide use**

 구체적인 CNN의 architecture 측면에서는 VGGNet, GoogLeNet, ResNet이 여전히 굉장히 많이 활용되고 있다.

* **ResNet is currently the best default**

 이 중에서 ResNet이 여러 분야에서 가장 많이 활용되고 있는 알고리즘으로 인식되고 있다.

* **Recent trends are going towards extremely deep networks**

 최근에도 layer 수를 증가시켜 성능을 끌어올린다거나 convolution neural network 기반 하에 transformer 또는 self-attention이라는 module을 또 추가함으로써 더 좋은 성능을 내도록 하는 식으로 network architecture가 발전하고 있다.