---
layout: post
title: "SSD Hands-on Practice"
description: "SSD_Pytorch"
date: 2023-04-01
tags: study, code
comments: true
---

# SSD Pytorch

 사용환경 : Google Colab

---

## Installing Dependencies
```
!pip install torch==1.7.1
!pip install torchvision==0.8.2
!pip install os
!pip install opencv-python
!pip install numpy
```

## Mounting Drive
```
cd /content/drive/SSD/SSD-pytorch
```
실행 위치 변경


## Importing Libraries
```
import numpy as np
import cv2
from PIL import Image
import os
import itertools
from math import sqrt
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import shutil
import torch
import torch.nn as nn
import torchvision
from src.transform import SSDTransformer
from src.utils import generate_dboxes, Encoder, colors, coco_classes
from torchvision.datasets import CocoDetection
from torch.utils.data.dataloader import default_collate
from torchvision.models.resnet import resnet50
from torchvision.models.mobilenet import mobilenet_v2, InvertedResidual
from pycocotools.cocoeval import COCOeval
from tqdm.autonotebook import tqdm
from torch.optim.lr_scheduler import MultiStepLR
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from src.model import SSD, SSDLite, ResNet, MobileNetV2
from src.loss import Loss
import torch.nn.functional as F
from torchvision.ops.boxes import box_iou, box_convert
```

## Defining Variables
```
cls_threshold=0.3
nms_threshold=0.5
epochs=65
batch_size=32
multistep=[43,54]
lr=2.6e-3
momentum =0.9
local_rank=0
num_workers=4
weight_decay= 0.0005
model="ssd"
parent_dir="/content/drive/MyDrive/Colab_Notebooks/SSD/SSD-pytorch"
pretrained_model_path=parent_dir +"/checkpoints"
ckpt = pretrained_model_path+"/SSD.pth"
dataset_path= "/content/drive/MyDrive/Colab_Notebooks/data"+"/coco"
save_folder=parent_dir+"/trained_models"
log_path=parent_dir+"/tensorboard"
dir_path = dataset_path+"/val2017"
#result_dir=parent_dir+"/Results"
```
hyper parameter 정의

## Helper Functions
```
def train(model, train_loader, epoch, writer, criterion, optimizer, scheduler):
    model.train()
    num_iter_per_epoch = len(train_loader)
    progress_bar = tqdm(train_loader)
    scheduler.step()
    for i, (img, _, _, gloc, glabel) in enumerate(progress_bar):
        if torch.cuda.is_available():
            img = img.cuda()
            gloc = gloc.cuda()
            glabel = glabel.cuda()

        ploc, plabel = model(img)
        ploc, plabel = ploc.float(), plabel.float()
        gloc = gloc.transpose(1, 2).contiguous()
        loss = criterion(ploc, plabel, gloc, glabel)

        progress_bar.set_description("Epoch: {}. Loss: {:.5f}".format(epoch + 1, loss.item()))

        writer.add_scalar("Train/Loss", loss.item(), epoch * num_iter_per_epoch + i)

        # if is_amp:
        #     with amp.scale_loss(loss, optimizer) as scale_loss:
        #         scale_loss.backward()
        # else:
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()


def evaluate(model, test_loader, epoch, writer, encoder, nms_threshold):
    model.eval()
    detections = []
    category_ids = test_loader.dataset.coco.getCatIds()
    for nbatch, (img, img_id, img_size, _, _) in enumerate(test_loader):
        print("Parsing batch: {}/{}".format(nbatch, len(test_loader)), end="\r")
        if torch.cuda.is_available():
            img = img.cuda()
        with torch.no_grad():
            # Get predictions
            ploc, plabel = model(img)
            ploc, plabel = ploc.float(), plabel.float()

            for idx in range(ploc.shape[0]):
                ploc_i = ploc[idx, :, :].unsqueeze(0)
                plabel_i = plabel[idx, :, :].unsqueeze(0)
                try:
                    result = encoder.decode_batch(ploc_i, plabel_i, nms_threshold, 200)[0]
                except:
                    print("No object detected in idx: {}".format(idx))
                    continue

                height, width = img_size[idx]
                loc, label, prob = [r.cpu().numpy() for r in result]
                for loc_, label_, prob_ in zip(loc, label, prob):
                    detections.append([img_id[idx], loc_[0] * width, loc_[1] * height, (loc_[2] - loc_[0]) * width,
                                       (loc_[3] - loc_[1]) * height, prob_,
                                       category_ids[label_ - 1]])

    detections = np.array(detections, dtype=np.float32)

    coco_eval = COCOeval(test_loader.dataset.coco, test_loader.dataset.coco.loadRes(detections), iouType="bbox")
    coco_eval.evaluate()
    coco_eval.accumulate()
    coco_eval.summarize()

    writer.add_scalar("Test/mAP", coco_eval.stats[0], epoch)
```
training 함수로써, 먼저 model을 train하게 만듦 `model.train()` 
한 epoch의 iteration은 DataLoader가 가지고 있는 data의 개수를 정의 `num_iter_per_epoch` 
program의 progress bar를 보여줄 수 있는 tqdm package를 사용하여 표현
<del>scheduler.step()을 하는이유?</del>
`progress_bar`가 돌아가면서 image와 label이 나오게 됨
image와 location, label을 모두 cuda에 올림 `img.cuda()`
model에 image를 넣음
prediction된 label과 prediction된 location이 나옴
location은 bounding box를 의미하고 label은 그 class를 의미
이 것들을 floating point로 바꾸어줌 `ploc.plabel = ploc.float().plabel.float()`
<del>floating point로 바꾸어주는 이유?</del>
location을 transpose를 첫 번째 dimension과 두 번째 dimenstion의 위치를 바꾸어준 후에 `gloc = gloc.transpose(1,2).contiguous()` loss를 계산
`gloc = gloc.transpose(1,2).contiguous()`는 label과 ground truth 간에 데이터 형태를 맞추기 위함
loss는 prediction한 값 2개와 ground truth 값 2 개를


it is intended only for human readers.[^1]

[^1]: <http://en.wikipedia.org/wiki/Syntax_highlighting>


To modify styling and highlight colors edit `/_sass/_highlighter.scss`.




```css
#container {
    float: left;
    margin: 0 -240px 0 0;
    width: 100%;
}
```


### Standard Code Block

    {% raw %}<nav class="pagination" role="navigation">
        {% if page.previous %}
            <a href="{{ site.url }}{{ page.previous.url }}" class="btn" title="{{ page.previous.title }}">Previous article</a>
        {% endif %}
        {% if page.next %}
            <a href="{{ site.url }}{{ page.next.url }}" class="btn" title="{{ page.next.title }}">Next article</a>
        {% endif %}
    </nav><!-- /.pagination -->{% endraw %}

### GitHub Gist Embed

An example of a Gist embed below.

<script src="https://gist.github.com/mmistakes/43a355923921d22cd993.js"></script>
