---
layout: post
title: "Pix2Pix: Colorization"
description: "week1, Image-to-Image Translation with Conditional Adversarial Nets"
date: 2023-02-16
tags: study
comments: true
---

*GAN을 이용하여 흑백 이미지를컬러 이미지로 만드는 프로젝트*

---
# GAN이란?

## GAN

### Outputs

![image](https://user-images.githubusercontent.com/122149118/219203676-64579402-23f9-4174-b43f-81e81d0b267f.png)

 인공지능이 만든 사진으로, 가짜 이미지들을 만드는 능력을 가지고 있다.

### Overview

![image](https://user-images.githubusercontent.com/122149118/219212578-f7b4ddbc-e018-4331-8cf9-64c72ea0076f.png)

 만들어낸 이미지를 가지고 real과 fake를 판단한다. 이 과정에서 더 좋은 fake 이미지를 생성하고 또 real과 fake를 판단하며 향상된 판별력을 가지게 된다.

 ### Loss Function

 * Discriminator
 ![image](https://user-images.githubusercontent.com/122149118/219214467-6676d7b7-1fcf-47a8-8711-c08ad5c321af.png)
 * Generator
 ![image](https://user-images.githubusercontent.com/122149118/219214732-91679ef1-5f8a-475f-a4d9-3b93680d80de.png)

 ![image](https://user-images.githubusercontent.com/122149118/219215112-1a722f1c-bc9f-4085-a6ad-d4f644fbda61.png){: .center}

  **D** is trained to discriminate samples from data.

  ⬛ : real image의 분포, 🟩 : Generator가 만든 fake image의 분포, 🟦와 🟩의 교점 아래 겹치는 부분은 Descriminator가 판별하기 힘들다.

![image](https://user-images.githubusercontent.com/122149118/219370326-a096adbd-0db3-4909-a577-c87b1fbef9b2.png){: .center}

 Gradients of **D** guides **G(z)** to flow to regions more likely to be classified as data.

 학습이 되면 될수록 fake image와 real image 분포가 비슷해지는 것을 볼 수 있다.

![image](https://user-images.githubusercontent.com/122149118/219371384-f18ecfa5-7010-4d13-8286-9f41be1d1b1d.png){: .center}
###### Goodfellow et al. 2014

![image](https://user-images.githubusercontent.com/122149118/219371922-2a2215e5-e585-4e02-9592-e03e4ecb346d.png){: .center}

![image](https://user-images.githubusercontent.com/122149118/219372172-13600697-284c-48c0-8e0f-e6a7b1928b91.png){: .center}

 분포의 겹치는 부분이 늘어났다는 것은 Generator가 real image 같은 것만 생성한다는 것을 의미한다.

## Mode Collapse

![image](https://user-images.githubusercontent.com/122149118/219372591-0de2af1d-4124-419d-92fd-403b366b311e.png)

 Discriminator의 loss function 안에 realistic한 조건이 없기 때문에 발생한다.

![image](https://user-images.githubusercontent.com/122149118/219214467-6676d7b7-1fcf-47a8-8711-c08ad5c321af.png)

 log⁡〖D(x)〗와 log⁡〖(1-D(x))〗는 binary cross entropy를 나타낸다.

 image가 얼마나 realistic 해야 되는지에 대한 언급이 없고 따라서 real image 같은지는 중요한 것이 아니다. Discriminator를 통과할 수 있는지 없는지가 중요하다.

![image](https://user-images.githubusercontent.com/122149118/219374562-06712191-5ed7-486c-8b3c-69f708d9a53d.png)

![image](https://user-images.githubusercontent.com/122149118/219377932-7df195d7-0aca-4400-bd76-091e8d2c771e.png)

 still image 생성이 가능하다는 것을 보여준다.

![image](https://user-images.githubusercontent.com/122149118/219378272-f77a1639-1735-4a67-bf31-27af2c555fb6.png)

 convolution을 만든 사람이 위와 같이 말했다.

### RGB Vs Lab

![image](https://user-images.githubusercontent.com/122149118/219378731-f8d9c541-ad77-49d8-88a4-ad9480d5b84e.png)

 RGB Channel을 가진 image는 먼저 Grey scale로 변환 후 Neural Network를 지나 R, G, B 3개의 channel을 prediction해야 한다.

![image](https://user-images.githubusercontent.com/122149118/219935732-e437eafb-2cdc-4d0a-ad4a-cde2bf46f0f4.png)

 Lab Channel을 가진 image는 이미 L channel이 Lightness Channel, 흑백 이미지로 L channel을 Neural Network를 지나 a, b 2개의 channel을 prediction하므로 RGB image 보다는 Lab image가 더 효율적이라고 할 수 있다.