---
layout: post
title: "Gradient Descent"
description: "ì´í™”ì—¬ìëŒ€í•™êµ ê°•ì œì› êµìˆ˜ë‹˜(Electronic & Electrical Engineering)"
date: 2023-02-23
tags: study
comments: true
---

Gradient descent algorithmê³¼ ê·¸ ì™¸ì— Machine learningì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª‡ ê°€ì§€ ìµœì í™” ê¸°ìˆ ì— ëŒ€í•´ì„œ ì•Œì•„ë³¸ë‹¤.

---

# ì§€ë„ í•™ìŠµ

## Overview

 * We have some function (loss function)

 ![image](https://user-images.githubusercontent.com/122149118/220755807-0e50f77f-5b1a-4edc-9d90-5f50295007bc.png)
 and want 
 ![image](https://user-images.githubusercontent.com/122149118/220756080-ee36f26d-df03-437d-8c87-536c9d648e32.png)
 Algorithm outline:
  * Start with some initial parameters <i>Î¸<sub>0</sub>, Î¸<sub>1</sub></i>
  * Keep changing the parameter to reduce the loss function until we hopefully end up at a minimum.

 ìœ„ì™€ ê°™ì€ objective í•¨ìˆ˜ê°€ ì¡´ì¬í•œë‹¤.
 ëª©ì ì€ ì´ objective í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ í•˜ëŠ” <i>Î¸<sub>0</sub>ì™€ Î¸<sub>1</sub></i>ì„ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤.
 ê·¸ì— ëŒ€í•œ ë°©ë²•ë¡ ìœ¼ë¡œ gradient descnet algorithmì—ì„œëŠ” ì²« ë²ˆì§¸, initialí•œ parameter <i>Î¸<sub>0</sub>, Î¸<sub>1</sub></i>ìœ¼ë¡œë¶€í„° ì‹œì‘í•˜ì—¬ ì´ ê°’ë“¤ì„ ì§€ì†ì ìœ¼ë¡œ ìµœì†Œë¡œ í•˜ëŠ” ì§€ì ê¹Œì§€ ë³€í™”ì‹œí‚¤ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤.

## Gradient Descent Algorithm

 **Key components**

 * Gradient : the derivative of vector functions (partial derivative along each dimension)
    - Direction of greatest increase (or decrease) of a function
 * <u>The step size Î±</u> affects the rate at which the weight vector moves down the error surface and must be a positive number. (<u>hyper parameter</u>)
 * Î¸ is the <u>learnable parameters</u>
 * The function <i>J</i> is <u> the objective function</u> that we want to minimize.

 ![image](https://user-images.githubusercontent.com/122149118/220884034-6adc0fbe-2be1-40f7-87ae-5b8436b4c294.png)

 ì´ ë•Œ gradientëŠ” vectorí•¨ìˆ˜ì˜ partial derivativetermì„ ê°€ì§„ë‹¤.
 í•¨ìˆ˜ì˜ ë³€í™”ëŸ‰ì´ ê°€ì¥ í° ë°©í–¥ìœ¼ë¡œ ê·¸ë¦¼ì—ì„œì™€ ê°™ì´ updateí•œë‹¤.
 step size Î±ëŠ” parameter updateì˜ ë³€í™” ì •ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” ê°’ìœ¼ë¡œ í•™ìŠµ ì´ì „ì— ì„¤ì •í•˜ëŠ” hyper parameterì´ë‹¤. 
 Î¸ëŠ” learnable parameterì´ë‹¤.
 Î±ëŠ” ì‚¬ì „ì— ì •ì˜í•´ì•¼ í•˜ëŠ” ê°’ì´ê³ , Î¸ëŠ” êµ¬í•˜ê³ ì í•˜ëŠ” modelì˜ í•™ìŠµ parameterì´ë‹¤. 
 ë§Œì•½ ì´ Î±ê°’ì´ ëŒ€ë‹¨íˆ í¬ë‹¤ ë˜ëŠ” ì‘ë‹¤ì— ë”°ë¼ì„œ lossê°€ ë³€í™”í•˜ëŠ” ì •ë„ë¥¼ ë³´ì´ê³  ìˆë‹¤.

 * If Î± is too small, gradient descent can be slow.
 * If Î± is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge.

 ![image](https://user-images.githubusercontent.com/122149118/220885119-eb4c93da-2062-4dfe-8722-fd0526094b88.png)
 
 ê°€ìš´ë° graphëŠ” Î±ê°’ì´ êµ‰ì¥íˆ ì‘ì€ ê²½ìš°ì— ìˆ˜ë ´í•˜ëŠ” í˜•íƒœì˜ graphê°€ ëœë‹¤.
 ìˆ˜ë ´ì†ë„ê°€ êµ‰ì¥íˆ ì²œì²œíˆ ë–¨ì–´ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
 ëŒ€ì‹  ì´ Î± ê°’ì´ ì‘ê²Œë˜ë©´ ìˆ˜ë ´í•˜ëŠ” í˜•íƒœê°€ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´í•˜ê²Œ ë˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
 ë°˜ëŒ€ë¡œ Î± ê°’ì´ êµ‰ì¥íˆ í° ê²½ìš°ì˜ graphê°€ 3ë²ˆì§¸ì— ë‚˜íƒ€ë‚˜ ìˆë‹¤.
 ì´ ê²½ìš°ì—ëŠ” Î± ê°’ì´ í¬ê¸°ë•Œë¬¸ì— error surface ìƒì—ì„œ ìµœì†Œì˜ ì§€ì ì„ ì°¾ê¸° ì–´ë µê³ , ë°œì‚°í•˜ëŠ” í˜•íƒœë¡œ í•™ìŠµì´ ì§„í–‰ëœë‹¤. 
 ê·¸ì— ë”°ë¼ì„œ errorì˜ lossê°’ì´ ì¤„ì–´ë“œëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ëŠ˜ì–´ë‚˜ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
 ì¦‰, í•™ìŠµì´ ì§„í–‰ë˜ê³  ìˆì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤.
 ì¤‘ê°„ ì •ë„ì˜ Î±ê°’ì„ í†µí•´ ì–´ëŠì •ë„ ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ë©´ì„œ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´í•˜ë„ë¡ í•˜ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤.

## Batch gradient descent

 ![image](https://user-images.githubusercontent.com/122149118/220886034-6cc56f6b-7eb3-4e2c-9388-424ae58c4f6b.png)

 ![image](https://user-images.githubusercontent.com/122149118/220886101-9db3af6b-2ce5-411d-995e-66eaeaa54bba.png)
 â†’ What if the number of sample size <i>m</i> is increasing?
 ì•ì„œ ì„¤ëª…í•œ Gradient descent algorithmì„ Batch gradient descent algorithmì´ë¼ê³  í•œë‹¤.
 ìˆ˜ì‹ì€ Batch gradient descent algorithmì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ linear regression modelì—ì„œ ëª©ì  í•¨ìˆ˜ Jì˜ partial derivative termì„ ë„£ì–´ì„œ ê°ê° <i>Î¸<sub>0</sub>ì™€ Î¸<sub>1</sub></i>ì„ ë°”ê¾¸ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
 ìœ„ ê·¸ë˜í”„ëŠ” parameterê°€ updateë˜ë©´ì„œ ì ì°¨ modelì´ dataì— fittingì´ ë˜ì–´ê°€ëŠ” ê³¼ì •ì„ ë³´ì´ê³  ìˆë‹¤.
 ì´ëŸ¬í•œ algorithmì€ ë¹„ë¡ local optimumì— ì·¨ì•½í•˜ì§€ë§Œ, ì–´ëŠ ì •ë„ ìˆ˜ë ´ì´ ë˜ì–´ê°€ëŠ” ì¥ë©´ì„ ë³¼ ìˆ˜ ìˆë‹¤.
 ì´ ë°©ì‹ì€ í° ë‹¨ì ì´ ìˆë‹¤. 
 ê·¸ ë‹¨ì ì€ ìˆ˜ì‹ì—ì„œ ë³´ì´ëŠ” ë°”ì™€ ê°™ì´ ì§€ê¸ˆ í˜„ì¬ <i>Î¸<sub>0</sub>ê·¸ë¦¬ê³  Î¸<sub>1</sub></i>ì„ updateí•˜ëŠ” ê³¼ì •ì—ì„œ ë°”ë¡œ ì „ì²´ sample mê°œê°€ ëª¨ë‘ ë‹¬ë¼ ê³ ë ¤ë¥¼ í•´ì•¼ëœë‹¤ê³  í•˜ëŠ” ê²ƒì´ë‹¤.
 ì „ì²´ sample errorë¥¼ ê³„ì‚°í•˜ê²Œ ë˜ê³ (h<sub>Î¸</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) ëª¨ë“  sampleì— ëŒ€í•´ì„œ ì „ë¶€ ë‹¤ accumilationí•´ì•¼ì§€ Î¸<sub>0</sub>ë¥¼ ë°”ë¡œ í•œ ë²ˆ updateí•  ìˆ˜ ìˆë‹¤. Î¸<sub>1</sub> ì—­ì‹œ ë¹„ìŠ·í•˜ê²Œ ì´ì™€ ê°™ì€ computation loadê°€ ì¡´ì¬í•œë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.
 ì´ ì‹ì—ì„œì™€ ê°™ì´ m, data sampleì˜ ìˆ«ìê°€ ì¦ê°€í•˜ë©´ ì¦ê°€í• ìˆ˜ë¡ ë³µì¡ë„ê°€ êµ‰ì¥íˆ ì»¤ì§€ê²Œ ëœë‹¤.

## Stochastic gradient descent (SGD)

 ![image](https://user-images.githubusercontent.com/122149118/220888845-68e2ef9c-e79e-406a-b3e8-da73502dc140.png)
 1 < <i>m</i> < <i>N</i> : mini-batch SGD
    Vs SGD : aileviate randomness
    Vs GD : less time in converging

 ![image](https://user-images.githubusercontent.com/122149118/220889146-5660944f-b412-4d77-9263-7733bffed3f8.png)

 ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ mì„ ê·¹ë‹¨ì ìœ¼ë¡œ ì¤„ì—¬ 1ë¡œ ë°”ê¾¼ algorithmì„ Stocahstic gradient descent algorithmì´ë¼ê³  í•œë‹¤.
 ì´ algorithmì€ batch gradient descentì— ë¹„í•´ ë¹ ë¥´ê²Œ iterationì„ ëŒ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, ë°˜ëŒ€ë¡œ ê° sample í•˜ë‚˜í•˜ë‚˜ ë§ˆë‹¤ ê³„ì‚°ì„ í†µí•´ì„œ parameterë¥¼ ì—°ì‚°í•˜ê¸° ë•Œë¬¸ì— noiseì˜ ì˜í–¥ì„ ë°›ê¸° ì‰½ê²Œ ëœë‹¤ëŠ” ë‹¨ì ì„ ê°€ì§€ê³  ìˆë‹¤.
 ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ìˆ˜ë ´í•˜ëŠ” ê³¼ì •ì—ì„œ ë§ì€ oscillationì´ ë°œìƒí•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

## Limitation : Local Optimum

 ![image](https://user-images.githubusercontent.com/122149118/220900508-a8c95780-89dd-4450-bf62-7a6b9af64274.png)
 Cannot guarantee global minimum but attempt to find a good local minimum

 gradient descent algorithmì€ parameterì˜ ì´ˆê¸° pointì— ë”°ë¼ì„œ local minimumì— ë¹ ì§€ê¸° ì‰½ë‹¤.
 ì˜ˆë¥¼ ë“¤ì–´ ìœ„ ê·¸ë¦¼ì—ì„œ ë³´ëŠ” ë°”ì™€ ê°™ì´ gradient descent algorithmì´ ì‹œì‘ë˜ëŠ” pointì— ë”°ë¼ì„œ local optimumì„ ë‹¬ì„±í•˜ëŠëƒ ê·¸ë ‡ì§€ ì•Šê³  global optimumì„ ë‹¬ì„±í•˜ëŠëƒê°€ ê²°ì •ì´ ëœë‹¤.

 **Critical points** with zero slope: <i>âˆ‡<sub>x</sub>f(x)</i> = 0 gives no information about which direction to move

 ![image](https://user-images.githubusercontent.com/122149118/220901086-361902ff-33e7-4ef5-ad19-f28228e228cb.png)
 ì‚¬ì‹¤ deep learningê³¼ ê°™ì€ ë³µì¡í•œ modelì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì— error surfaceê°€ êµ‰ì¥íˆ ë³µì¡í•´ì„œ ì´ëŸ¬í•œ local optimumì— ë¹ ì§€ê²Œ ë  ìœ„í—˜ì„±ì´ ë§ì€ ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤.
 ê·¸ ì¤‘ì—ì„œë„ settle pointì™€ ê°™ì´ ì–´ëŠ í•œ ë°©í–¥ìœ¼ë¡œ ìˆ˜ë ´ì„ í•˜ê²Œ ë  ë•Œ gradient ê°’ì´ 0ì´ ë˜ì–´ local optimumì— ë¹ ì§€ê²Œ ë˜ëŠ” ì§€ì ë“¤ì´ ë‹¤ìˆ˜ ì¡´ì¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤.
 ì´ëŸ¬í•œ suboptimalí•œ ë¬¸ì œì ë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ê¸°ì¡´ì˜ gradient descent algorithmì—ì„œ ë‹¤ì–‘í•œ ë³€í˜• algorithmë“¤ì´ ê°œë°œë˜ì—ˆë‹¤.
 ê·¸ ì¤‘ì— ê°€ì¥ ëŒ€í‘œì ì¸ ë°©ì‹ì´ ë°”ë¡œ momentumì„ ì´ìš©í•˜ëŠ” ê²ƒì´ë‹¤.
 > Momentum
 >   ê³¼ê±°ì— Gradientê°€ update ë˜ì–´ì˜¤ë˜ ë°©í–¥ ë° ì†ë„ë¥¼ ì–´ëŠ ì •ë„ ë°˜ì˜í•´ì„œ í˜„ì¬ pointì—ì„œ Gradientê°€ 0ì´ ë˜ë”ë¼ë„ ê³„ì†í•´ì„œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ë™ë ¥ì„ ì œê³µí•˜ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤.

## Some ideas to avoid local minimum

 **Method of momentum**

 * SGD : very popular but tends to be slow and difficult to reach the minimum
 * **Method of momentum**
    - Designed to speed up learning in high curvature and small/noise gradients
    - Exponentially weighted moving average of past gradients(low pass filtering)

 ![image](https://user-images.githubusercontent.com/122149118/220902981-4fba3168-6816-42a1-af6b-a8ffab00fb06.png)
 ###### <i>v<sub>t</sub></i> : Exponentially weighted moving average at time <i>t</i>
 ###### <i>g<sub>t</sub></i> : observation gradient at time <i>t</i>
 ###### <i>Ï</i> (0~1): degree of weighting decrease (smoothing factor)
 c.f. <i>v<sub>t</sub> = Ï<sup>k</sup>v<sub>t - k</sub></i> + (1 - <i>Ï</i>)[<i>g<sub>t</sub> + Ïg<sub>t - 1</sub> + ... + Ï<sup>k - 1</sup>g<sub>t - k + 1</sub></i>]

 ìœ„ ìˆ˜ì‹ì—ì„œ momentum vëŠ” ê³¼ê±°ì˜ momentum v<sub>t - 1</sub>ì— Ïë¥¼ ê³±í•˜ê²Œ ë˜ê³  ë‹¤ì‹œ 1 - Ïë¥¼ í˜„ì¬ ê³„ì‚°í•œ gradient g<sub>t</sub>ì— ê³±í•˜ì—¬ êµ¬ì„±í•˜ëŠ” ë°©ì‹ì„ ì˜ë¯¸í•œë‹¤.
 ì´ ìˆ˜ì‹ì„ í’€ì–´ ì˜ë¯¸ë¥¼ ì‚´í´ë³´ê²Œ ë˜ë©´ í˜„ì¬ì˜ momentumì€ ê³¼ê±°ì˜ momentumì—ë‹¤ê°€ Ïë§Œí¼ì˜ ê°’ì„ ê³±í•˜ê²Œ ë˜ê³  ê·¸ ì´í›„ì— ê³¼ê±°ì— ë‚˜ì˜¤ê²Œë˜ëŠ” gradient termì„ ëˆ„ì í•´ì„œ ê³„ì‚°í•˜ê²Œ ëœë‹¤.
 ì´ ë•Œ gradient termë“¤ì´ ëˆ„ì ì„ í•˜ê²Œ ë  ë•Œ í˜„ì¬ ì‹œì ì—ì„œ ë©€ë©´ ë©€ìˆ˜ë¡ Ïê°’ì´ ì—°ì†ì ìœ¼ë¡œ ê³±í•´ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
 ì´ ë•Œ ÏëŠ” 1ë³´ë‹¤ ì‘ê¸° ë•Œë¬¸ì— Ïë¥¼ ì—°ì†ì ìœ¼ë¡œ ê³±í•˜ê²Œ ë˜ë©´ 1ë³´ë‹¤ ë”ìš± ì‘ì•„ì§€ê²Œ ëœë‹¤.
 ë”°ë¼ì„œ ë¨¼ ê³¼ê±°ì˜ ê°’ì€ ë”ìš± ì‘ì•„ì§€ê²Œ ë˜ê³  ë¹„êµì  ê°€ê¹Œìš´ ê±°ë¦¬ì˜ ê³¼ê±° gradientëŠ” ì ê²Œ ì‘ì•„ì§€ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ê³¼ì •ì„ exponentially moving averageë¼ê³  ë¶€ë¥¸ë‹¤.
 ì´ ë°©ì‹ì€ low pass filtering ì—°ì‚°ì´ê¸° ë•Œë¬¸ì—, í˜„ì¬ pointì—ì„œì˜ saddle pointë‚˜ ì‘ì€ noise gradient ê°’ ë³€í™”ì— ë³´ë‹¤ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´í•  ìˆ˜ ìˆê²Œ ë°”ë€Œê²Œ ëœë‹¤.

 **SGD**

 <i>Î¸<sub>t + 1</sub> = Î¸<sub>t</sub> - Î±âˆ‡<sub>0</sub>J(Î¸<sub>t</sub>)
 let g = âˆ‡<sub>0</sub>J(Î¸)</i>

 ![image](https://user-images.githubusercontent.com/122149118/220906140-9e1aaced-9435-4f84-90d1-8cf6c1ac86bd.png)

 **SGD + momentum : Use a velocity as a weighted moving average of previous gradients**
 <i>v â† Ïv - Î±g
 Î¸ â† Î¸ + v</i>

 ![image](https://user-images.githubusercontent.com/122149118/220906758-2cbfa623-9c9c-45b6-95a1-9d2a00b52f90.png)

 **A parameter is updated by linear combination of gradient and velocity**

 ê¸°ì¡´ì˜ stochastic gradient descent algorithmì€ momentumì„ ë”í•´ì„œ ê³¼ê±°ì— ê°’ì„ ë°˜ì˜í•œ gradient ê°’ì´ updateê°€ ë˜ê²Œ ëœë‹¤.
 ì„¤ë ¹ local minumumì´ë‚˜ saddle pointì—ì„œ gradietê°€ 0ì´ ë˜ëŠ” ì§€ì ì´ ë°œìƒ í•˜ë”ë¼ë„ ê³¼ê±°ì— ì´ì–´ì˜¤ë˜ momentum ê°’ì„ ë°˜ì˜ í•˜ì—¬ ê³„ì†í•´ì„œ í•™ìŠµì„ ì§„í–‰ í•  ìˆ˜ ìˆê²Œ ëœë‹¤.
 ì¦‰ ì„¤ë ¹ gradient ê°’ì´ 0ì´ ë˜ë”ë¼ë„ í•™ìŠµì„ ì´ì–´ì„œ ì§„í–‰í•  ìˆ˜ ìˆê²Œ ëœë‹¤.
 ì´ëŸ¬í•œ momentumì„ ì´ìš©í•˜ëŠ” gradient descentì—ì„œ ì¡°ê¸ˆ ë” ë°œì „í•œ ê²ƒì´ nestrov momentum ë°©ì‹ì´ë‹¤.
 nestrov momentumì€ ê¸°ì¡´ì˜ ë°©ì‹ê³¼ ë‹¤ë¥´ê²Œ ìš°ì„  gradientë¥¼ ë¨¼ì € í‰ê°€í•˜ê³  updateë¥¼ í•´ì£¼ê²Œ ëœë‹¤.
 ì´ ë°©ì‹ì„ look ahead gradient stepì„ ì´ìš©í•œë‹¤ê³  ì´ì•¼ê¸°í•œë‹¤.

 * Nestrov Momentum
    - Difference from standard momentum: where gradient <i>g</i> is evaluated (i.e. "lookahead" gradient step)
  <i>v â† Ïv - Î±âˆ‡<sub>Î¸</sub>J(Î¸ + Ïv)
  Î¸ â† Î¸ + v</i>

 ![image](https://user-images.githubusercontent.com/122149118/220908312-b401bf69-2913-4b7d-9539-5fece8431fef.png)

 ê¸°ì¡´ì˜ ë°©ì‹ê³¼ ê°™ì€ ê²½ìš°ëŠ” í˜„ì¬ gradient stepê³¼ ê¸°ì¡´ì˜ momentum stepì„ ê³ ë ¤í•˜ì—¬ ì‹¤ì œ ë‹¤ìŒë²ˆ actual stepì„ vectorì˜ í•©ìœ¼ë¡œì„œ ê³„ì‚°ì„ í•œë‹¤ë©´ Nestrov momentum update ë°©ì‹ì—ì„œëŠ” actual stepì´ì™¸ì—ë„ momentum ê³„ì‚°ì„ í•˜ê²Œ ë  ë•Œ momentum stepë§Œí¼ ì´ë™ ì§€ì ì—ì„œ lookahead gradient stepì„ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— ê·¸ ë‘ ê°œì˜ vector í•©ìœ¼ë¡œì„œ actual stepì„ ê³„ì‚°í•˜ê²Œ ëœë‹¤.
 ìˆ˜ì‹ì—ì„œ Jì— partial derivative term(âˆ‡<sub>Î¸</sub>)ì„ Î¸ + Ïvê°€ ë“¤ì–´ê°€ëŠ” ê²ƒì´ ì´ëŸ¬í•œ ê³¼ì •ì„ ë³´ì´ëŠ” ê²ƒì´ë‹¤.
 ë‹¤ìŒ ë°©ì‹ìœ¼ë¡œëŠ” AdaGradë¼ëŠ” ë°©ì‹ì´ ìˆë‹¤.
 ì´ ë°©ì‹ì€ ê° ë°©í–¥ìœ¼ë¡œì˜ learning rateë¥¼ ì ì‘ì ìœ¼ë¡œ ì¡°ì ˆí•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„ ì˜¬ë¦¬ê²Œ ëœë‹¤.
 ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ learning rateê°€ ì¡°ì ˆì´ ë˜ëŠ”ì§€ ì‚´í´ë³¸ë‹¤.

 **per-parameter adaptive learning rates**

 * **AdaGrad** : Adapts an indinidual learning rate of each direction
    - Slow down the learning rate when an accumulated gradient is large
    - Speed up the learning rate when an accumulated gradient is small
 * Allows an automatic tuning of the learning rate per parameter

 ![image](https://user-images.githubusercontent.com/122149118/220910872-d77f8475-a6b0-4e41-9ccf-ac30b7616cf5.png)

 ![image](https://user-images.githubusercontent.com/122149118/220910981-d69115ec-de16-4b16-94ab-4ea3d3f29add.png)

 ìœ„ ìˆ˜ì‹ì—ì„œ rì€ ê¸°ì¡´ì˜ ê°’ì— gradientì˜ ì œê³±ì„ ë”í•´ê°€ë©° updateí•˜ê²Œ ëœë‹¤.
 ë”°ë¼ì„œ rì€ gradientì˜ ì œê³± ì¦‰, í•©ì´ ëˆ„ì ì´ ë˜ê²Œ ë˜ë©´ì„œ ì ì°¨ ê°’ë“¤ì´ ì»¤ì§€ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤.
 ë°˜ë©´ì— ì´ëŸ¬í•œ rì€ Î”Î¸ë¥¼ updateí•˜ëŠ” ê³¼ì •ì—ì„œ ë¶„ëª¨ì˜ termìœ¼ë¡œ ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì— ì´ Î”Î¸ëŠ” ê°’ì´ ì ì  ì‘ì•„ì§€ê²Œ ë  ê²ƒì´ë‹¤.
 ì–´ëŠ í•œ ë°©í–¥ìœ¼ë¡œ gradient ê°’ì´ í¬ë‹¤ë¼ê³  í•˜ëŠ” ê²ƒì€ ì´ë¯¸ ê·¸ ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ë§ì´ ì§„í–‰ë˜ì—ˆë‹¤ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
 ê·¸ ë°©í–¥ìœ¼ë¡œ ì´ë¯¸ í•™ìŠµì´ ë§ì´ ì§„í–‰ë˜ì–´ì„œ gradientì˜ ëˆ„ì í•©ì´ í¬ë‹¤ë¼ê³  í•œë‹¤ë©´ ë°˜ëŒ€ë¡œ Î”Î¸ê°’ì´ ì‘ì•„ì ¸ì„œ ê·¸ë§Œí¼ì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ì¤„ì´ê²Œ ë˜ëŠ”ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤.
 ë°˜ëŒ€ë¡œ ì•„ì§ í•™ìŠµ ê³¼ì •ì´ ì§„í–‰ë˜ì§€ ì•Šì•„ rê°’ì´ ì—¬ì „íˆ ì‘ë‹¤ë©´ ê·¸ ë°©í–¥ìœ¼ë¡œëŠ” Î”Î¸ê°’ì„ í¬ê²Œí•˜ì—¬ ìˆ˜ë ´ì˜ ì†ë„ë¥¼ ë” ë¹ ë¥´ê²Œ í•  ê²ƒì´ë‹¤.
 ì´ì™€ ê°™ì´ AdaGrad algorithmê°™ì€ ê²½ìš° accumulated gradient ê°’ì„ í†µí•´ learning rateë¥¼ ì¡°ì ˆí•˜ê²Œ ëœë‹¤.
 í•˜ì§€ë§Œ AdaGradì™€ ê°™ì€ ë°©ì‹ì€ ë‹¨ì ì´ í•˜ë‚˜ ìˆë‹¤.
 ë°”ë¡œ gradientì˜ ê°’ì´ ê³„ì†í•´ì„œ ëˆ„ì ì´ ë¨ì— ë”°ë¼ì„œ learning rate ê°’ì´ êµ‰ì¥íˆ ì‘ì•„ì§€ê²Œ ëœë‹¤ëŠ” ê²ƒì´ë‹¤.
 ğŸ” Learning rateì´ ì‘ì•„ì§€ê²Œ ë˜ë©´ ì–´ë–»ê²Œ ë˜ëŠ”ê°€?
 â¡ í•™ìŠµì´ ê·¸ ì§€ì ì—ì„œ ì¼ì–´ë‚˜ê²Œ ë˜ì§€ ì•Šì„ ê²ƒì´ë‹¤.
 ì´ëŸ¬í•œ ë°©ì‹ì„ ìˆ˜ì •í•œ ê²ƒì´ RMSProp algorithmì´ë‹¤.

 * **RMSProp** : attempts to fix the drawbacks of AdaGrad, in which the learning rate becomes infinitesimally small and the algorithm is no longer able learning when the accumulated gradient is large.
 * **Remedy** Gradient accumulation by weighted decaying

 ![image](https://user-images.githubusercontent.com/122149118/220917328-7a10ee8b-1917-4d43-be2f-f9329e018123.png)

 ì˜¤ë¥¸ìª½ ìˆ˜ì‹ì—ì„œ ë³´ëŠ” ë°”ì™€ ê°™ì´ rì„ updateí•˜ê²Œ ë  ë•Œì—ëŠ” ì´ì œëŠ” ë°”ë¡œ gradientì˜ ì œê³±ì„ ê·¸ëŒ€ë¡œ ê³±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê¸°ì¡´ì— ìˆë˜ rì— Ïê°’ì„ ê³±í•˜ê²Œ ëê³  (1 - Ï)ë¥¼ gradientì˜ ì œê³±ì—ë‹¤ê°€ ê³±í•¨ìœ¼ë¡œì„œ ì´ rì˜ ê°’ì„ ê³¼ê±°ì— r ë§Œí¼ì˜ Ï factorë¥¼ ê³±í•´ì„œ ì–´ëŠ ì •ë„ ì¡°ì ˆí•˜ê²Œ ëœë‹¤.
 ê·¸ë¦¬ê³  ê·¸ ì¡°ì ˆëœ ê°’ì€ ë¶„ëª¨ì— ê·¸ëŒ€ë¡œ ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì— ê³¼ê±°ì™€ ê°™ì´ ê·¹ë‹¨ì ìœ¼ë¡œ gradient ê°’ì´ ëˆ„ì ë¨ì— ë”°ë¼ì„œ Î¸ê°’ì´ ì¤„ì–´ë“œëŠ” ê²ƒì´ ì•„ë‹ˆë¼ RMSProp ë°©ì‹ì—ì„œëŠ” ì–´ëŠ ì •ë„ ì™„ì¶©ëœ í˜•íƒœë¡œ í•™ìŠµ ì†ë„ê°€ ì¤„ì–´ë“ ë‹¤ê³  ìƒê°ì„ í•  ìˆ˜ ìˆë‹¤.
 <mark>ê°€ì¥ ë§ì´ ì ‘í•˜ê²Œ ë˜ëŠ” gradient discent algorithmì€ Adamì´ë‹¤.
 Adamì€ Adaptive moment estimationì˜ ì¤„ì„ë§ë¡œ RMSPropì™€ Momentum ë°©ì‹ì„ í˜¼í•©í•œ ê²ƒì´ë‹¤.</mark>

 * **Adam (adaptive moment estimation) : RMSProp + momentum**

 <i>let g = âˆ‡<sub>Î¸</sub>J(Î¸)</i>

 â‘  Compute the first moment from momentum
 â‘¡ Compute the second moment from RMSprop
 â‘¢ Correct bias
 â‘£ Update the parameters

 ![image](https://user-images.githubusercontent.com/122149118/220938038-b65ae397-49c2-4fcb-95cd-d209c3d643b0.png)

 ë¨¼ì € ì²« ë²ˆì§¸ë¡œ ì²« ë²ˆì§¸ momentumì„ ê³„ì‚°í•˜ê²Œ ëœë‹¤.
 ì´ momentumì€ sì™€ ê°™ì€ í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤.
 ë‘ ë²ˆì§¸ë¡œëŠ” RMSPropì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë‘ ë²ˆì§¸ momentumì„ ê³„ì‚°í•˜ê²Œ ëœë‹¤.
 ì´ ë‘ ë²ˆì§¸ momentumì€ ì•ì„œ ë³´ì•˜ë˜ rê°’ì´ë‹¤.
 ê·¸ ë‹¤ìŒì€ biasë¥¼ correctioní•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ê²Œ ëœë‹¤.
 í†µê³„ì ìœ¼ë¡œ ë³´ë‹¤ ë” ì•ˆì •ëœ í•™ìŠµì„ ìœ„í•œ ê³¼ì •ì´ë‹¤.
 ì´ì–´ì„œ gradient discent algorithmì—ì„œ ì´ì•¼ê¸°í•˜ëŠ” parameterë¥¼ updateí•˜ëŠ” ê³¼ì •ì„ ìœ„ì™€ ê°™ì€ í˜•íƒœë¡œ êµ¬ì„±í•˜ê²Œ ëœë‹¤.

 ![image](https://user-images.githubusercontent.com/122149118/220938278-d8b58ade-6590-4201-bae2-85d503cf1704.png)
 ì„œë¡œ ë‹¤ë¥¸ gradient discent algorithmì´ ìˆ˜ë ´í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤€ë‹¤.

## Learning rate scheduling

 * Learning rate: key hyper parameter for gradient-based algorithms; need to gradually <u>decrease</u> learning rate over time
 e.g. decay learning rate by every half of few epochs

 ![image](https://user-images.githubusercontent.com/122149118/221073887-8f9df0c4-1652-4c4c-9f8c-4d4f160a1455.png)

 ![image](https://user-images.githubusercontent.com/122149118/220940132-fe20b282-eb79-484c-80e3-59086247ccde.png)

 ì‹¤ì§ˆì ìœ¼ë¡œ modelì„ í•™ìŠµí•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” tipì´ë‹¤.
 ë°”ë¡œ hyper parameter Î±ë¥¼ ê³¼ì •ì— ë”°ë¼ ì¡°ì •í•˜ëŠ” ê²ƒì´ë‹¤.
 graphì—ì„œ ë³´ì´ëŠ” ë°”ì™€ ê°™ì´ low learning rateì™€ ê°™ì€ ê²½ìš°ì—ëŠ” ì²œì²œíˆ ìˆ˜ë ´í•˜ê²Œ ë˜ì§€ë§Œ lossë¥¼ ì¤„ì¼ ìˆ˜ê°€ ìˆë‹¤.
 ë°˜ëŒ€ë¡œ high learning rateì™€ ê°™ì€ ê²½ìš° í•™ìŠµì´ ì§„í–‰ë ìˆ˜ë¡ ìˆ˜ë ´í•˜ëŠ” ì •ë„ê°€ low learning rateì— ë¹„í•´ ì¤„ì–´ë“¤ì§€ ì•Šì§€ë§Œ ë³´ë‹¤ ë” ë¹ ë¥´ê²Œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤ê³  í•˜ëŠ” ì¥ì ì´ ìˆë‹¤.
 ì´ëŸ° ë‘ ê°€ì§€ì˜ ì¥ì ì„ í˜¼í•©í•˜ê¸° ìœ„í•´ ìˆ˜ë ´ ë‹¨ê³„ë§ˆë‹¤ ì ì‘ì ìœ¼ë¡œ ì¡°ì ˆí•´ ë‚˜ê°€ë©´ ëœë‹¤.
 ìˆ˜ì‹ì—ì„œ ë³´ì´ëŠ” ë°”ì™€ ê°™ì´ step size Î±ë¥¼ í•™ìŠµ ê³¼ì •ì— ë”°ë¼ì„œ ì ì°¨ ì¤„ì—¬ë‚˜ê°€ê²Œ ëœë‹¤.
 ì´ˆê¸°ì—ëŠ” í•™ìŠµì„ ë¹ ë¥´ê²Œ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ë°˜ë©´ì— Î±ê°’ì´ ëŠ˜ì–´ë‚˜ê²Œ ë¨ì— ë”°ë¼ì„œ costê°€ ë”ì´ìƒ ì¤„ì–´ë“¤ì§€ ëª»í•˜ëŠ” ë¬¸ì œë¥¼ learning rateë¥¼ ì ì°¨ ì¤„ì„ìœ¼ë¡œì„œ ë³´ë‹¤ ë” í•™ìŠµì„ ìš©ì´í•˜ê²Œë” í•  ìˆ˜ ìˆë‹¤.

 modelì˜ ê³¼ì í•© ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ìµœì í™” ê³¼ì •ì—ì„œì˜ ëª‡ ê°€ì§€ tipì„ ì„¤ëª…í•œë‹¤.
 > Model ê³¼ì í•© ë¬¸ì œ
 > Modelì´ ì§€ë‚˜ì¹˜ê²Œ ë³µì¡í•˜ì—¬, í•™ìŠµ Parameterì˜ ìˆ«ìê°€ ë§ì•„ì„œ ì œí•œëœ í•™ìŠµ sampleì— ë„ˆë¬´ ê³¼í•˜ê²Œ í•™ìŠµì´ ë˜ëŠ” ê²ƒì´ë‹¤.

## Some optimization in regression

 **to avoid overfitting**

 * If we have too many features, the hypothesis may fit the training set very well. However, it may fail to generalize to new samples

 ![image](https://user-images.githubusercontent.com/122149118/221075594-286af3d4-c348-4cbd-9a20-1ea3e0f6e9f4.png)


 ì˜ˆë¥¼ ë“¤ì–´, í•™ìŠµ í•˜ê³ ì í•˜ëŠ” ê°œí˜•ì´ ì˜¤ë Œì§€ìƒ‰ê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆë‹¤ë©´ polinomial degree4ê°€ ê°€ì¥ ìµœì ì´ì§€ë§Œ ê·¸ ì´í›„ì— ì¦ê°€í•˜ëŠ” ì°¨ìˆ˜ì— ë”°ë¼ì„œ ê³¼ì í•©ì´ ë°œìƒí•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. 
 í˜„ì¬ sampleì— ëŒ€í•´ì„œëŠ” ì˜¤ì°¨ê°€ ëŒ€ë‹¨íˆ ì ì–´ì§€ì§€ë§Œ ì‹¤ì œ í•¨ìˆ˜ì˜ ê°œí˜•ì„ ë”°ë¼ê°„ë‹¤ê³  ë³´ê¸°ì—ëŠ” ì–´ë ¤ìš¸ ê²ƒì´ë‹¤. 

 <i>x<sub>1</sub></i> = size of house
 <i>x<sub>2</sub></i> = no. of bedrooms
 <i>x<sub>3</sub></i> = no. of floors
 <i>x<sub>4</sub></i> = age of house
 <i>x<sub>5</sub></i> =
 <i>x<sub>6</sub></i> = kitchen size
 ...
 <i>x<sub>100</sub></i> 

 ![image](https://user-images.githubusercontent.com/122149118/221076283-070e4de5-3333-49b4-ae4c-f4271f70bd38.png)

 More features â†’ more parameters â†’ need more data ; (in practice) less data â†’ overfitting
 Furthermore, mean-squared-error is sensitive to outliers

 ì˜ˆë¥¼ ë“¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì§‘ê°’ì„ ì¶”ì •í•˜ëŠ” regression modelì—ì„œ ì…ë ¥ featureì˜ ìˆ«ìê°€ ì§€ë‚˜ì¹˜ê²Œ ë§ì•„ì§„ë‹¤ê³  í•˜ë©´ í•­ìƒ ì¢‹ì€ ê²ƒë§Œì€ ì•„ë‹ˆë‹¤.
 ì¼ë¶€ ì…ë ¥ ë³€ìˆ˜ë“¤ì€ ìƒí˜¸ ê°„ì— dependentí•  ìˆ˜ë„ ìˆë‹¤.
 ê·¸ëŸ¬ë‚˜ ì…ë ¥ featureì˜ ìˆ«ìê°€ ë§ì•„ì§€ê²Œ ëœë‹¤ë©´ ë”ìš± parameterì˜ ê°œìˆ˜ê°€ ë§ì•„ì§€ê²Œ ë˜ê³  ê·¸ê²ƒì€ curse of dimension problemì— ì˜í•´ì„œ dataì˜ ê°œìˆ˜ê°€ ë” ë§ì•„ì§€ê²Œ ëœë‹¤ê³  í•˜ëŠ” ê²ƒì´ë‹¤.
 í•˜ì§€ë§Œ ì‹¤ì§ˆì ìœ¼ë¡œ ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” dataë¥¼ ì¶©ë¶„íˆ ëŠ˜ë¦´ ìˆ˜ê°€ ì—†ê¸° ë•Œë¬¸ì— ì´ modelì´ overfittingì´ ë˜ëŠ” ë¬¸ì œê°€ ë°œìƒì„ í•˜ê²Œ ëœë‹¤.
 ë”ìš±ì´ mean-squared-errorì™€ ê°™ì€ ê²½ìš°ì—ëŠ” ì´ëŸ¬í•œ noise, outlierì— êµ‰ì¥íˆ ë¯¼ê°í•œ íŠ¹ì„±ì„ ê°€ì§€ê²Œ ëœë‹¤.
 ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ì€ Regularization ë°©ì‹ì´ ìˆë‹¤.

 1. Reduce number of features.
    - select which features to keep.
 2. Regularization
    - keep the features but reduce magnitude/values of parameters
    - Simple hypothesis and less prone to overfitting and robust to noise

  ![image](https://user-images.githubusercontent.com/122149118/221078072-202f2fda-c0d2-44c3-a3a8-fbd2500257c7.png)
  ###### Î» : regularization parameter

  ![image](https://user-images.githubusercontent.com/122149118/221078186-3298ee48-74c3-44a1-bc79-046d0d3c240a.png)
  <i>Î¸<sub>0</sub> + Î¸<sub>1</sub>x + Î¸<sub>2</sub>x<sup>2</sup> + Î¸<sub>3</sub>x<sup>3</sup> + Î¸<sub>4</sub>x<sup>4</sup></i>

 ìœ„ ê·¸ë¦¼ì—ì„œì™€ ê°™ì´ parameterì˜ ìˆ«ìì— ë”°ë¼ì„œ model ë³µì¡ë„ê°€ ì„œë¡œ ë‹¤ë¥´ë‹¤ê³  ìƒê°í•´ë³¸ë‹¤.
 ì´ ë•Œ regularizationì€ ìˆ˜ì‹ì—ì„œì™€ ê°™ì´ ì„¤ë ¹ ë³µì¡í•œ modelì„ ì‚¬ìš©í•˜ë”ë¼ë„ í•™ìŠµ ê³¼ì •ì—ì„œ modelì˜ ë³µì¡ë„ì— ëŒ€í•œ penaltyë¥¼ ì£¼ì–´ì„œ modelì´ overfittingë˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ë°©ì‹ì´ë‹¤.
 ì²« ë²ˆì§¸ ë‚˜íƒ€ë‚˜ê²Œ ë˜ëŠ” termì€(<i>h<sub>Î¸</sub>(x<sup>(i)</sup> - y<sup>(i)</sup>)<sup>2</sup>) MSE, ì¦‰ modelì´ ì •ë‹µ yì— fittingì„ í•˜ë„ë¡ í•˜ëŠ” termì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.
 ì´ termì„ "fitting"ì´ë¼ê³  í•œë‹¤.
 ê·¸ ë’¤ì— ìˆëŠ” termì€ Î¸<sub>j</sub>ê°’ì´ í¬ë©´ í´ìˆ˜ë¡ ëŠ˜ì–´ë‚˜ê²Œ ë˜ëŠ” ì˜¤ë¥˜ê°€ ëœë‹¤.
 ì¦‰, model ì…ì¥ì—ì„œëŠ” ê°€ëŠ¥í•œí•œ Î¸ë¥¼ ì“°ì§€ ì•Šìœ¼ë©´ì„œ ì´ lossë¥¼ ìµœì†Œí™”í•˜ë„ë¡ í•˜ëŠ” ë…¸ë ¥ì„ í•œë‹¤.
 Î¸ê°’ì„ ì“°ì§€ ì•ŠëŠ”ë‹¤ë¼ê³  í•˜ëŠ” ê²ƒì€ ì£¼ì–´ì§„ linear modelì—ì„œ ì–´ë–¤ íŠ¹ì •í•œ Î¸ê°’ë“¤ì´ ëœ ì¤‘ìš”í•˜ê²Œ ëœë‹¤ë©´ 0ìœ¼ë¡œ ë³´ë‚´ë²„ë¦¬ëŠ” í•™ìŠµì´ ì§„í–‰ëœë‹¤.
 ê·¸ì— ë”°ë¼ì„œ parameterì˜ ê°œìˆ˜ë¥¼ ì¤„ì„ìœ¼ë¡œì„œ modelì˜ ë³µì¡ë„ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¤„ì¼ ìˆ˜ ìˆê²Œ ëœë‹¤.
 ë”°ë¼ì„œ modelì€ ê°€ê¸‰ì  ì ì€ ìˆ«ìì˜ parameterë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ì£¼ì–´ì§„ ë¬¸ì œì˜ sampleë“¤ì„ fittingí•˜ê³ ì í•  ê²ƒì´ë©° ê·¸ì— ëŒ€í•´ì„œ overfittingì˜ ë¬¸ì œë¥¼ í”¼í•  ìˆ˜ ìˆë‹¤.

## Quiz

 **What answers are correct?**

 **A.** Gradient descent produces a numerical solution but it may not acheive a global optimum
 Gradient descent algorithmì´ numericalí•œ solutionì„ ì œê³µí•˜ëŠ”ë° í•­ìƒ global optimumì„ ë‹¬ì„±í•˜ì§€ ëª»í•œë‹¤.
 **A. Correct** The solution can be different with an initial point of an error surface
 Gradient descent algorithmì€ í•­ìƒ local optimumì— ë¹ ì§€ê¸° ì‰¬ìš´ ìœ„í—˜ì´ ìˆë‹¤.
 í˜„ì¬ ë‹¨ê³„ì—ì„œì˜ gradient ë°©ì‹ìœ¼ë¡œ ê·¸ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

 **B.** Momentum of previous gradien descent can help avoid overfitting
 ì´ì „ì˜ gradient descentì—ì„œì˜ momentumì€ overfittingì„ í”¼í•˜ëŠ”ë° ë„ì›€ì´ ëœë‹¤.
 **B. False** Momentum can avoid local minimum and help obtain a solution close to global optimum
 Momentumì€ gradient descent algorithmì„ í†µí•´ì„œ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ì¤‘ê°„ì— local minimumì„ í”¼í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ ì´ë‹¤.

 **C.** Regularization can penalize the importance of some input features to avoid overfitting
 Regularizationì€ overfittingì„ í”¼í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ ë¡œ íŠ¹ì •í•œ ì…ë ¥ featrueì˜ ì¤‘ìš”ì„±ì— ëŒ€í•´ penaltyë¥¼ ì¤€ë‹¤.
 **C. Correct** Regularization can decrease some weights to have compact sets of parameters
 Regularization ë°©ì‹ì€ Î¸ì— ëŒ€í•œ termì„ ì´ìš©í•˜ì—¬ ì–´ë–¤ weightë“¤ì´ í•„ìš”ì—†ëŠ” ê²½ìš°ì—ëŠ” ê³¼ê°í•˜ê²Œ modelì´ 0ìœ¼ë¡œ ê°€ê¹ê²Œ ë³´ë‚´ì„œ modelì„ ë‹¨ìˆœí•˜ê²Œ ë§Œë“œëŠ” ë°©ì‹ì„ ë§í•œë‹¤.

## Summary

* Optimization in general ML/DL
   - General ideas of gradient descent algorithm
   - Mostly stochastic gradient descent and its variants using gradien estimates
   - Adam is a good default choice in most cases
* Regularization
   - Reduce magnitude/values of parameters while keeping features
   - Simple hypothesis and less prone to overfitting
   - Robust to noise

ë¹„ë¡ stochastic gradient ë°©ì‹ì´ ë§ì´ ì‚¬ìš©ë˜ê³  ìˆì§€ë§Œ ê·¸ê²ƒì— ë³€í™”ëœ algorithm ì—­ì‹œ ê°œì„ ëœ í˜•íƒœë¡œ ë³´ë‹¤ ë” local optimumì„ í”¼í•˜ê¸° ìœ„í•´ ê°œë°œì´ ë˜ê³  ìˆë‹¤.
ê·¸ ì¤‘ì—ì„œë„ Adamì€ ê°€ì¥ ì¢‹ì€ gradient descent algorithmì˜ ì„ íƒì§€ê°€ ë  ê²ƒì´ë‹¤.
ê·¸ ì´ì™¸ì— ìµœì í™” ë°©ì‹ìœ¼ë¡œë„ regularizationì—ì„œ ì„¤ëª…í–ˆë˜ ì–´ë–¤ íŠ¹ì • parameter ì¤‘ìš”ì„±ì— ë”°ë¼ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ë™ì•ˆì— overfittingì„ í”¼í•˜ê¸° ìœ„í•´ modelì˜ ë³µì¡ë„ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ë°©ì‹ì´ë‹¤.