---
layout: post
title: "Gradient Descent"
description: "이화여자대학교 강제원 교수님(Electronic & Electrical Engineering)"
date: 2023-02-23
tags: study
comments: true
---

Gradient descent algorithm과 그 외에 Machine learning에서 사용하는 몇 가지 최적화 기술에 대해서 알아본다.

---

# 지도 학습

## Overview

 * We have some function (loss function)

 ![image](https://user-images.githubusercontent.com/122149118/220755807-0e50f77f-5b1a-4edc-9d90-5f50295007bc.png)
 and want 
 ![image](https://user-images.githubusercontent.com/122149118/220756080-ee36f26d-df03-437d-8c87-536c9d648e32.png)
 Algorithm outline:
  * Start with some initial parameters <i>θ<sub>0</sub>, θ<sub>1</sub></i>
  * Keep changing the parameter to reduce the loss function until we hopefully end up at a minimum.

 위와 같은 objective 함수가 존재한다.
 목적은 이 objective 함수를 최소화하도록 하는 <i>θ<sub>0</sub>와 θ<sub>1</sub></i>을 구하는 것이다.
 그에 대한 방법론으로 gradient descnet algorithm에서는 첫 번째, initial한 parameter <i>θ<sub>0</sub>, θ<sub>1</sub></i>으로부터 시작하여 이 값들을 지속적으로 최소로 하는 지점까지 변화시키는 것이 목적이다.

## Gradient Descent Algorithm

 **Key components**

 * Gradient : the derivative of vector functions (partial derivative along each dimension)
    - Direction of greatest increase (or decrease) of a function
 * <u>The step size α</u> affects the rate at which the weight vector moves down the error surface and must be a positive number. (<u>hyper parameter</u>)
 * θ is the <u>learnable parameters</u>
 * The function <i>J</i> is <u> the objective function</u> that we want to minimize.

 ![image](https://user-images.githubusercontent.com/122149118/220884034-6adc0fbe-2be1-40f7-87ae-5b8436b4c294.png)

 이 때 gradient는 vector함수의 partial derivativeterm을 가진다.
 함수의 변화량이 가장 큰 방향으로 그림에서와 같이 update한다.
 step size α는 parameter update의 변화 정도를 조절하는 값으로 학습 이전에 설정하는 hyper parameter이다. 
 θ는 learnable parameter이다.
 α는 사전에 정의해야 하는 값이고, θ는 구하고자 하는 model의 학습 parameter이다. 
 만약 이 α값이 대단히 크다 또는 작다에 따라서 loss가 변화하는 정도를 보이고 있다.

 * If α is too small, gradient descent can be slow.
 * If α is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge.

 ![image](https://user-images.githubusercontent.com/122149118/220885119-eb4c93da-2062-4dfe-8722-fd0526094b88.png)
 
 가운데 graph는 α값이 굉장히 작은 경우에 수렴하는 형태의 graph가 된다.
 수렴속도가 굉장히 천천히 떨어지는 것을 볼 수 있다.
 대신 이 α 값이 작게되면 수렴하는 형태가 안정적으로 수렴하게 되는 것을 알 수 있다.
 반대로 α 값이 굉장히 큰 경우의 graph가 3번째에 나타나 있다.
 이 경우에는 α 값이 크기때문에 error surface 상에서 최소의 지점을 찾기 어렵고, 발산하는 형태로 학습이 진행된다. 
 그에 따라서 error의 loss값이 줄어드는 것이 아니라 늘어나고 있는 것을 볼 수 있다.
 즉, 학습이 진행되고 있지 않는다는 것이다.
 중간 정도의 α값을 통해 어느정도 빠르게 수렴하면서 안정적으로 수렴하도록 하는 것이 목적이다.

## Batch gradient descent

 ![image](https://user-images.githubusercontent.com/122149118/220886034-6cc56f6b-7eb3-4e2c-9388-424ae58c4f6b.png)

 ![image](https://user-images.githubusercontent.com/122149118/220886101-9db3af6b-2ce5-411d-995e-66eaeaa54bba.png)
 → What if the number of sample size <i>m</i> is increasing?
 앞서 설명한 Gradient descent algorithm을 Batch gradient descent algorithm이라고 한다.
 수식은 Batch gradient descent algorithm을 보이는 것으로 linear regression model에서 목적 함수 J의 partial derivative term을 넣어서 각각 <i>θ<sub>0</sub>와 θ<sub>1</sub></i>을 바꾸고 있는 것을 볼 수 있다.
 위 그래프는 parameter가 update되면서 점차 model이 data에 fitting이 되어가는 과정을 보이고 있다.
 이러한 algorithm은 비록 local optimum에 취약하지만, 어느 정도 수렴이 되어가는 장면을 볼 수 있다.
 이 방식은 큰 단점이 있다. 
 그 단점은 수식에서 보이는 바와 같이 지금 현재 <i>θ<sub>0</sub>그리고 θ<sub>1</sub></i>을 update하는 과정에서 바로 전체 sample m개가 모두 달라 고려를 해야된다고 하는 것이다.
 전체 sample error를 계산하게 되고(h<sub>θ</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) 모든 sample에 대해서 전부 다 accumilation해야지 θ<sub>0</sub>를 바로 한 번 update할 수 있다. θ<sub>1</sub> 역시 비슷하게 이와 같은 computation load가 존재한다고 볼 수 있다.
 이 식에서와 같이 m, data sample의 숫자가 증가하면 증가할수록 복잡도가 굉장히 커지게 된다.

## Stochastic gradient descent (SGD)

 ![image](https://user-images.githubusercontent.com/122149118/220888845-68e2ef9c-e79e-406a-b3e8-da73502dc140.png)
 1 < <i>m</i> < <i>N</i> : mini-batch SGD
    Vs SGD : aileviate randomness
    Vs GD : less time in converging

 ![image](https://user-images.githubusercontent.com/122149118/220889146-5660944f-b412-4d77-9263-7733bffed3f8.png)

 이러한 문제를 해결하기 위해 m을 극단적으로 줄여 1로 바꾼 algorithm을 Stocahstic gradient descent algorithm이라고 한다.
 이 algorithm은 batch gradient descent에 비해 빠르게 iteration을 돌 수 있다는 장점이 있지만, 반대로 각 sample 하나하나 마다 계산을 통해서 parameter를 연산하기 때문에 noise의 영향을 받기 쉽게 된다는 단점을 가지고 있다.
 위의 그림과 같이 수렴하는 과정에서 많은 oscillation이 발생한다는 것을 알 수 있다.

## Limitation : Local Optimum

 ![image](https://user-images.githubusercontent.com/122149118/220900508-a8c95780-89dd-4450-bf62-7a6b9af64274.png)
 Cannot guarantee global minimum but attempt to find a good local minimum

 gradient descent algorithm은 parameter의 초기 point에 따라서 local minimum에 빠지기 쉽다.
 예를 들어 위 그림에서 보는 바와 같이 gradient descent algorithm이 시작되는 point에 따라서 local optimum을 달성하느냐 그렇지 않고 global optimum을 달성하느냐가 결정이 된다.

 **Critical points** with zero slope: <i>∇<sub>x</sub>f(x)</i> = 0 gives no information about which direction to move

 ![image](https://user-images.githubusercontent.com/122149118/220901086-361902ff-33e7-4ef5-ad19-f28228e228cb.png)
 사실 deep learning과 같은 복잡한 model을 사용하는 경우에 error surface가 굉장히 복잡해서 이러한 local optimum에 빠지게 될 위험성이 많은 것으로 알려져 있다.
 그 중에서도 settle point와 같이 어느 한 방향으로 수렴을 하게 될 때 gradient 값이 0이 되어 local optimum에 빠지게 되는 지점들이 다수 존재하는 것으로 알려져 있다.
 이러한 suboptimal한 문제점들을 해결하기 위해서 기존의 gradient descent algorithm에서 다양한 변형 algorithm들이 개발되었다.
 그 중에 가장 대표적인 방식이 바로 momentum을 이용하는 것이다.
 > Momentum
 >   과거에 Gradient가 update 되어오던 방향 및 속도를 어느 정도 반영해서 현재 point에서 Gradient가 0이 되더라도 계속해서 학습을 진행할 수 있는 동력을 제공하게 되는 것이다.

## Some ideas to avoid local minimum

 **Method of momentum**

 * SGD : very popular but tends to be slow and difficult to reach the minimum
 * **Method of momentum**
    - Designed to speed up learning in high curvature and small/noise gradients
    - Exponentially weighted moving average of past gradients(low pass filtering)

 ![image](https://user-images.githubusercontent.com/122149118/220902981-4fba3168-6816-42a1-af6b-a8ffab00fb06.png)
 ###### <i>v<sub>t</sub></i> : Exponentially weighted moving average at time <i>t</i>
 ###### <i>g<sub>t</sub></i> : observation gradient at time <i>t</i>
 ###### <i>ρ</i> (0~1): degree of weighting decrease (smoothing factor)
 c.f. <i>v<sub>t</sub> = ρ<sup>k</sup>v<sub>t - k</sub></i> + (1 - <i>ρ</i>)[<i>g<sub>t</sub> + ρg<sub>t - 1</sub> + ... + ρ<sup>k - 1</sup>g<sub>t - k + 1</sub></i>]

 위 수식에서 momentum v는 과거의 momentum v<sub>t - 1</sub>에 ρ를 곱하게 되고 다시 1 - ρ를 현재 계산한 gradient g<sub>t</sub>에 곱하여 구성하는 방식을 의미한다.
 이 수식을 풀어 의미를 살펴보게 되면 현재의 momentum은 과거의 momentum에다가 ρ만큼의 값을 곱하게 되고 그 이후에 과거에 나오게되는 gradient term을 누적해서 계산하게 된다.
 이 때 gradient term들이 누적을 하게 될 때 현재 시점에서 멀면 멀수록 ρ값이 연속적으로 곱해지는 것을 알 수 있다.
 이 때 ρ는 1보다 작기 때문에 ρ를 연속적으로 곱하게 되면 1보다 더욱 작아지게 된다.
 따라서 먼 과거의 값은 더욱 작아지게 되고 비교적 가까운 거리의 과거 gradient는 적게 작아지기 때문에 이러한 과정을 exponentially moving average라고 부른다.
 이 방식은 low pass filtering 연산이기 때문에, 현재 point에서의 saddle point나 작은 noise gradient 값 변화에 보다 안정적으로 수렴할 수 있게 바뀌게 된다.

 **SGD**

 <i>θ<sub>t + 1</sub> = θ<sub>t</sub> - α∇<sub>0</sub>J(θ<sub>t</sub>)
 let g = ∇<sub>0</sub>J(θ)</i>

 ![image](https://user-images.githubusercontent.com/122149118/220906140-9e1aaced-9435-4f84-90d1-8cf6c1ac86bd.png)

 **SGD + momentum : Use a velocity as a weighted moving average of previous gradients**
 <i>v ← ρv - αg
 θ ← θ + v</i>

 ![image](https://user-images.githubusercontent.com/122149118/220906758-2cbfa623-9c9c-45b6-95a1-9d2a00b52f90.png)

 **A parameter is updated by linear combination of gradient and velocity**

 기존의 stochastic gradient descent algorithm은 momentum을 더해서 과거에 값을 반영한 gradient 값이 update가 되게 된다.
 설령 local minumum이나 saddle point에서 gradiet가 0이 되는 지점이 발생 하더라도 과거에 이어오던 momentum 값을 반영 하여 계속해서 학습을 진행 할 수 있게 된다.
 즉 설령 gradient 값이 0이 되더라도 학습을 이어서 진행할 수 있게 된다.
 이러한 momentum을 이용하는 gradient descent에서 조금 더 발전한 것이 nestrov momentum 방식이다.
 nestrov momentum은 기존의 방식과 다르게 우선 gradient를 먼저 평가하고 update를 해주게 된다.
 이 방식을 look ahead gradient step을 이용한다고 이야기한다.

 * Nestrov Momentum
    - Difference from standard momentum: where gradient <i>g</i> is evaluated (i.e. "lookahead" gradient step)
  <i>v ← ρv - α∇<sub>θ</sub>J(θ + ρv)
  θ ← θ + v</i>

 ![image](https://user-images.githubusercontent.com/122149118/220908312-b401bf69-2913-4b7d-9539-5fece8431fef.png)

 기존의 방식과 같은 경우는 현재 gradient step과 기존의 momentum step을 고려하여 실제 다음번 actual step을 vector의 합으로서 계산을 한다면 Nestrov momentum update 방식에서는 actual step이외에도 momentum 계산을 하게 될 때 momentum step만큼 이동 지점에서 lookahead gradient step을 계산하기 때문에 그 두 개의 vector 합으로서 actual step을 계산하게 된다.
 수식에서 J에 partial derivative term(∇<sub>θ</sub>)을 θ + ρv가 들어가는 것이 이러한 과정을 보이는 것이다.
 다음 방식으로는 AdaGrad라는 방식이 있다.
 이 방식은 각 방향으로의 learning rate를 적응적으로 조절하여 학습 효율을 올리게 된다.
 어떤 방식으로 learning rate가 조절이 되는지 살펴본다.

 **per-parameter adaptive learning rates**

 * **AdaGrad** : Adapts an indinidual learning rate of each direction
    - Slow down the learning rate when an accumulated gradient is large
    - Speed up the learning rate when an accumulated gradient is small
 * Allows an automatic tuning of the learning rate per parameter

 ![image](https://user-images.githubusercontent.com/122149118/220910872-d77f8475-a6b0-4e41-9ccf-ac30b7616cf5.png)

 ![image](https://user-images.githubusercontent.com/122149118/220910981-d69115ec-de16-4b16-94ab-4ea3d3f29add.png)

 위 수식에서 r은 기존의 값에 gradient의 제곱을 더해가며 update하게 된다.
 따라서 r은 gradient의 제곱 즉, 합이 누적이 되게 되면서 점차 값들이 커지게 되는 것이다.
 반면에 이러한 r은 Δθ를 update하는 과정에서 분모의 term으로 들어가기 때문에 이 Δθ는 값이 점점 작아지게 될 것이다.
 어느 한 방향으로 gradient 값이 크다라고 하는 것은 이미 그 방향으로 학습이 많이 진행되었다라는 것을 의미한다.
 그 방향으로 이미 학습이 많이 진행되어서 gradient의 누적합이 크다라고 한다면 반대로 Δθ값이 작아져서 그만큼의 수렴 속도를 줄이게 되는게 되는 것이다.
 반대로 아직 학습 과정이 진행되지 않아 r값이 여전히 작다면 그 방향으로는 Δθ값을 크게하여 수렴의 속도를 더 빠르게 할 것이다.
 이와 같이 AdaGrad algorithm같은 경우 accumulated gradient 값을 통해 learning rate를 조절하게 된다.
 하지만 AdaGrad와 같은 방식은 단점이 하나 있다.
 바로 gradient의 값이 계속해서 누적이 됨에 따라서 learning rate 값이 굉장히 작아지게 된다는 것이다.
 🔍 Learning rate이 작아지게 되면 어떻게 되는가?
 ➡ 학습이 그 지점에서 일어나게 되지 않을 것이다.
 이러한 방식을 수정한 것이 RMSProp algorithm이다.

 * **RMSProp** : attempts to fix the drawbacks of AdaGrad, in which the learning rate becomes infinitesimally small and the algorithm is no longer able learning when the accumulated gradient is large.
 * **Remedy** Gradient accumulation by weighted decaying

 ![image](https://user-images.githubusercontent.com/122149118/220917328-7a10ee8b-1917-4d43-be2f-f9329e018123.png)

 오른쪽 수식에서 보는 바와 같이 r을 update하게 될 때에는 이제는 바로 gradient의 제곱을 그대로 곱하는 것이 아니라 기존에 있던 r에 ρ값을 곱하게 됐고 (1 - ρ)를 gradient의 제곱에다가 곱함으로서 이 r의 값을 과거에 r 만큼의 ρ factor를 곱해서 어느 정도 조절하게 된다.
 그리고 그 조절된 값은 분모에 그대로 들어가기 때문에 과거와 같이 극단적으로 gradient 값이 누적됨에 따라서 θ값이 줄어드는 것이 아니라 RMSProp 방식에서는 어느 정도 완충된 형태로 학습 속도가 줄어든다고 생각을 할 수 있다.
 <mark>가장 많이 접하게 되는 gradient discent algorithm은 Adam이다.
 Adam은 Adaptive moment estimation의 줄임말로 RMSProp와 Momentum 방식을 혼합한 것이다.</mark>

 * **Adam (adaptive moment estimation) : RMSProp + momentum**

 <i>let g = ∇<sub>θ</sub>J(θ)</i>

 ① Compute the first moment from momentum
 ② Compute the second moment from RMSprop
 ③ Correct bias
 ④ Update the parameters

 ![image](https://user-images.githubusercontent.com/122149118/220938038-b65ae397-49c2-4fcb-95cd-d209c3d643b0.png)

 먼저 첫 번째로 첫 번째 momentum을 계산하게 된다.
 이 momentum은 s와 같은 형태로 구성되어있다.
 두 번째로는 RMSProp와 같은 방식으로 두 번째 momentum을 계산하게 된다.
 이 두 번째 momentum은 앞서 보았던 r값이다.
 그 다음은 bias를 correction하는 과정을 거치게 된다.
 통계적으로 보다 더 안정된 학습을 위한 과정이다.
 이어서 gradient discent algorithm에서 이야기하는 parameter를 update하는 과정을 위와 같은 형태로 구성하게 된다.

 ![image](https://user-images.githubusercontent.com/122149118/220938278-d8b58ade-6590-4201-bae2-85d503cf1704.png)
 서로 다른 gradient discent algorithm이 수렴하는 과정을 보여준다.

## Learning rate scheduling

 * Learning rate: key hyper parameter for gradient-based algorithms; need to gradually <u>decrease</u> learning rate over time
 e.g. decay learning rate by every half of few epochs

 ![image](https://user-images.githubusercontent.com/122149118/221073887-8f9df0c4-1652-4c4c-9f8c-4d4f160a1455.png)

 ![image](https://user-images.githubusercontent.com/122149118/220940132-fe20b282-eb79-484c-80e3-59086247ccde.png)

 실질적으로 model을 학습할 때 사용할 수 있는 tip이다.
 바로 hyper parameter α를 과정에 따라 조정하는 것이다.
 graph에서 보이는 바와 같이 low learning rate와 같은 경우에는 천천히 수렴하게 되지만 loss를 줄일 수가 있다.
 반대로 high learning rate와 같은 경우 학습이 진행될수록 수렴하는 정도가 low learning rate에 비해 줄어들지 않지만 보다 더 빠르게 학습을 진행할 수 있다고 하는 장점이 있다.
 이런 두 가지의 장점을 혼합하기 위해 수렴 단계마다 적응적으로 조절해 나가면 된다.
 수식에서 보이는 바와 같이 step size α를 학습 과정에 따라서 점차 줄여나가게 된다.
 초기에는 학습을 빠르게 진행할 수 있는 반면에 α값이 늘어나게 됨에 따라서 cost가 더이상 줄어들지 못하는 문제를 learning rate를 점차 줄임으로서 보다 더 학습을 용이하게끔 할 수 있다.

 model의 과적합 문제를 해결하는 최적화 과정에서의 몇 가지 tip을 설명한다.
 > Model 과적합 문제
 > Model이 지나치게 복잡하여, 학습 Parameter의 숫자가 많아서 제한된 학습 sample에 너무 과하게 학습이 되는 것이다.

## Some optimization in regression

 **to avoid overfitting**

 * If we have too many features, the hypothesis may fit the training set very well. However, it may fail to generalize to new samples

 ![image](https://user-images.githubusercontent.com/122149118/221075594-286af3d4-c348-4cbd-9a20-1ea3e0f6e9f4.png)


 예를 들어, 학습 하고자 하는 개형이 오렌지색과 같이 구성되어 있다면 polinomial degree4가 가장 최적이지만 그 이후에 증가하는 차수에 따라서 과적합이 발생하는 것을 볼 수 있다. 
 현재 sample에 대해서는 오차가 대단히 적어지지만 실제 함수의 개형을 따라간다고 보기에는 어려울 것이다. 

 <i>x<sub>1</sub></i> = size of house
 <i>x<sub>2</sub></i> = no. of bedrooms
 <i>x<sub>3</sub></i> = no. of floors
 <i>x<sub>4</sub></i> = age of house
 <i>x<sub>5</sub></i> =
 <i>x<sub>6</sub></i> = kitchen size
 ...
 <i>x<sub>100</sub></i> 

 ![image](https://user-images.githubusercontent.com/122149118/221076283-070e4de5-3333-49b4-ae4c-f4271f70bd38.png)

 More features → more parameters → need more data ; (in practice) less data → overfitting
 Furthermore, mean-squared-error is sensitive to outliers

 예를 들면 다음과 같이 집값을 추정하는 regression model에서 입력 feature의 숫자가 지나치게 많아진다고 하면 항상 좋은 것만은 아니다.
 일부 입력 변수들은 상호 간에 dependent할 수도 있다.
 그러나 입력 feature의 숫자가 많아지게 된다면 더욱 parameter의 개수가 많아지게 되고 그것은 curse of dimension problem에 의해서 data의 개수가 더 많아지게 된다고 하는 것이다.
 하지만 실질적으로 실제 환경에서는 data를 충분히 늘릴 수가 없기 때문에 이 model이 overfitting이 되는 문제가 발생을 하게 된다.
 더욱이 mean-squared-error와 같은 경우에는 이러한 noise, outlier에 굉장히 민감한 특성을 가지게 된다.
 이러한 문제를 해결할 수 있는 대표적인 방법은 Regularization 방식이 있다.

 1. Reduce number of features.
    - select which features to keep.
 2. Regularization
    - keep the features but reduce magnitude/values of parameters
    - Simple hypothesis and less prone to overfitting and robust to noise

  ![image](https://user-images.githubusercontent.com/122149118/221078072-202f2fda-c0d2-44c3-a3a8-fbd2500257c7.png)
  ###### λ : regularization parameter

  ![image](https://user-images.githubusercontent.com/122149118/221078186-3298ee48-74c3-44a1-bc79-046d0d3c240a.png)
  <i>θ<sub>0</sub> + θ<sub>1</sub>x + θ<sub>2</sub>x<sup>2</sup> + θ<sub>3</sub>x<sup>3</sup> + θ<sub>4</sub>x<sup>4</sup></i>

 위 그림에서와 같이 parameter의 숫자에 따라서 model 복잡도가 서로 다르다고 생각해본다.
 이 때 regularization은 수식에서와 같이 설령 복잡한 model을 사용하더라도 학습 과정에서 model의 복잡도에 대한 penalty를 주어서 model이 overfitting되지 않도록 하는 방식이다.
 첫 번째 나타나게 되는 term은(<i>h<sub>θ</sub>(x<sup>(i)</sup> - y<sup>(i)</sup>)<sup>2</sup>) MSE, 즉 model이 정답 y에 fitting을 하도록 하는 term이라고 생각할 수 있다.
 이 term을 "fitting"이라고 한다.
 그 뒤에 있는 term은 θ<sub>j</sub>값이 크면 클수록 늘어나게 되는 오류가 된다.
 즉, model 입장에서는 가능한한 θ를 쓰지 않으면서 이 loss를 최소화하도록 하는 노력을 한다.
 θ값을 쓰지 않는다라고 하는 것은 주어진 linear model에서 어떤 특정한 θ값들이 덜 중요하게 된다면 0으로 보내버리는 학습이 진행된다.
 그에 따라서 parameter의 개수를 줄임으로서 model의 복잡도를 자연스럽게 줄일 수 있게 된다.
 따라서 model은 가급적 적은 숫자의 parameter를 사용하면서 주어진 문제의 sample들을 fitting하고자 할 것이며 그에 대해서 overfitting의 문제를 피할 수 있다.

## Quiz

 **What answers are correct?**

 **A.** Gradient descent produces a numerical solution but it may not acheive a global optimum
 Gradient descent algorithm이 numerical한 solution을 제공하는데 항상 global optimum을 달성하지 못한다.
 **A. Correct** The solution can be different with an initial point of an error surface
 Gradient descent algorithm은 항상 local optimum에 빠지기 쉬운 위험이 있다.
 현재 단계에서의 gradient 방식으로 그 다음 단계를 진행하기 때문이다.

 **B.** Momentum of previous gradien descent can help avoid overfitting
 이전의 gradient descent에서의 momentum은 overfitting을 피하는데 도움이 된다.
 **B. False** Momentum can avoid local minimum and help obtain a solution close to global optimum
 Momentum은 gradient descent algorithm을 통해서 학습을 진행하는 중간에 local minimum을 피하기 위해서 사용하는 기술이다.

 **C.** Regularization can penalize the importance of some input features to avoid overfitting
 Regularization은 overfitting을 피하기 위해 사용하는 기술로 특정한 입력 featrue의 중요성에 대해 penalty를 준다.
 **C. Correct** Regularization can decrease some weights to have compact sets of parameters
 Regularization 방식은 θ에 대한 term을 이용하여 어떤 weight들이 필요없는 경우에는 과감하게 model이 0으로 가깝게 보내서 model을 단순하게 만드는 방식을 말한다.

## Summary

* Optimization in general ML/DL
   - General ideas of gradient descent algorithm
   - Mostly stochastic gradient descent and its variants using gradien estimates
   - Adam is a good default choice in most cases
* Regularization
   - Reduce magnitude/values of parameters while keeping features
   - Simple hypothesis and less prone to overfitting
   - Robust to noise

비록 stochastic gradient 방식이 많이 사용되고 있지만 그것에 변화된 algorithm 역시 개선된 형태로 보다 더 local optimum을 피하기 위해 개발이 되고 있다.
그 중에서도 Adam은 가장 좋은 gradient descent algorithm의 선택지가 될 것이다.
그 이외에 최적화 방식으로도 regularization에서 설명했던 어떤 특정 parameter 중요성에 따라 학습을 진행하는 동안에 overfitting을 피하기 위해 model의 복잡도를 줄이기 위한 방식이다.