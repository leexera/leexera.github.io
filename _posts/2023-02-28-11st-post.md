---
layout: post
title: "객체 탐지(Object detection)과 분할(segmentation) Overview"
description: "Part 2. 컴퓨터비전 특화 이론과 실습"
date: 2023-02-28
tags: study
comments: true
---

* 📌 Classical Object Detection
   ###### Classical Object Detection이 어떻게 진행되는가, feautre extraction으로부터 어떻게 decision boundary를 그려서 object bounding box를 찾았었는지 알아본다.
* 📌 Region Proposal : R-CNN
   ###### Deep learning 기반의 방법으로서 Region Proposal를 사용하는 Two stage detector인 R-CNN Region CNN 계열의 network를 배워본다.
* 📌 One stage Detector : YOLO
   ###### One stage detector인 YOLO와 같은 network를 배워본다.
* 📌 Feature Pyramid Network
   ###### 조금 더 detection을 잘하기 위해서 사용하는 technique인 Feature Pyramid Network와 같은 image의 multi scale 정보를 integration하는 Network를 배워본다.
* 📌 EfficientDet
   ###### Efficient Detector라고 하는 Efficient Net과 비슷하게 Network의 scale등을 키우면서 조금 더 효과적인 network를 얻고 detector를 만드는 것에 대하여 배워본다.
* 📌 DETR(Detection Trnasformer)
   ###### DETR(Detection Transformer), 최근에 유행하는 Vision Transformer 구조를 사용한 detection transformer라는 DETR구조를 배워본다.
* 📌 3D Objectdetection
   ###### 2D Object 뿐만 아니라 3D Object를 2차원 평면상에서 어떻게 찾을 것인지에 대해 배워본다. 2D image상에서 3D의 scale을 어떻게 찾을지 3D object를 찾을지에 대해서 다룬다. <del>3D data 구조에 대한 것은 다루지 않는다.</del>

* Semantic Segmentation : SuperPixel
   ###### image의 pixel level의 어떤 classification label, 또 위치도 찾아주는 Semantic Segmentation에 대해서 배워본다. 고전적인 방법인 SuperPixel 방법을 먼저 이야기 한다.
* Fully-Convolution Networks(FCN)
   ###### Fully-Convolution Network(FCN) 이라는 첫 번째로 나왔던 semantic segmentation 문제를 푸는 Network에 대해 배워본다.
* DeconvNet, U-Net
   ###### 좀 더 image의 prediction을 높이기 위해 사용했던 DeconvNet이나 U-Net과 같은 어떤 Upsampling convolution을 사용하여 Network를 구성하는 model들에 대해 배워본다.
* DeepLab
   ###### Semantic Segmentation에서 한 획을 그었던 DeepLab series, DeepLab과 CRF관련하여 post processing한 기법들에 대해 배워본다.
* Mask R-CNN
   ###### instance segmentation 문제를 푼 것으로 instance segmentation은 semantic segmentation과 object detection을 합쳐서 object가 어디에 있는지도 파악을 하고 어떤 segmentation label에 갖는지 동시에 판단하는, mask R-CNN에 대해 배워본다.
* Segmenter
   ###### Segmenter라고 부르는 vision transformer 구조를 사용하여 feature를 extraction하고 segmentation mask를 찾아내는 segmentation 구조에 대해서 배워본다.
* Weakly-Supervised Learning
   ###### 강한 지도학습이 아닌 classification label만 가지고도 object detection, 더 어려운 object detection이나 semantic segmentation같은 문제를 푸는 Weakly-Supervised object detection, Weakly-Supervised Learning기법에 대해 배워본다.
* Grad-CAM
   ###### 대표적인 방법인 Grad-CAM, Gradient Class Activation Map, Class Activation Map을 수도 lable로 사용하여 semantic segmentation이나 object detection을 푸는 기법에 대해 배워본다.
* Human
   ###### Human Pose Estimation이나 Human Pose Recognition과 같은 Human과 관련된 2차원 정보에서 정보를 추출해내는 Human 관련 task를 배워본다.

---

# Popular Visual Recognition Tasgks

 ![image](https://user-images.githubusercontent.com/122149118/221815712-f6848f1e-652e-4a38-aa52-3206c2a3feba.png)

 왼쪽은 Image classification Task를 푼다고 한다면 Image의 어떤 class label이 있는지 찾는 것이다.
 Person이 있고 Bike가 있다는 것을 알 수 있다.
 이것을 순화하여 Object detection이라고 하면 사람이 있는 곳에 사각형의 bounding box를 찾아주고 오토바이가 있는 곳에 사각형의 bounding box를 찾아주는 것이 object detection이다.
 semantic segmentation은 pixel 수준에서 pixel 수준의 classification label을 찾아주는 task이다.
 사람의 각 요소들에 대해 빨간색으로 Human이라고 annotate가 되고, 오토바이에 대해서는 초록색으로 bike라는 annotate가 되는 정보를 찾는 것이다.
 노란색 영역에 대해서는 don't care 영역이기 때문에 사람이 결국 평가해야하는데, 사람이라고 하기에도 오토바이라고 하기에도 모호한 back ground라고 하기에도 모호하여 don't care, 굳이 구분해도 되지 않아도 되는 영역을 노란색으로 나타내었다.
 따라서 visual recognition task를 크게 3가지로 나눌 수 있다.

 ![image](https://user-images.githubusercontent.com/122149118/221822379-805008c0-068f-452f-8c8f-42dcb5429185.png)

 조금 더 detail하게 살펴 보면 classification 문제가 있고, classification의 single object에 대해서 또는 여러 장의 object가 있을 수 있지만 기본적으로 single object에 대해서 찾는 task이다.
 그리고 semantic segmentation은 class에 pixel level label image에서 pixel level label을 찾아주는데 예를 들어 GRASS나, CAT, TREE, SKY를 segment를 나누어 주게 된다.
 어떤 object 위주를 찾아주는 것은 아니고 pixel만, 어떤 pixel이 무슨 class정도 인지정도만 class label을 찾아주는 것이다.
 반면에 object localization이라는 task는 classification과 localization을 더하여 object가 어디있는지 localize를 해주고 그게 어떤 class인지 'CAT'이라고 찾아주는 것이다.
 보통 object localization은 하나의 single object에대해서만 대체로 한다.
 Object Detection은 Object localization과 달리 여러 개의 object가 있을 수 있고 그 object들의 각각의 label을 찾아주는 'DOG'가 있으면 'DOG' bounding box가 있고 Dog에 대해서 class를 찾아주고, 'CAT'에 대해서 bounding box를 찾아주고 class label을 찾아주는 것이다.
 Instance Segmentation은 Semantic Segmentation과 Object Detection을 합친 것과 같다.
 Semantic Segmentation은 object의 위치를 찾아주고 거기에 대해서 Sementic label, Sementic segmentation label을 찾아주는 task이다.

# Deep Learning for Object Dtection : A Naive Approch

 ![image](https://user-images.githubusercontent.com/122149118/221826138-b936a933-8ad0-49f7-b53b-43ba9559fdd6.png)
 ###### (<i>left</i>) Selective Search for Object Detection, UCV 2013
 ###### (<i>right</i>) Edge Boxes : Locating
 Motivated by the great success of deep learning in image classification
 Object Detection = Box localization(➡ Object proposals) + Box classification(➡ CNN)

 Object Detection을 위한 가장 naive한 approach는 image classification과 비슷한 방식을 사용하는 것이다.
 먼저 Box를 localization하고, Box에 대해서 Classification을 해서 Box가 무엇인지 알게된다.
 보통 Box localization은 Object proposals를 뽑는다.
 그리고 Box classification은 CNN 구조를 사용하여 뽑거나 기존의 고전적인 classification model인 softfactor machine이나 그러한 기법들을 사용한다.
 기본적인 Object Detection의 예시는 왼쪽에 나타나있는 Selective Search라는 것을 사용하여 Object Detection을 하게 된다.
 Selective Search를 통해서 Bounding Box를 찾는다.
 그 Bounding box들에 대해서 classification을 하여 아무것도 아닌 confidence가 너무 낮은 파란색과 같은 box들은 아무것도 아니라고 해주고 젖소를 가장 잘 잡은 box에 대해서는 초록색으로 나타내준다.
 영역들에 대해서 corse하게 먼저 찾아주고 영역을 나누어 fine하게 찾아 찾아진 object 영역들을 하나의 어떤 box들로 다시 merge를 해주는 방식으로 찾아준다.
 오른쪽에 나타나있는 그림은 Edge Box라는 algorithm으로 Edge proposal들을 활용하여 찾아주는 Object proposal을 찾는 algorithm이다.

# Region-based CNN* (RCNN)

 ![image](https://user-images.githubusercontent.com/122149118/222064503-3ee5fbc8-a0ac-4b51-9d31-7feef11bef80.png)

 Object proposal을 찾는 방식을 기반으로 region proposal자체를 학습하거나 region proposal로부터 CNN을 활용하고자 하는 RCNN, region based CNN 계열의 논문들이 많이 나오기 시작한다.
 Input image가 들어가면 selective search, edge box등, 다른 network들을 이용하여 region proposal을 뽑고, 그 다음 CNN feature들을 뽑고 architecture를 통해서 어떤 box에 대해서 class에 대한 label이 Yes인지 또는 No인지 classification하는 것이다.
 이 때는 softmax나 SVM을 이용하여 어떤 logic 값을 통하여 classification을 하게된다.

 **Summary**
 * Independent evaluation of each proposal Any architecture
 * Bounding box regression imporves detection accuracy
 * Mean average precision (mAP): 53.7% with bounding box regression in VOC 2010 test set

 어떤 proposal network를 다 사용하여도 독립적인 평가가 가능하다.
 Bounding Box regression을 통해서 Bounding Box 자체도 학습을 하는 제안을 했다.
 Object detectio의 evaluation metric인 Mean average precision (mAP)의 성능도 향상시켰다.

 * Learning a transformation of bounding box

 ![image](https://user-images.githubusercontent.com/122149118/222064681-e28934cf-747b-4199-a93a-8c923ccc3a2e.png)

 RCNN의 기본적인 이념은 bounding box의 transformation을 배우는 것이다.
 어떤 region proposal의 후보가 나왔을 때 그 근처로 어떻게 Ground Truth로 가는 차이를 transformation을 학습을 하여 box를 옮겨주는 형태로 학습을 하는 loss function을 사용한다.
 최종적으로 box, prediction과 Ground Truth를 가깝게 만드는 형태로 loss를 제안했다.

# Faster R-CNN with ResNet

 ![image](https://user-images.githubusercontent.com/122149118/222064744-7642acd2-cc58-47a7-a60c-52609c70919e.png)

 Resion based CNN을 조금 더 좋게 만드는 Faster RCNN이 있다.
 최근격이라고 말할 수 있는 two stage detector의 Faster RCNN의 결과는 object들을 잘 잡아주는 것을 위의 사진을 통해 정성적인 결과를 확인할 수 있다. 
 
 ![image](https://user-images.githubusercontent.com/122149118/222064835-145036cb-3d6f-4fee-b91a-8e1fbf5c7ab2.png)

 어떤 random한 drama 장면에 대해서도 detection을 높은 confidence score로 찾아내는 것을 확인할 수 있다.

# Fully-Convolutional Networks (FCN) for Semantic Segmentation
 
 * The first end-to-end architecture for semantic segmentation
 * Interpreting fully connected layers of classification nets as 1x1 convolutions

 object segmentation, 특히 semantic segmentation이나 instance segmentation의 network에 대해 나타나 있다.
 첫 번째로 deep learning 기법을 사용했던 Fully-Covolutional Network (FCN)과 semantic segmentation을 위한 첫 번째 end-to-end network이다.

 ![image](https://user-images.githubusercontent.com/122149118/222064921-13a4a1b3-aa7e-4959-99ea-981ce9e4740e.png)

 기존의 image classification이 Query image에 대해서 convolution을 통과해서 fully connected layer로 하나의 output vector, 1 by 1 by 21개의 class를 예측하는 output vector를 만들었다면 Semantic Segmentation은 동일하게 Query image가 들어가 convolution을 통과해서 output vector가 아니라 output feature map이 나온다.
 위에서는 16 by 16 by 21 size의 feature map이 도출되었다.
 각 위치에 대해서 어떤 resolution이 maxpooling된, specially pooling된 작은 feature map이 나오는 형태로 prediction한다.
 이것을 다시 upsampling하게 되면 각 query image에 대해서 어디가 segmentaion mask인지 알 수 있게된다.
 각 class label을 prediction 할 수 있다.
 classification network의 fully-connected layer를 1 by 1 convolution으로 해석하여, fully-connected layer가 결국 어떤 FC layer가 1 by 1 convolution이 영역에 대해서sliding 하는 것과 같기 때문이다.
 1 by 1 convolution을 사용하여 convolutional network를 묘사하게 되었다.

# Segmenter using Vision Transformer

 * Current model using vision transformer
 * Improving the segmentation quality very much

 ![image](https://user-images.githubusercontent.com/122149118/222066367-7603d0be-9835-44f2-b46b-85eb2fefa7fe.png)

 최근 나온 work는 segmenter라는 방식인데 vision transformer 구조를 활용하여 semantic segmentation 문제를 푸는 것이다. 
 21년에 나온 model로 segmentation quality를 크게 늘렸다.
 방식은 어떤 input image가 있으면 patch 단위로 쪼개어 Transformer encoder 통과시킨다.
 다시 Mask Trasnsformer에 통과시켜서 어떤 label에 대해서 class token들을 넣어주고 그 class에 대해서 mask를 prediction한다. 
 pixel level classification이므로 어떤 mask score가 가장 높은 patch의 level에 대해서 다시 upsampling하고 다시 patch로 폴딩해주어 segmentation mask를 구해낸다.
 pixel level score를 사용하여 완성된 segmentation map을 도출한다.

# FCN (2015) to Segmenter (2021) for semantic segmentation

 ![image](https://user-images.githubusercontent.com/122149118/222522071-d4896b02-a9a8-4980-b5cb-da69e0d31e5d.png)

 ⬇{: .center}

 ![image](https://user-images.githubusercontent.com/122149118/222523252-bbe86ba0-0f3d-4aa6-beb5-c488a3662688.png)

 결과적으로 FCN과 segmentation 사이에 gap이 존재하는데, 맨 위는 FCN의 결과이다.
 기존의 SDS, 고전적인 방법, Deep Learning을 사용하지 않는 SDS의 결과가 위와 같이 도출되는데 FCN은 고전적인 방법에 비해서 상당히 영역들을 잘 잡아내는 것을 볼 수 있다.
 image를 넣었을 때 Ground Truth와 어느정도 말과 사람의 image도 잡아내고 오토바이 image들도 나름 약간의 noise는 존재하지만 잘 잡아내는 결과를 확인할 수 있다.
 양에 대해서도 잘 잡는 것을 볼 수 있다.
 하지만 segmenter까지 넘어오는 과정을 보면, Deep Learning 기반의 model 중 DeepLabv3+가 좋은 model이었지만 DeepLabv3+와 비교했을 때 segmenter는 boundary까지도 아주 잘 잡아주는 것을 볼 수 있다.
 공들에 대해서도 하나하나 detail하게 결과를 잡아낸다.
 이러한 결과를 DeepLabv3+와 비교했을 때 훨씬 더 세부적으로 잘 잡아내는 결과를 보인다.
 마찬가지로 DeepLabv3+는 사람들에 대해서도 약간 틀릴 수도 있는 모습을 보이지만 segmenter는 조금 더 detail하고 정확하게 잡아낸다.
 DeepLabv3+같은 경우 noise같은 것도 생기지만 segmenter는 더 정확하게 잡아내는 더 잘 학습되는 모습을 볼 수 있다.