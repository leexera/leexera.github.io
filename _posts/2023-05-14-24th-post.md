---
layout: post
title: "Feature Pyramid Networks(FPN)"
description: "Part 2. 컴퓨터비전 특화 이론과 실습", "Ch05. 객체탐지(Object Detection)와 분할(Segmentation)", "Object Detection - Object Detection by CNN"
date: 2023-05-14
tags: study
comments: true
published: true
---

# Additional Object Detection Techniques
 * Feature Pyramid Networks
 * Path Aggregation Networks
 * Efficient Model Search
 * Transformer-based Models

# Feature Pyramid Networks(FPN)
 * R-CNN family achieves the state-of-the-art performance in object detection
 * Stronger backbone network, better detection performance
 <b>Pascal VOC 2007 Object Detection mAP(%)</b>
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/83889f1a-c41e-4184-8ec8-badbfe515f1e)
 feature pyramid network는 faster R-CNN과 같은 model을 기반으로 만들어진다.
 AlexNet이나 VGG에서 ResNet으로 올라갈수록 더 좋은 detection performance를 내게 된다.

 * A challenge in object detection: Detecting objects of vastly different scales
 * Previous solutions
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/186d0997-d12a-4dd1-a92a-9bc7f1d71615)
 <b>Image Pyramid</b>
    Constructing an image pyramid and running an object detector for all the images: <mark>Computationally heavy</mark>
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/1f7bdb52-ca6b-4cc3-ad67-a9f8e166c0c5)
 <b>Feature Hierarchy</b>
    Running a detector per feature level: <mark>Low-level features lack semantic info, and high-level ones are too small in resolution</mark>
 FPN의 motivation은 어떤 object를 찾을 때 다양한 different scale에 대해서 찾을 수 있어야 한다는 것이다.
 image pyramid는 image를 resize하여 원본 image에 대해 down sampling하여 image pyramid를 만든다.
 이렇게 생성한 image pyramid는 scale robustness는 보장될 지 몰라도 heavy한 computational을 가진다.
 반면에 feature hierarchy에서 feature를 추출하는 것은 low-level feature는 너무 semantic 정보가 없고 geometric 정보가 많으며 high-level feature는 너무 resolution이 작아서 object를 정확하게 찾기에는 부적절하다.

 * A smart solution: <i>Feature Pyramid Network (FPN)</i>
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/51a5fc67-0f93-4af6-a5f4-3038cb488b6f)
 * As fast as the methods using feature hierarchy
 * More accurate thanks to the upsampling module exploiting high-level feature maps
 solution을 통해 object의 지역적인 정보도 판단하면서 high-level sementic도 encoding할 수 있는 구조가 제안된다.
 구조는 bottom up top down 구조를 가진다.
 bottom up에서는 기존 feed forward network를 똑같이 통과시키고 top down path에서 먼저 coarser한 resolution feature map을 2배로 키운다.
 더 작은 feature map을 2배 키우고 higher resolution map에 1 by 1 convolution을 통과시켜 channel size를 줄여준다.
 위에 있는 feature map과 아래있는 feature map의 size, w, h, c가 같아지도록 만든다.
 2개의 feature map을 element-wise addition을 통해 merge해준다.
 이러한 과정의 특징은 feature hierarchy에서 feature를 뽑아오는 것만큼이나 충분히 빠르다고 한다.
 high-level feature map의 upsampling module을 사용하여 충분히 정확한 feature accuaracy를 나타낼 수 있다.

 * Feature pyramid variations
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/0fe22c2d-760d-4206-9f3e-25ba5b257b5e)
 (a)는 image pyramid를 만든 다음에 똑같은 ConvNet을 통과시켜서 feature map을 만드는 것이다.
 그 위에서 각각 따로 prediction을 수행하는 것이다.
 그렇기에 ensemble이 가능하다.
 (b)와 같은 것이 R-CNN과 YOLO와 같은 계열로 single feature map에서 feed forward를 하여 output feature에서 prediction을 하는 것이다.
 반면 (c)는 image를 feed forward에서 통과시키면서 Conv1에서 prediction을 가져오고 Conv2에서 prediction을 가져오고, Conv3에서 prediction을 가져오는 형태를 가진다.
 (d)는 각각의 feature를 뽑은 후 top-down pathway를 추가시켜 1 by 1 convolution으로 update를 하고 위에서는 2배 upsampling을하여 더해주는 구조를 제안한다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/d3ebfe24-3f80-400d-b5ed-f0be2b3981bc)
 image pyramid들이 합쳐지는 전반적인 과정을 도식화한 것이다.
 위에 있는 image는 resolution이 작은 상태이기 때문에 2배 upsampling을 하여 resolution을 맞추어주고 resolution이 큰 feature는 1 by 1 covolution을 통해 channel size를 맞춰주게된다.
 이 두 개를 더하여 다음 단계로 넘어가게 된다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/fb5010fc-9b08-489f-901a-41ebb3a1fcdd) 
 첫 번째 그림은 skip connection을 사용한 top-down architecture를 나타낸 것으로 pathway를 주었어도 prediction은 마지막 coarse한 map에서만 수행하였다.
 반면 FPN은 모든 top-down pathway에 대해서 bounding box predictor를 통과시켜주고 feature pyramid의 prediction할 수 있는 요소들을 더 leverage했다는 특성이 있다.

 * Results
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/5e5f578d-1b48-4724-8305-9848ccfbdf30)
 Feature Pyramid Network를 사용한 Region Proposal Network과 Fast R-CNN을 사용했을 때의 결과이다.
 conv4만 사용한 baseline이나 conv5만 사용한 baseline에 비해 FPN은 2배로 키우고 chennel을 1 by 1 convolution으로 맞춰주는 lateral connection을 사용했고 top-down pathway도 사용한 FPN이 Average Recall 관점에서 조금 더 높은 성능을 낸다.
 bottom-up pyramid나 top-down pyramid를 사용했을 때 각각의 ablation 성능을 볼 수 있다.
 오직 finest level, P<sub>2</sub>에 대해서만 사용했을 때에도 ablation을 수행한다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/4144abbb-dfb4-4c0b-a3a6-52cd45a75896)
 Fast R-CNN에서 backbone을 FPN구조로 바꾸었을 때 detection Average Precision이 conv4에서 추출한 baseline나 conv5에서 추출한 baseline보다 충분한 성능 향상을 보인다.
 conv4를 사용한 경우가 conv5보다 성능이 더 높은 이유는 conv5가 high-level sementic을 잘 encoding하고 있더라도 resolution이 너무 크게 줄어들기 때문에 conv4를 사용한 경우가 조금 더 정밀하게 bounding box로 localization이 가능하고 bounding box를 통해서 patch의 classification을 구할 수 있는 것이다.

 * Comparisons of single-model
 * Results on instance segmentation
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/86d0d3cb-51e2-4a9e-9998-85f3415cdda7)
 FPN구조에서 최종적으로 output feature map의 upsampling을 하여 boudning box instance mask를 구할 수 있다.
 이러한 mask를 사용하여 평가한 결과이다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/f4027deb-6d12-4389-8ec8-1cdb6263a094)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/7238d483-69cc-44aa-a093-afcd4269eb6e)
 기존 baseline들 보다 더 좋은 성능을 낼 뿐만아니라 속도도 충분히 빠르다.

 * Conclusion: scale robustness는 object detection에 중요
 * Image pyramid를 만드는 것보다 feature pyramid를 만드는 것이 효과적
 * post-work: PANet(Path-aggregation network) → top-down-top을 활용

