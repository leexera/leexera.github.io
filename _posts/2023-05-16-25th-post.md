---
layout: post
title: "PANet, EfficientDet"
description: "Part 2. 컴퓨터비전 특화 이론과 실습", "Ch05. 객체탐지(Object Detection)와 분할(Segmentation)", "Object Detection - Object Detection by CNN"
date: 2023-05-16
tags: study
comments: true
published: true
---
# Path Aggregation Network (PANet)
 * PANet: top-down path의 Feature Pyramid Network에서 botton-up path를 추가하여 object detection에서의 scale robustness를 키움
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/157908c2-7a9f-428b-ba12-a24eb46150ee)
 (a)부분이 Feature Pyramid Network backbone이다.
 (b)에서 추가적으로 bottom-up path augmentation을 한다.
 즉, 다시 아래에서 위로 올라가는 path가 주어지게 된다.
 (c)에서는 각 bottom-up path의 feature에 대해서 모두 가져와 더한 다음 feature pooling을 수행한다.
 그 다음 두 개의 branch로 나뉘는데 첫 번째 branch (d)는 object detection branch로 box regression과 calssification을 각각 수행한다.
 (e)는 fully connected fusion을 통해서 mask prediction을 하여 instance segmentation을 같이 수행한다.

 * PANet main contribution: bottom-up path 구조
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/ec8208e3-153c-4140-820e-1e8ed7d35494)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/eeeaf14b-f901-4683-a5b8-561d1164b6b6)
 하나의 path가 다음과 같이 수행되는 것을 알 수 있다.
 기존의 feature pyramid network와 같이 feature가 down sampling되어 size가 작아지고 옆에서 오는 값은 1 by 1 convolution gating을 통과하거나 또는 그냥 들어와서 element와 더해져 output N<sub>i + 1</sub>을 만든다.
 N<sub>3</sub>가 N<sub>4</sub>가 되기 위해서는 N<sub>i</sub>와 P<sub>i + 1</sub>이 같이 들어와서 N<sub>i + 1</sub>을 만드는 것이다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/d73e454b-7293-45cb-8891-f47f04d9a1f5) 
 Region Of Interest patch가 잘려왔을 때 conv3 layer까지 통과되고 conv4에서 하나는 deconv으로 size를 키우고 다른 하나는 fc layer를 통과하여 fully connected layer를 통해 class probability를 만든다.
 이 두 개를 덧셈하여 mask를 구하게 된다.

 * Results: COCO instance segmentation challenge 2017에서 높은 성능 달성
 * conclusion: bottom-up connection이 image의 더 좋은 features 생성에 도움이 됨(e.g., low-level cues(지역적인 부분) + high-level semantics encoding)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/84c162fd-1699-4f2f-976b-1817b28283e1)
 기존의 Mask R-CNN + FPN보다 PANet이 더 높은 성능을 내는 것을 볼 수 있다.
 두 가지 score로 나누어진 이유는 왼쪽은 single scale로 training한 것이고 오른쪽은 multi scale로 training한 것이다.
 multi scale로 training했을 때 일관성있게 성능 향상이 일어나는 것을 볼 수 있다.
 backbone이 ResNet-101에서 ResNeXt-101으로 바뀌어도 충분히 더 높은 성능이 나타났다.
 fairness관점에서 multi scale training(ms-train)은 image scale을 말하는 것인데 image pyramid를 만들어 training했지만 기존 baseline은 그렇지 않기 때문에 fair한 비교는 아니다.
 feature space에서 scale차이가 나는 feature map을 사용하지만 scale robustness를 수학적으로 완벽하게 따라할 수는 없기 때문에 image pyramid를 만들어서 multi scale training이나 multi scale inference를 수행하기도 한다.
 여전히 feature의 hierarchy 활용하고자 하는 기법들 중에서도 image pyramid를 쌓는 것은 성능 향상에 중요하게 작용한다는 것을 나타낸다고 볼 수 있다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/549939fd-17fc-4de0-a4ed-0cfb0f001a13)
 instacne segmentation의 정성적 결과이다.
 작은 object에서도 bounding box와 segmentation mask들을 아주 잘 찾아낸다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/ccdc411f-f7db-40ee-9fad-a8fd707c25be)
 PANet baseline에 DCN을 추가하고 testing trick, multi scale feature와 같은 model을 추가하고 더 큰 model로 바꾸었을 때 성능 향상, 최종적으로 ensemble까지 하여 성능을 최대한으로 끌어올린 결과이다.

# EfficientDet: Efficient Model Search

 * EfficientNet과 비슷한 model search
 * BiFPN 구조를 채택하여, top-down, bottom-up 정보의 propagation을 함
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/604889e3-fc7c-4297-83ca-1d905bff7837)
 Figure 2: A sort of pyramid propoagations
 (a)는 기존 feature pyramid network로 각 feature가 있을 때 top-down으로 합쳐져서 각각의 prediction을 수행하는 결과를 보인다.
 (b)는 Pass Aggregation Net은 top-down 후 다시 bottom-up을 하여 feed fowarding을 하나씩 연결을 해 준 다음 각 pyramid에서 prediction을 수행한다.
 (c)는 NAS-FPN이 등장하였는데 feature pyramid상에서 어떻게 연결했을 때 가장 좋을지 neural architecture를 search하여 feature pyramid network를 구성한 것이다.
 top-down과 bottom-up pathway가 model에서 찾아져 random하게도 보일 수 있지만 가장 effective하다고 보이는 block이 찾아져 구해진다.
 (d)는 Efficient Detector에서 제안하는 구조인 BiFPN은 top-down pathway가 이전 feature에서 옮겨가는 형태로 이루어지고 다시 올라가는 형태이다.
 residual connection까지 같이 있어 최종적으로 repeated block이 구성되게 된다.
 BiFPN구조를 반복시킨 것이 이 detector에서 사용하는 scale robustness나 여러가지 feature를 최대한 exploitation하기 위한 구조이다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/25b46619-6922-4ae3-b3a3-49159be380e2)
 Figure 1: Model FLOPs vs. COCO accuracy
 FLOP 수는 model parameter 수를 나타낸 것으로 parameter 수가 증가할 때마다 Average Precision evaluation metric이 증가하는 것을 볼 수 있다.
 이전에 있던 best model인 YOLO v3나 mask R-CNN, RetinaNet, ResNet + NAS-FPN, AmoebaNet + NAS-FPN + AA(Auto Augmantation)보다 model parameter 수는 훨씬 덜 가지면서 AP는 높은 성능을 보인다.

 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/92307714-c89b-4669-abcc-3fad8e45f6e2)
 Table 1: Scaling configs for EfficientDet D0-D6
 model이 커질수록 input image size를 키우는 것이 확실한 성능 gain이 object detection에서 있다.
 backbone network 또한 어느정도 커진다.
 사용하는 BiFPN 구조에서 chennel size와 layer 수도 점점 커지는 것을 알 수 있다.
 box와 classification의 number of layer가 커질수록 resolution도 커지는 형태를 가진다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/13ec61a8-e60e-4d2b-adfc-64f2db751e13)
 EfficientNet의 backbone을 그대로 사용한다.
 얼마나 width와 depth를 증가시킬지에 따라 달라지는 backbone이다.
 resolution을 2씩 줄이는 part에 대해서 feature를 추출한다.
 추출한 feature에 대해서 stacking한 BiFPN layer를 통과시킨다.
 residual path와 top-down path, bottom-up path가 겹쳐져서 feature를 update하는 것이다.
 최종적으로 모든 feature를 사용하여 각각을 ensemble하여 class prediction network와 box prediction network를 통과시킨다.
 clss prediction network는 box의 class가 무엇인지, box prediction network는 box가 어떻게 이동해야할지 regression을 수행하는 branch이다.

 * Results
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/f98ba636-119e-4997-ab64-a7652cd71930)
 EfficientDet-D0는 YOLO v3와 비교해보면 더 높은 AP, detection 성능 score를 가지면서도 model size는 더 작고 parameter 수도 더 적은 결과를 보인다.
 EfficientDet-D1은 RetinaNet과 비교하여 더 높은 성능을 나타낸다.
 EfficientDet-D2는 Detectron2, mask R-CNN에 FPN을 추가한 것인데 Detectron2보다 더 작은 parameter와 더 적은 model size로 더 좋은 결과를 만들어낸다.

 * results: 더 낮은 resource로 더 좋은 결과를 냄
 * conclusion: systematic architecture design choices 선택하기 (for object detection)
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/f8cba808-a8aa-4e79-9a93-a2a890021959)
 EfficientDet이 효과적인 trade off를 보여준다.
 GFLOPs(computer가 연산하는 수), model size(model 학습 parameter 개수), latency(inference time, 실제로 얼마나 걸렸는지)를 기재하는 것이 일반적이다.
 parameter 수가 적어도 primitive operation, 사칙연산이 많아지면 inference time이 그만큼 증가할 수 있기 때문이다.
 ![image](https://github.com/leexera/leexera.github.io/assets/122149118/ae6b0345-8001-4194-82d4-aea844dad8b0)
 backbone을 달리 사용했을 때 얼마나 성능이 달라지는지를 나타내는 table이다.
 BiFPN을 사용했을 때 parameter 수도 적게 사용하고 성능은 더 좋아지는 것을 볼 수 있다.
 parameter 수가 적은 이유는 1 by 1 convolution들이 조금 더 효과적으로 만들어지기 때문이다.