---
layout: post
title: "You Only Look Once (YOLO) : Unified, Real-Time Object Detection"
description: "1 Method and Results"
date: 2023-04-08
tags: study
comments: true
---

# Faster R-CNN (NIPS 2015)

> * A single,unified network
> * Region proposal network with anchor boxes
> * End-to-end training

![image](https://user-images.githubusercontent.com/122149118/230700429-b9013d52-9770-4809-976e-f0d4165cdafe.png)

![image](https://user-images.githubusercontent.com/122149118/230700736-14234634-2411-4545-bffc-86a4e6260ca2.png)

 Faster R-CNN은 single, unified network를 사용하며 region proposal network가 anchor box라는 개념을 도입하여 bounding box를 proposal한다.
 end-to-end로 모든 network를 학습했다.

> * Limitations
>   - Limited flexibility of anchor boxes
>   - Three subnetworks: feature extraction, region proposal, classification/bbox regression

 anchor box의 개수가 적으며 network가 총 3개의 sub network로 구성되어 있어 이 network 중 성능을 감소시키는 연결고리가 있지않을까 하는 의문을 가지게 되었다.

# SSD (ECCV 2016)

> * Feature pyramid with default anchors
>   - the same size of anchors represents different sizes of objects in feature pyramid

![image](https://user-images.githubusercontent.com/122149118/230701456-c4f20a75-da98-4c4b-810f-f860e824ba4b.png)

 SSD는 Faster R-CNN의 anchor box 문제를 해결하기 위해서 feature pyramid에서 anchor box를 적용하였다.
 resolution이 큰 feature map과 resolution이 작은 feature map은 같은 크기의 anchor box가 다른 object 크기를 의미한다는 것에 착안하여 network를 통과하면서 생기는 feature pyramid에서 각각의 resolution에서 detection branch를 뽑아 다양한 크기의 anchor box를 많은 숫자로 prediction할 수 있다.

> * Multi-scale feature maps for detection

![image](https://user-images.githubusercontent.com/122149118/230701901-7990a852-34e5-4dd2-9698-8b04d27ceb53.png) 

 YOLO는 SSD보다 조금 먼저 나왔는데, SSD 논문에서는 YOLO는 custom되어있는 architecture로 너무 simple하고 anchor의 숫자도 98개밖에 없는 성능이 떨어지는 algorithm이라고 이야기하며 반면 SSD는 속도면에서도 빠르고 성능도 좋다고 주장한다.

# YOLO (CVPR 2016)
> * Unified, simple, real-time object detection

![image](https://user-images.githubusercontent.com/122149118/230702084-92e2ea25-46ee-432d-8cfc-fa287ec4c048.png)

 YOLO는 unified, simple, real-time object detection algorithm이다.
 3단계를 거치면 detection bounding box를 찾을 수 있다.
 1단계는 image를 resize하는 것이고 2단계는 convolution network를 통과하는 것, 마지막 3단계는 non-maximum suppression을 수행하는 것이다.
 2단계에서 만들어진 다양한 bounding box를 제거하기만 하면 된다고 주장한다.
 사실 이러한 3단계는 Faster R-CNN이나, SSD도 똑같이 수행하고 있다.
 초창기 논문인 R-CNN이나 Fast R-CNN과는 차이가 있지만 Faster R-CNN과 SSD는 같은 기능을 수행하고 있기 때문에 큰 차이를 나타내는 figure라고 하기에는 어렵다.

> * Grid based approaches for bboxes and class probability

![image](https://user-images.githubusercontent.com/122149118/230702239-6caaf9d9-b5a4-43b6-9fda-a0bcec9aaa18.png)

 YOLO는 기존의 방법들과 다르게 grid based approach를 사용하였다.
 video를 특정 개수 S by S개로 쪼개어 하나의 grid마다 bounding box를 2개씩 추론을 하고 해당 box의 object가 있는지 없는지에 대한 confidence를 같이 학습한다.
 기존의 Faster R-CNN이나 SSD에서 사용한 anchor box based approach와 약간의 차이는 존재하지만 비슷하다고 볼 수 있다.
 <del>Bounding box와 confidence를 합치는 과정은 유사하지만 class probability map을 사용하는 것을 차이점이라고 생각한다.</del>
 기존에는 각 bounding box마다 어떤 class를 의미하는지 학습하였지만, grid마다 어떤 class에 속하는지 판단한다.
 network 자체는 학습을 object 전체에 대한 classification을 수행하는 것이 아니라 object의 part에 대한 classification을 수행하게 된다.
 confidence가 높은 box는 위 그림에서 굵은 선으로 표현된 box로, 이 box에 가장 많이 포함되어있는 class probability로 최종 class를 정하게 된다.
 자전거의 경우를 보면 자전거 class는 강아지 class도 포함하지만 자전거 class에 대한 확률이 가장 높기 때문에 자전거로 bounding box의 색깔을 표현했다.

> * Single scale feature map for detection
>   - 2 bboxes with a confidence score, 20 classes
>   - Fixed resolution for input and output

![image](https://user-images.githubusercontent.com/122149118/230705807-36ca663e-f5e3-4514-9390-0caad89063aa.png)

 SSD와 유사하게 input video가 fixed size로 고정되어 들어온다.
 448 by 448 size를 사용하였으며 최종 출력 결과는 7 by 7 resolution을 가진다.
 처음에는 resolution이 ¼로 줄어들어 112 그 다음 ½배로 줄어들다가 최종 7 by 7에 도달한다.
 7 by 7 convolution에서 시작하여 3 by 3 convolution 위주로 사용되어 network가 구성된다.
 간단하게 구성되어 있는 network를 가지고 마지막 7 by 7 network가 그림에서 보았던 grid이다.
 7 by 7의 한 pixel들이 448 X 448에 해당하는 input video의 grid를 그린 것과 같은 의미이다.
 한 pixel이 30개의 dimension을 갖는데 이 dimension이 bounding box cordinate 4개와 해당 bounding box에 대한 confidence score를 포함하여 총 5개가 bounding box 2개에 대해서 존재하므로 총 10 dimension에 20가지 class에 대한 classification을 포함하여 30 dimension이 된다.
 anchor box approach와 다른 점은 anchor box는 aspect ratio를 정하여 크기를 미리 정해놓았지만 YOLO 논문에서는 크기를 미리 정해놓은 것보다는 network가 알아서 bounding box의 score를 배울 수 있도록 하였다.

> * Training
>   - Loss functions

![image](https://user-images.githubusercontent.com/122149118/230706862-ab95b2ec-78d7-476b-bdc6-88566830bc91.png)

 Faster R-CNN과 SSD에서도 중요하게 다루었었던 background 영역에 대해 어떻게 handling을 할 것인지가 issue였다.
 YOLO에서는 object가 있는 grid, object가 없는 grid로 나누어 loss를 design하였다.
 object가 있는 grid는 obj라고 표시되어있는 index이고 noobj는 object가 없는 grid, 즉 background에 대한 grid이다.
 background에 대한 grid를 따로 정의하여 object가 있는 grid에 대해서 x, y bounding box의 center를 regression해주고 width와 height도 regression해주었다.
 center는 MSE를 사용하였는데 width와 height의 경우에는 root를 씌워 사용하였다.
 그 이유는 너무 object가 큰 경우에 변화가 너무 sensitive하여 object 큰 영역에 대한 gradient를 감소시키기 위해 root를 사용하였다고 한다.
 c는 각 object bounding box에 해당하는 confidence score로 추측할 수 있다.
 <del>confidence score는 bounding box마다 정의가 되어 있어야 하므로 C<sub>ij</sub>이어야 한다.
 각 bounding box에 해당하는 confidence score를 box가 있다면 1이 될 것이고 없으면 0이 되도록 regression하는 loss가 있어야 하는데 마지막 term은 classification이고 위에 두 term은 coordinate에 관한 것이므로 confidence에 대한 regression하는 score가 없지만 수식적으로 맞지않는 부분이 존재한다.</del>
 background에 대한 confidence를 λ<sub>noobj</sub>의 값을 0.5로 설정하였다.
 object가 있는 영역 대비 반만 들어가도록 설정하였다.
 이러한 방법 또한 기존의 Faster R-CNN이나 SSD에서의 approach와 비슷하다고 볼 수 있다.
 grid based approach 자체가 background에 대한 grid가 적기 때문에 더 효과적인 학습이 가능하다.
 기존의 bounding box별로 background 인지 아닌지 구분하는 것은 background만 선택되어있는 bounding box가 너무 많은 것이 문제였는데 grid별로 object가 한 부분도 포함되지 않은 grid만 background로 여긴다.
 λ<sub>coord</sub>은 5로 숫자가 정해져 있고 그 이유는 다른 loss들과 balance를 맞추기 위해서 설정한 값이다.
 전체적인 network 구성이나 학습 방법이 간단하다는 것을 알 수 있다.

> * Experiments

![image](https://user-images.githubusercontent.com/122149118/230708763-092694b5-a19c-46ce-938f-a6fdf791e774.png)

 YOLO가 Real-Time algorithm을 사용하는 방법들 중에서는 가장 성능이 좋았으며 Fast R-CNN과 Faster R-CNN같은 경우에는 less than real-time에서 성능은 조금 더 좋긴하지만 FPS가 너무 떨어져서 real-time algorithm으로 보기에는 어렵다고할 수 있다.

# SSD (ECCV 2016)
> * Experiments

![image](https://user-images.githubusercontent.com/122149118/230708973-df0e6086-b782-4de6-98dd-7a3b7626929a.png)

 SSD에 나온 결과를 보면 SSD는 기존 YOLO대비 성능이 10%정도 올랐으며 속도도 뒤쳐지지 않는다는 것을 볼 수 있다.

# YOLO (CVPR 2016)

> * Experiments

![image](https://user-images.githubusercontent.com/122149118/230709079-72ed4ffa-ec2e-44f8-8a03-f5cdd7b8e9c2.png)

 YOLOv2에서는 같은 FPS를 유지하면서 성능을 78.6까지 끌어올린 것을 확인할 수 있다.
 78.6은 SSD의 76.8보다 2%가량 더 좋은 mAP를 가진다는 것 또한 확인할 수 있다.
 improved approach에서 YOLOv2에서는 anchor box를 사용하는 것을 제외했다는 점을 알 수 있다.
 따라서 최종 anchor box의 수인 98개를 유지하면서도 더 좋은 성능을 낼 수 있다는 것을 보이면서 SSD의 anchor box의 수가 많아야한다는 것을 claim이라고 볼 수 있다.

>   - Error analysis

![image](https://user-images.githubusercontent.com/122149118/230709328-57a0bf5c-b649-49e8-be7f-cc83c6d640bc.png) 

 Fast R-CNN과 YOLO를 비교했을 때 error가 어디서 오는지를 분석해본 것으로 localization이 안맞는 부분이 YOLO가 더 컸고 background에 대해서는 오히려 훨씬 적은 error를 보였다.
 YOLO의 grid based classification 방법이 background error를 줄일 수 있는 주요한 요인이라고 생각할 수 있다.
 anchor box를 쓰지않는 prediction되는 box의 개수가 적은 것이 location error에 큰 영향을 주는 것이라고 생각해볼 수 있다.
 Fast R-CNN과 YOLO가 취하는 approach가 다르다보니 approach에 강점들이 존재하는 것이고, YOLO는 다른 training techniqe으로 localization error를 완화하는 모습을 볼 수 있다.

![image](https://user-images.githubusercontent.com/122149118/230709499-f917b176-be11-435c-8177-76d47c5e7c0d.png)

 localization error가 4번째 그림 강아지 머리가 조금 잘리는 모습을 보여주는 것이고 3번째 그림에서도 person object 위치에 비해 조금 위에 bounding box가 위치하는 것이 error의 모습을 나타내는 것이다.
 box의 width와 height를 정하는 것이 network 성능에 sensitive하게 작용한다는 의견이 있어 localization이 쉽지 않다는 것인데 사람이 지정한 bounding box와 어느정도 겹치는 부분이 크면 되는 것으로 tuning하여 성능을 크게 늘릴 수 있었다.